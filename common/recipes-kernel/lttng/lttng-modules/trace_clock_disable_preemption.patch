From d3a177c909622313ef3a314e0ce812b0aca9d5ad Mon Sep 17 00:00:00 2001
From: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date: Fri, 9 Oct 2015 12:24:23 -0400
Subject: [PATCH] Fix: lttng trace-clock needs to disable preemption

We use a per-cpu data structure, and some contexts (e.g. buffer create)
call this function with preemption enabled. This is the case also for
buffer flush operation.

Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
---
 wrapper/trace-clock.h | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/wrapper/trace-clock.h b/wrapper/trace-clock.h
index d7d1842..561094b 100644
--- a/wrapper/trace-clock.h
+++ b/wrapper/trace-clock.h
@@ -90,7 +90,7 @@ static inline u64 trace_clock_fixup(u64 src_now, u64 last)
 #endif /* #else #if (BITS_PER_LONG == 32) */
 
 /*
- * Always called with preemption disabled. Can be interrupted.
+ * Sometimes called with preemption enabled. Can be interrupted.
  */
 static inline u64 trace_clock_monotonic_wrapper(void)
 {
@@ -99,6 +99,7 @@ static inline u64 trace_clock_monotonic_wrapper(void)
 	local_t *last_tsc;
 
 	/* Use fast nmi-safe monotonic clock provided by the Linux kernel. */
+	preempt_disable();
 	last_tsc = lttng_this_cpu_ptr(&lttng_last_tsc);
 	last = local_read(last_tsc);
 	/*
@@ -112,6 +113,7 @@ static inline u64 trace_clock_monotonic_wrapper(void)
 	if (((long) now - (long) last) < 0)
 		now = trace_clock_fixup(now, last);
 	result = local_cmpxchg(last_tsc, last, (unsigned long) now);
+	preempt_enable();
 	if (result == last) {
 		/* Update done. */
 		return now;
-- 
1.9.1

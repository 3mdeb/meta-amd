From 0faddbf26d7c403a26754ae197cd49b8b1e18562 Mon Sep 17 00:00:00 2001
From: Chunming Zhou <David1.Zhou@amd.com>
Date: Wed, 27 Apr 2016 18:07:41 +0800
Subject: [PATCH 0066/1722] drm/amdgpu: add pipeline sync while vmid switch in
 same ctx

Since vmid-mgr supports vmid sharing in one vm, the same ctx could
get different vmids for two emits without vm flush, vm_flush could
be done in another ring.

Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
Signed-off-by: Kalyan Alle <kalyan.alle@amd.com>
---
 drivers/gpu/drm/amd/amdgpu/amdgpu.h    | 4 +++-
 drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c | 9 +++++++--
 drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c | 6 +++---
 3 files changed, 13 insertions(+), 6 deletions(-)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu.h b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
index 351e74c..8dd93ec 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu.h
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
@@ -810,6 +810,7 @@ struct amdgpu_ring {
 	unsigned		cond_exe_offs;
 	u64				cond_exe_gpu_addr;
 	volatile u32	*cond_exe_cpu_addr;
+	int                     vmid;
 };
 
 /*
@@ -951,7 +952,8 @@ int amdgpu_vm_flush(struct amdgpu_ring *ring,
 		    unsigned vm_id, uint64_t pd_addr,
 		    uint32_t gds_base, uint32_t gds_size,
 		    uint32_t gws_base, uint32_t gws_size,
-		    uint32_t oa_base, uint32_t oa_size);
+		    uint32_t oa_base, uint32_t oa_size,
+		    bool vmid_switch);
 void amdgpu_vm_reset_id(struct amdgpu_device *adev, unsigned vm_id);
 uint64_t amdgpu_vm_map_gart(const dma_addr_t *pages_addr, uint64_t addr);
 int amdgpu_vm_update_page_directory(struct amdgpu_device *adev,
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
index e269141..af1f6a4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
@@ -122,6 +122,7 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
         bool skip_preamble, need_ctx_switch;
         unsigned patch_offset = ~0;
         struct amdgpu_vm *vm;
+        int vmid = 0, old_vmid = ring->vmid;
         struct fence *hwf;
         uint64_t ctx;
 
@@ -136,9 +137,11 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
         if (job) {
                 vm = job->vm;
                 ctx = job->ctx;
+                vmid = job->vm_id;
         } else {
                 vm = NULL;
                 ctx = 0;
+                vmid = 0;
         }
 
 	if (!ring->ready) {
@@ -164,7 +167,8 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
                 r = amdgpu_vm_flush(ring, job->vm_id, job->vm_pd_addr,
                                     job->gds_base, job->gds_size,
                                     job->gws_base, job->gws_size,
-                                    job->oa_base, job->oa_size);
+                                    job->oa_base, job->oa_size,
+                                    (ring->current_ctx == ctx) && (old_vmid != vmid));
 		if (r) {
 			amdgpu_ring_undo(ring);
 			return r;
@@ -181,7 +185,6 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
         need_ctx_switch = ring->current_ctx != ctx;
 	for (i = 0; i < num_ibs; ++i) {
                 ib = &ibs[i]; 
- 
                 /* drop preamble IBs if we don't have a context switch */
                 if ((ib->flags & AMDGPU_IB_FLAG_PREAMBLE) && skip_preamble)
                         continue;
@@ -189,6 +192,7 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
                 amdgpu_ring_emit_ib(ring, ib, job ? job->vm_id : 0,
                                     need_ctx_switch);
                 need_ctx_switch = false;
+                ring->vmid = vmid;
 	}
 	ring->last_fence_context = fence_context;
 
@@ -200,6 +204,7 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
 		dev_err(adev->dev, "failed to emit fence (%d)\n", r);
                 if (job && job->vm_id)
                         amdgpu_vm_reset_id(adev, job->vm_id);
+                ring->vmid = old_vmid;
 		amdgpu_ring_undo(ring);
 		return r;
 	}
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
index 51a9cdd..4f6a0ff 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
@@ -297,7 +297,8 @@ int amdgpu_vm_flush(struct amdgpu_ring *ring,
 		    unsigned vm_id, uint64_t pd_addr,
 		    uint32_t gds_base, uint32_t gds_size,
 		    uint32_t gws_base, uint32_t gws_size,
-		    uint32_t oa_base, uint32_t oa_size)
+		    uint32_t oa_base, uint32_t oa_size,
+		    bool vmid_switch)
 {
 	struct amdgpu_device *adev = ring->adev;
 	struct amdgpu_vm_id *id = &adev->vm_manager.ids[vm_id];
@@ -311,8 +312,7 @@ int amdgpu_vm_flush(struct amdgpu_ring *ring,
 	int r;
 
 	if (ring->funcs->emit_pipeline_sync && (
-	    pd_addr != AMDGPU_VM_NO_FLUSH || gds_switch_needed ||
-	    ring->type == AMDGPU_RING_TYPE_COMPUTE))
+            pd_addr != AMDGPU_VM_NO_FLUSH || gds_switch_needed || vmid_switch))
 	       amdgpu_ring_emit_pipeline_sync(ring);
 
 	if (ring->funcs->emit_vm_flush &&
-- 
2.7.4


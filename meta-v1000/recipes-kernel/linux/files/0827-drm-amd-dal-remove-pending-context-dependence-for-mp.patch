From 75100550fbd689d5f6d161005eb0a7065b9312b8 Mon Sep 17 00:00:00 2001
From: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date: Mon, 15 Aug 2016 16:54:19 -0400
Subject: [PATCH 0827/1722] drm/amd/dal: remove pending context dependence for
 mpo

Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Acked-by: Harry Wentland <harry.wentland@amd.com>
Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
Signed-off-by: Kalyan Alle <kalyan.alle@amd.com>
---
 drivers/gpu/drm/amd/dal/dc/core/dc.c               | 198 ++++++++++-----------
 drivers/gpu/drm/amd/dal/dc/core/dc_hw_sequencer.c  |   8 +-
 drivers/gpu/drm/amd/dal/dc/dc.h                    |   4 +-
 .../drm/amd/dal/dc/dce110/dce110_hw_sequencer.c    |  63 ++-----
 drivers/gpu/drm/amd/dal/dc/inc/core_dc.h           |   3 +-
 drivers/gpu/drm/amd/dal/dc/inc/core_types.h        |   3 -
 drivers/gpu/drm/amd/dal/dc/inc/hw_sequencer.h      |   8 +-
 7 files changed, 116 insertions(+), 171 deletions(-)

diff --git a/drivers/gpu/drm/amd/dal/dc/core/dc.c b/drivers/gpu/drm/amd/dal/dc/core/dc.c
index fb0d51a..463c660 100644
--- a/drivers/gpu/drm/amd/dal/dc/core/dc.c
+++ b/drivers/gpu/drm/amd/dal/dc/core/dc.c
@@ -277,8 +277,9 @@ static bool construct(struct core_dc *dc,
 	}
 
 	dc->current_context = dm_alloc(sizeof(*dc->current_context));
+	dc->temp_flip_context = dm_alloc(sizeof(*dc->temp_flip_context));
 
-	if (!dc->current_context) {
+	if (!dc->current_context || !dc->temp_flip_context) {
 		dm_error("%s: failed to create validate ctx\n", __func__);
 		goto val_ctx_fail;
 	}
@@ -366,6 +367,7 @@ static void destruct(struct core_dc *dc)
 {
 	resource_validate_ctx_destruct(dc->current_context);
 	dm_free(dc->current_context);
+        dm_free(dc->temp_flip_context);
 	dc->current_context = NULL;
 	destroy_links(dc);
 	dc->res_pool.funcs->destruct(&dc->res_pool);
@@ -889,18 +891,6 @@ bool dc_commit_targets(
 	dm_free(core_dc->current_context);
 	core_dc->current_context = context;
 
-	/* Any pending context is no longer valid once a setmode happens*/
-	if (core_dc->pending_context) {
-		resource_validate_ctx_destruct(core_dc->pending_context);
-		dm_free(core_dc->pending_context);
-		core_dc->pending_context = NULL;
-	}
-	if (core_dc->retired_context) {
-		resource_validate_ctx_destruct(core_dc->retired_context);
-		dm_free(core_dc->retired_context);
-		core_dc->retired_context = NULL;
-	}
-
 	return (result == DC_OK);
 
 fail:
@@ -923,17 +913,11 @@ bool dc_pre_commit_surfaces_to_target(
 	struct dc_target_status *target_status = NULL;
 	struct validate_context *context;
 	struct validate_context *temp_context;
-	bool bw_increased = false;
+        bool ret = true;
 
 	int current_enabled_surface_count = 0;
 	int new_enabled_surface_count = 0;
 
-        if (core_dc->retired_context) {
-                resource_validate_ctx_destruct(core_dc->retired_context);
-                dm_free(core_dc->retired_context);
-                core_dc->retired_context = NULL;
-        }
-
 	if (core_dc->current_context->target_count == 0)
 		return NULL;
 
@@ -942,6 +926,7 @@ bool dc_pre_commit_surfaces_to_target(
 
 	if (!context) {
 		dm_error("%s: failed to create validate ctx\n", __func__);
+                ret = false;
 		goto val_ctx_fail;
 	}
 
@@ -962,28 +947,23 @@ bool dc_pre_commit_surfaces_to_target(
 		if (new_surfaces[i]->visible)
 			new_enabled_surface_count++;
 
-	/*
-	 * Do not print if we have 2 surfaces previously and we are currently
-	 * comiting 2 surfaces. Since the multi-plane case generate a lot of
-	 * spam
-	 */
-	if (!((new_surface_count > 1) && target_status->surface_count > 1))
-		dal_logger_write(core_dc->ctx->logger,
-					LOG_MAJOR_INTERFACE_TRACE,
-					LOG_MINOR_COMPONENT_DC,
-					"%s: commit %d surfaces to target 0x%x\n",
-					__func__,
-					new_surface_count,
-					dc_target);
+	dal_logger_write(core_dc->ctx->logger,
+				LOG_MAJOR_INTERFACE_TRACE,
+				LOG_MINOR_COMPONENT_DC,
+				"%s: commit %d surfaces to target 0x%x\n",
+				__func__,
+				new_surface_count,
+				dc_target);
 
 	if (!resource_attach_surfaces_to_context(
 			new_surfaces, new_surface_count, dc_target, context)) {
 		BREAK_TO_DEBUGGER();
+		ret = false;
 		goto unexpected_fail;
 	}
 
 	for (i = 0; i < new_surface_count; i++)
-		for (j = 0; j < MAX_PIPES; j++) {
+		for (j = 0; j < context->res_ctx.pool->pipe_count; j++) {
 			if (context->res_ctx.pipe_ctx[j].surface !=
 					DC_SURFACE_TO_CORE(new_surfaces[i]))
 				continue;
@@ -999,6 +979,7 @@ bool dc_pre_commit_surfaces_to_target(
 
 	if (core_dc->res_pool.funcs->validate_bandwidth(core_dc, context) != DC_OK) {
 		BREAK_TO_DEBUGGER();
+                ret = false;
 		goto unexpected_fail;
 	}
 
@@ -1009,6 +990,7 @@ bool dc_pre_commit_surfaces_to_target(
                 if (!temp_context) {
                         dm_error("%s:failed apply clk constraints\n", __func__);
                         BREAK_TO_DEBUGGER();
+                        ret = false;
                         goto unexpected_fail;
                 }
                 resource_validate_ctx_destruct(context);
@@ -1019,107 +1001,112 @@ bool dc_pre_commit_surfaces_to_target(
 		pplib_apply_display_requirements(core_dc, context,
                                                 &context->pp_display_cfg);
                 core_dc->hwss.set_display_clock(context);
-                bw_increased = true;
                 core_dc->current_context->bw_results.dispclk_khz =
                                 context->bw_results.dispclk_khz;
 	}
+ 
+        for (i = 0; i < new_surface_count; i++)
+                for (j = 0; j < context->res_ctx.pool->pipe_count; j++) {
+                        if (context->res_ctx.pipe_ctx[j].surface !=
+                                        DC_SURFACE_TO_CORE(new_surfaces[i]))
+                                continue;
+ 
+                        core_dc->hwss.prepare_pipe_for_context(
+                                        core_dc,
+                                        &context->res_ctx.pipe_ctx[j],
+                                        context);
+                }
 
 	if (current_enabled_surface_count > 0 && new_enabled_surface_count == 0)
 		target_disable_memory_requests(dc_target,
 				&core_dc->current_context->res_ctx);
-
-        core_dc->hwss.apply_ctx_to_surface_locked(core_dc, context);
-        context->locked = true;
- 
-        core_dc->pending_context = context; 
- 
-        return !bw_increased;
  
 unexpected_fail:
+val_ctx_fail:
         resource_validate_ctx_destruct(context);
         dm_free(context);
-val_ctx_fail:
-        return false;
+	
+	return true;
 }
 
-bool dc_isr_commit_surfaces_to_target(
+ bool dc_isr_commit_surfaces_to_target(
                 struct dc *dc,
-                struct dc_flip_addrs flip_addrs[],
                 struct dc_surface *new_surfaces[],
-                int new_surface_count)
+                int new_surface_count,
+                struct dc_target *dc_target)
 {
         int i, j;
-        enum dc_status status = DC_OK;
         struct core_dc *core_dc = DC_TO_CORE(dc);
         int pipe_count = core_dc->res_pool->pipe_count;
-        struct validate_context *context = core_dc->pending_context ?
-                        core_dc->pending_context : core_dc->current_context;
+        struct validate_context *context = core_dc->temp_flip_context;
+
+        *context = *core_dc->current_context;
+
+        for (i = 0; i < context->res_ctx.pool->pipe_count; i++) {
+                struct pipe_ctx *cur_pipe = &context->res_ctx.pipe_ctx[i];
+
+                if (cur_pipe->top_pipe)
+                        cur_pipe->top_pipe =
+                                &context->res_ctx.pipe_ctx[cur_pipe->top_pipe->pipe_idx];
+
+                if (cur_pipe->bottom_pipe)
+                        cur_pipe->bottom_pipe =
+                                &context->res_ctx.pipe_ctx[cur_pipe->bottom_pipe->pipe_idx];
+        }
  
+        if (!resource_attach_surfaces_to_context(
+                        new_surfaces, new_surface_count, dc_target, context)) {
+                BREAK_TO_DEBUGGER();
+                return false;
+        }
  
-        for (j = 0; j < pipe_count; j++) {
-                struct pipe_ctx *pipe_ctx =
-                        &context->res_ctx.pipe_ctx[j];
-                struct core_surface *ctx_surface = pipe_ctx->surface;
+        for (i = 0; i < new_surface_count; i++)
+                for (j = 0; j < context->res_ctx.pool->pipe_count; j++) {
+                        struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[j];
  
-                if (!ctx_surface)
-                        continue;
+                        if (pipe_ctx->surface !=
+                                        DC_SURFACE_TO_CORE(new_surfaces[i]))
+                                continue;
  
-                if (flip_addrs) {
-                        for (i = 0; i < new_surface_count; i++) {
-                                        /*
-                                         * Temporary hack, allow address to be filled into
-                                         * the surface directly and programmed here.
-                                         * TODO: Unify how address is passed into DC
-                                         */
+                        resource_build_scaling_params(new_surfaces[i], pipe_ctx);
  
-                                        if (DC_SURFACE_TO_CORE(new_surfaces[i]) != ctx_surface)
-                                                continue;
-                                ctx_surface->public.address = flip_addrs[i].address;
-                                ctx_surface->public.flip_immediate = flip_addrs[i].flip_immediate;
+                        if (dc->debug.surface_visual_confirm) {
+                                pipe_ctx->scl_data.recout.height -= 2;
+                                pipe_ctx->scl_data.recout.width -= 2;
                         }
-                }
- 
-                if (!ctx_surface->public.flip_immediate)
+
                         core_dc->hwss.pipe_control_lock(
                                         core_dc->ctx,
                                         pipe_ctx->pipe_idx,
-                                        PIPE_LOCK_CONTROL_SURFACE |
-                                        PIPE_LOCK_CONTROL_MODE,
+                                        PIPE_LOCK_CONTROL_SURFACE,
                                         true);
- 
-                core_dc->hwss.update_plane_addr(core_dc, pipe_ctx);
- 
-        } 
 
-        for (j = pipe_count - 1; j >= 0; j--)
-                for (i = new_surface_count - 1; i >= 0; i--) {
-                        struct pipe_ctx *pipe_ctx =
-                                &context->res_ctx.pipe_ctx[j];
-                        struct core_surface *ctx_surface = pipe_ctx->surface;
- 
-                        if (!ctx_surface)
-                                continue;
- 
-                        if (!ctx_surface->public.flip_immediate)
-                                core_dc->hwss.pipe_control_lock(
-                                                core_dc->ctx,
-                                                pipe_ctx->pipe_idx,
-                                                PIPE_LOCK_CONTROL_SURFACE,
-                                                false);
+                        core_dc->hwss.update_plane_addr(core_dc, pipe_ctx);
                 }
+
+        core_dc->hwss.apply_ctx_to_surface(core_dc, context);
+        /* Go in reverse order so that all pipes are unlocked simultaneously
+         * when pipe 0 is unlocked
+         * Need PIPE_LOCK_CONTROL_MODE to be 1 for this
+        */
+        for (i = context->res_ctx.pool->pipe_count - 1; i >= 0; i--) {
+                struct pipe_ctx *pipe_ctx =
+                                        &context->res_ctx.pipe_ctx[i];
  
-        if (core_dc->pending_context && core_dc->pending_context->locked) {
-                status = core_dc->hwss.apply_ctx_to_surface_unlock(core_dc, core_dc->pending_context);
-                core_dc->pending_context->locked = false;
-        }
-        if (core_dc->pending_context) {
-                ASSERT(core_dc->retired_context == NULL || core_dc->retired_context == core_dc->current_context);
-                core_dc->retired_context = core_dc->current_context;
-                core_dc->current_context = core_dc->pending_context;
-                core_dc->pending_context = NULL;
+                core_dc->hwss.pipe_control_lock(
+                                core_dc->ctx,
+                                pipe_ctx->pipe_idx,
+                                PIPE_LOCK_CONTROL_GRAPHICS |
+                                PIPE_LOCK_CONTROL_SCL |
+                                PIPE_LOCK_CONTROL_BLENDER |
+                                PIPE_LOCK_CONTROL_SURFACE,
+                                false);
         }
-  
-        return status == DC_OK;
+
+        core_dc->temp_flip_context = core_dc->current_context;
+        core_dc->current_context = context;
+ 
+        return true;
 }
 
 bool dc_post_commit_surfaces_to_target(struct dc *dc)
@@ -1144,11 +1131,6 @@ bool dc_post_commit_surfaces_to_target(struct dc *dc)
         pplib_apply_display_requirements(
                         core_dc, core_dc->current_context, &core_dc->current_context->pp_display_cfg); 
  
-        if (core_dc->retired_context) {
-                resource_validate_ctx_destruct(core_dc->retired_context);
-                dm_free(core_dc->retired_context);
-                core_dc->retired_context = NULL;
-        } 
 	return true;
 }
 
@@ -1165,7 +1147,7 @@ bool dc_commit_surfaces_to_target(
                         dc_target))
                 return false;
  
-        if (!dc_isr_commit_surfaces_to_target(dc, NULL, new_surfaces, new_surface_count))
+        if (!dc_isr_commit_surfaces_to_target(dc, new_surfaces, new_surface_count, dc_target))
                 return false;
  
         if (!dc_post_commit_surfaces_to_target(dc))
diff --git a/drivers/gpu/drm/amd/dal/dc/core/dc_hw_sequencer.c b/drivers/gpu/drm/amd/dal/dc/core/dc_hw_sequencer.c
index afc5b44..933311e 100644
--- a/drivers/gpu/drm/amd/dal/dc/core/dc_hw_sequencer.c
+++ b/drivers/gpu/drm/amd/dal/dc/core/dc_hw_sequencer.c
@@ -53,10 +53,16 @@ static const struct tg_color black_color_format[] = {
 	{0x1a2, 0x20, 0x1a2},
 };
 
-bool front_end_need_program(struct pipe_ctx *old_pipe, struct pipe_ctx *new_pipe)
+static bool front_end_need_program(struct pipe_ctx *old_pipe, struct pipe_ctx *new_pipe)
 {
 	/*TODO: Findout if this is sufficient comparison*/
 
+	if (new_pipe->bottom_pipe && !old_pipe->bottom_pipe)
+		return true;
+
+	if (!new_pipe->bottom_pipe && old_pipe->bottom_pipe)
+		return true;
+
 	/* The scl_data comparison handles the hsplit case where the surface is unmodified*/
 	return new_pipe->surface != old_pipe->surface || memcmp(&old_pipe->scl_data,
 			&new_pipe->scl_data,
diff --git a/drivers/gpu/drm/amd/dal/dc/dc.h b/drivers/gpu/drm/amd/dal/dc/dc.h
index 3117e12..ac56bfa 100644
--- a/drivers/gpu/drm/amd/dal/dc/dc.h
+++ b/drivers/gpu/drm/amd/dal/dc/dc.h
@@ -241,9 +241,9 @@ bool dc_pre_commit_surfaces_to_target(
 
 bool dc_isr_commit_surfaces_to_target(
 		struct dc *dc,
-		struct dc_flip_addrs flip_addrs[],
 		struct dc_surface *new_surfaces[],
-		int new_surface_count);
+		int new_surface_count,
+		struct dc_target *dc_target);
 
 bool dc_post_commit_surfaces_to_target(
 		struct dc *dc);
diff --git a/drivers/gpu/drm/amd/dal/dc/dce110/dce110_hw_sequencer.c b/drivers/gpu/drm/amd/dal/dc/dce110/dce110_hw_sequencer.c
index d724858..0790952 100644
--- a/drivers/gpu/drm/amd/dal/dc/dce110/dce110_hw_sequencer.c
+++ b/drivers/gpu/drm/amd/dal/dc/dce110/dce110_hw_sequencer.c
@@ -1915,22 +1915,16 @@ static void dce110_program_front_end_for_pipe(struct core_dc *dc,
 	struct out_csc_color_matrix tbl_entry;
 	unsigned int i;
 
-	int lock_mask =
-		PIPE_LOCK_CONTROL_GRAPHICS |
-		PIPE_LOCK_CONTROL_SCL |
-		PIPE_LOCK_CONTROL_BLENDER |
-		PIPE_LOCK_CONTROL_MODE;
-
 	memset(&tbl_entry, 0, sizeof(tbl_entry));
 
-	if (!pipe_ctx->surface->public.flip_immediate)
-		lock_mask |= PIPE_LOCK_CONTROL_SURFACE;
-
 	if (blender_configuration_changed(pipe_ctx, &dc->current_context->res_ctx.pipe_ctx[pipe_ctx->pipe_idx]))
 		dc->hwss.pipe_control_lock(
 				dc->ctx,
 				pipe_ctx->pipe_idx,
-				lock_mask,
+				PIPE_LOCK_CONTROL_GRAPHICS |
+				PIPE_LOCK_CONTROL_SCL |
+				PIPE_LOCK_CONTROL_BLENDER |
+				PIPE_LOCK_CONTROL_MODE,
 				true);
 
 	if (dc->current_context)
@@ -2011,8 +2005,6 @@ static void dce110_program_front_end_for_pipe(struct core_dc *dc,
 				&surface->public.tiling_info,
 				surface->public.rotation);
 
-	dc->hwss.update_plane_addr(dc, pipe_ctx);
-
 	dal_logger_write(dc->ctx->logger,
 			LOG_MAJOR_INTERFACE_TRACE,
 			LOG_MINOR_COMPONENT_SURFACE,
@@ -2075,31 +2067,16 @@ static void dce110_prepare_pipe_for_surface_commit(
 			gamma, pipe_ctx->surface);
 }
 
-static enum dc_status apply_ctx_to_surface_locked(
+static void dce110_prepare_pipe_for_context(
 		struct core_dc *dc,
+		struct pipe_ctx *pipe_ctx,
 		struct validate_context *context)
 {
-	int i;
-
-	for (i = 0; i < context->res_ctx.pool->pipe_count; i++) {
-		struct pipe_ctx *head_pipe = &context->res_ctx.pipe_ctx[i];
-
-		if (!head_pipe->surface || head_pipe->top_pipe != NULL)
-			continue;
-
-		hw_sequencer_program_pipe_tree(dc, context, head_pipe,
-				dce110_power_on_pipe_if_needed);
-
-		hw_sequencer_program_pipe_tree(dc, context, head_pipe,
-				dce110_prepare_pipe_for_surface_commit);
-
-	}
-
-
-	return DC_OK;
+	dce110_power_on_pipe_if_needed(dc, pipe_ctx, context);
+	dce110_prepare_pipe_for_surface_commit(dc, pipe_ctx, context);
 }
 
-static enum dc_status apply_ctx_to_surface_unlock(
+static enum dc_status dce110_apply_ctx_to_surface(
 		struct core_dc *dc,
 		struct validate_context *context)
 {
@@ -2118,24 +2095,6 @@ static enum dc_status apply_ctx_to_surface_unlock(
 				dce110_program_blending);
 	}
 
-	/* Go in reverse order so that all pipes are unlocked simultaneously
-	 * when pipe 0 is unlocked
-	 * Need PIPE_LOCK_CONTROL_MODE to be 1 for this
-	 */
-	for (i = context->res_ctx.pool->pipe_count - 1; i >= 0; i--) {
-		struct pipe_ctx *pipe_ctx =
-					&context->res_ctx.pipe_ctx[i];
-
-		dc->hwss.pipe_control_lock(
-				dc->ctx,
-				pipe_ctx->pipe_idx,
-				PIPE_LOCK_CONTROL_GRAPHICS |
-				PIPE_LOCK_CONTROL_SCL |
-				PIPE_LOCK_CONTROL_BLENDER |
-				PIPE_LOCK_CONTROL_SURFACE,
-				false);
-	}
-
 	return DC_OK;
 }
 
@@ -2164,8 +2123,8 @@ static void update_plane_surface(
 static const struct hw_sequencer_funcs dce110_funcs = {
 	.init_hw = init_hw,
 	.apply_ctx_to_hw = apply_ctx_to_hw,
-	.apply_ctx_to_surface_locked = apply_ctx_to_surface_locked,
-	.apply_ctx_to_surface_unlock = apply_ctx_to_surface_unlock,
+	.prepare_pipe_for_context = dce110_prepare_pipe_for_context,
+	.apply_ctx_to_surface = dce110_apply_ctx_to_surface,
 	.set_plane_config = set_plane_config,
 	.update_plane_addr = update_plane_addr,
 	.update_pending_status = update_pending_status,
diff --git a/drivers/gpu/drm/amd/dal/dc/inc/core_dc.h b/drivers/gpu/drm/amd/dal/dc/inc/core_dc.h
index 17efc25..6fdd07e 100644
--- a/drivers/gpu/drm/amd/dal/dc/inc/core_dc.h
+++ b/drivers/gpu/drm/amd/dal/dc/inc/core_dc.h
@@ -22,9 +22,8 @@ struct coe_dc {
 	struct core_link *links[MAX_PIPES * 2];
 
 	/* TODO: determine max number of targets*/
-        struct validate_context *retired_context;
 	struct validate_context *current_context;
-        struct validate_context *pending_context;
+        struct validate_context *temp_flip_context;
 	struct resource_pool res_pool;
 
 	/*Power State*/
diff --git a/drivers/gpu/drm/amd/dal/dc/inc/core_types.h b/drivers/gpu/drm/amd/dal/dc/inc/core_types.h
index c992665..03ca083 100644
--- a/drivers/gpu/drm/amd/dal/dc/inc/core_types.h
+++ b/drivers/gpu/drm/amd/dal/dc/inc/core_types.h
@@ -310,9 +310,6 @@ struct validate_context {
 	struct bw_calcs_output bw_results;
 	/* Note: this is a big structure, do *not* put on stack! */
 	struct dm_pp_display_configuration pp_display_cfg;
-
-	/* Temporary*/
-	bool locked;
 };
 
 #endif /* _CORE_TYPES_H_ */
diff --git a/drivers/gpu/drm/amd/dal/dc/inc/hw_sequencer.h b/drivers/gpu/drm/amd/dal/dc/inc/hw_sequencer.h
index af12833..2bd09dc 100644
--- a/drivers/gpu/drm/amd/dal/dc/inc/hw_sequencer.h
+++ b/drivers/gpu/drm/amd/dal/dc/inc/hw_sequencer.h
@@ -51,10 +51,12 @@ struct hw_sequencer_funcs {
 	enum dc_status (*apply_ctx_to_hw)(
 			struct core_dc *dc, struct validate_context *context);
 
-	enum dc_status (*apply_ctx_to_surface_locked)(
-			struct core_dc *dc, struct validate_context *context);
+	void (*prepare_pipe_for_context)(
+			struct core_dc *dc,
+			struct pipe_ctx *pipe_ctx,
+			struct validate_context *context);
 
-	enum dc_status (*apply_ctx_to_surface_unlock)(
+	void (*apply_ctx_to_surface)(
 			struct core_dc *dc, struct validate_context *context);
 
 	void (*set_plane_config)(
-- 
2.7.4


From ecb22058ed93a350791fe3da1f0ee506799dcbef Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Christian=20K=C3=B6nig?= <christian.koenig@amd.com>
Date: Fri, 6 May 2016 15:57:42 +0200
Subject: [PATCH 0051/1722] drm/amdgpu: move the context from the IBs into the
 job
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

We only have one context for all IBs.

Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
Signed-off-by: Kalyan Alle <kalyan.alle@amd.com>
---
 drivers/gpu/drm/amd/amdgpu/amdgpu.h     |  2 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c  |  9 ++++-----
 drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c  | 27 +++++++++++++++++----------
 drivers/gpu/drm/amd/amdgpu/amdgpu_job.c |  7 +++----
 4 files changed, 25 insertions(+), 20 deletions(-)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu.h b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
index a2f5cfa..a7db71e 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu.h
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
@@ -754,7 +754,6 @@ struct amdgpu_ib {
 	struct amdgpu_user_fence	*user;
 	unsigned			vm_id;
 	uint64_t			vm_pd_addr;
-        uint64_t                        ctx;
 	uint32_t			gds_base, gds_size;
 	uint32_t			gws_base, gws_size;
 	uint32_t			oa_base, oa_size;
@@ -1271,6 +1270,7 @@ struct amdgpu_job {
 	struct fence		*fence; /* the hw fence */
 	uint32_t		num_ibs;
 	void			*owner;
+        uint64_t                ctx;
 	uint64_t		fence_context;
 	struct amdgpu_user_fence	 uf;
 };
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 00ed90c..54420a8 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -790,7 +790,6 @@ static int amdgpu_cs_ib_fill(struct amdgpu_device *adev,
 
 		ib->length_dw = chunk_ib->ib_bytes / 4;
 		ib->flags = chunk_ib->flags;
-                ib->ctx = parser->ctx->rings[ring->idx].entity.fence_context;
 		j++;
 	}
 
@@ -898,16 +897,16 @@ static int amdgpu_cs_submit(struct amdgpu_cs_parser *p,
 	p->job = NULL;
 
 	r = amd_sched_job_init(&job->base, &ring->sched,
-						&p->ctx->rings[ring->idx].entity,
-						amdgpu_job_timeout_func,
-						amdgpu_job_free_func,
-						p->filp, &fence);
+			       entity, amdgpu_job_timeout_func,
+			       amdgpu_job_free_func,
+			       p->filp, &fence);
 	if (r) {
 		amdgpu_job_free(job);
 		return r;
 	}
 
 	job->owner = p->filp;
+        job->ctx = entity->fence_context;
 	p->fence = fence_get(fence);
 	cs->out.handle = amdgpu_ctx_add_fence(p->ctx, ring, fence);
 	job->ibs[job->num_ibs - 1].sequence = cs->out.handle;
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
index ee3a3b1..1f7a7a88 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
@@ -121,20 +121,27 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
 	struct amdgpu_device *adev = ring->adev;
 	struct amdgpu_ib *ib = &ibs[0];
 	uint64_t fence_context = 0, old = ring->last_fence_context;
-	struct fence *hwf;
-	struct amdgpu_vm *vm = NULL;
-	unsigned i, patch_offset = ~0;
         bool skip_preamble, need_ctx_switch;
+        unsigned patch_offset = ~0;
+        struct amdgpu_vm *vm;
+        struct fence *hwf;
+        uint64_t ctx;
+
+        unsigned i;
 
 	int r = 0;
 
 	if (num_ibs == 0)
 		return -EINVAL;
 
-	if (job) {/* for domain0 job like ring test, ibs->job is not assigned */
-		vm = job->vm;
-		fence_context = job->fence_context;
-	}
+        /* ring tests don't use a job */
+        if (job) {
+                vm = job->vm;
+                ctx = job->ctx;
+        } else {
+                vm = NULL;
+                ctx = 0;
+        }
 
 	if (!ring->ready) {
 		dev_err(adev->dev, "couldn't schedule ib\n");
@@ -172,8 +179,8 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
 	/* always set cond_exec_polling to CONTINUE */
 	*ring->cond_exe_cpu_addr = 1;
  
-        skip_preamble = ring->current_ctx == ib->ctx;
-        need_ctx_switch = ring->current_ctx != ib->ctx;
+        skip_preamble = ring->current_ctx == ctx;
+        need_ctx_switch = ring->current_ctx != ctx;
 	for (i = 0; i < num_ibs; ++i) {
                 ib = &ibs[i]; 
  
@@ -212,7 +219,7 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
 	if (patch_offset != ~0 && ring->funcs->patch_cond_exec)
 		amdgpu_ring_patch_cond_exec(ring, patch_offset);
  
-        ring->current_ctx = ibs->ctx;
+        ring->current_ctx = ctx;
 	amdgpu_ring_commit(ring);
 	return 0;
 }
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c
index de521d8..dd34f31 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c
@@ -122,14 +122,13 @@ int amdgpu_job_submit(struct amdgpu_job *job, struct amdgpu_ring *ring,
 		return -EINVAL;
 
 	r = amd_sched_job_init(&job->base, &ring->sched,
-						       entity,
-						       amdgpu_job_timeout_func,
-						       amdgpu_job_free_func,
-						       owner, &fence);
+                               entity, amdgpu_job_timeout_func,
+                               amdgpu_job_free_func, owner, &fence);
 	if (r)
 		return r;
 
 	job->owner = owner;
+        job->ctx = entity->fence_context;
 	*f = fence_get(fence);
 	amd_sched_entity_push_job(&job->base);
 
-- 
2.7.4


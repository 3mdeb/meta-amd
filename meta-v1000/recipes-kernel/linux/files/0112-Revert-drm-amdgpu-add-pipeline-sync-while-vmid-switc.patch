From 6768b3e6885d35ce9994b20106ccc5b7243ee0ee Mon Sep 17 00:00:00 2001
From: Alex Deucher <alexander.deucher@amd.com>
Date: Mon, 13 Jun 2016 18:59:17 -0400
Subject: [PATCH 0112/1722] Revert "drm/amdgpu: add pipeline sync while vmid
 switch in same ctx"

This reverts commit 2ba272d7bde27e1db2cf1c6cee49b01b7ea08989.

The issue fixed by this patch is specific to compute rings and the
previous patch was enough.  Additionally, this patch as been traced
to strange behavior on some CZ systems so we might as well drop it.
Signed-off-by: Kalyan Alle <kalyan.alle@amd.com>
---
 drivers/gpu/drm/amd/amdgpu/amdgpu.h    |  4 +---
 drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c | 11 +++--------
 drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c |  6 +++---
 3 files changed, 7 insertions(+), 14 deletions(-)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu.h b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
index 97ab88e..edb990d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu.h
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
@@ -810,7 +810,6 @@ struct amdgpu_ring {
 	unsigned		cond_exe_offs;
 	u64				cond_exe_gpu_addr;
 	volatile u32	*cond_exe_cpu_addr;
-	int                     vmid;
 };
 
 /*
@@ -952,8 +951,7 @@ int amdgpu_vm_flush(struct amdgpu_ring *ring,
 		    unsigned vm_id, uint64_t pd_addr,
 		    uint32_t gds_base, uint32_t gds_size,
 		    uint32_t gws_base, uint32_t gws_size,
-		    uint32_t oa_base, uint32_t oa_size,
-		    bool vmid_switch);
+		    uint32_t oa_base, uint32_t oa_size);
 void amdgpu_vm_reset_id(struct amdgpu_device *adev, unsigned vm_id);
 uint64_t amdgpu_vm_map_gart(const dma_addr_t *pages_addr, uint64_t addr);
 int amdgpu_vm_update_page_directory(struct amdgpu_device *adev,
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
index af1f6a4..95aa73d 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ib.c
@@ -122,7 +122,6 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
         bool skip_preamble, need_ctx_switch;
         unsigned patch_offset = ~0;
         struct amdgpu_vm *vm;
-        int vmid = 0, old_vmid = ring->vmid;
         struct fence *hwf;
         uint64_t ctx;
 
@@ -137,11 +136,9 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
         if (job) {
                 vm = job->vm;
                 ctx = job->ctx;
-                vmid = job->vm_id;
         } else {
                 vm = NULL;
                 ctx = 0;
-                vmid = 0;
         }
 
 	if (!ring->ready) {
@@ -167,8 +164,7 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
                 r = amdgpu_vm_flush(ring, job->vm_id, job->vm_pd_addr,
                                     job->gds_base, job->gds_size,
                                     job->gws_base, job->gws_size,
-                                    job->oa_base, job->oa_size,
-                                    (ring->current_ctx == ctx) && (old_vmid != vmid));
+                                    job->oa_base, job->oa_size);
 		if (r) {
 			amdgpu_ring_undo(ring);
 			return r;
@@ -185,14 +181,14 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
         need_ctx_switch = ring->current_ctx != ctx;
 	for (i = 0; i < num_ibs; ++i) {
                 ib = &ibs[i]; 
-                /* drop preamble IBs if we don't have a context switch */
+                
+		/* drop preamble IBs if we don't have a context switch */
                 if ((ib->flags & AMDGPU_IB_FLAG_PREAMBLE) && skip_preamble)
                         continue;
 
                 amdgpu_ring_emit_ib(ring, ib, job ? job->vm_id : 0,
                                     need_ctx_switch);
                 need_ctx_switch = false;
-                ring->vmid = vmid;
 	}
 	ring->last_fence_context = fence_context;
 
@@ -204,7 +200,6 @@ int amdgpu_ib_schedule(struct amdgpu_ring *ring, unsigned num_ibs,
 		dev_err(adev->dev, "failed to emit fence (%d)\n", r);
                 if (job && job->vm_id)
                         amdgpu_vm_reset_id(adev, job->vm_id);
-                ring->vmid = old_vmid;
 		amdgpu_ring_undo(ring);
 		return r;
 	}
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
index 4f6a0ff..e0e40e4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
@@ -297,8 +297,7 @@ int amdgpu_vm_flush(struct amdgpu_ring *ring,
 		    unsigned vm_id, uint64_t pd_addr,
 		    uint32_t gds_base, uint32_t gds_size,
 		    uint32_t gws_base, uint32_t gws_size,
-		    uint32_t oa_base, uint32_t oa_size,
-		    bool vmid_switch)
+		    uint32_t oa_base, uint32_t oa_size)
 {
 	struct amdgpu_device *adev = ring->adev;
 	struct amdgpu_vm_id *id = &adev->vm_manager.ids[vm_id];
@@ -312,7 +311,8 @@ int amdgpu_vm_flush(struct amdgpu_ring *ring,
 	int r;
 
 	if (ring->funcs->emit_pipeline_sync && (
-            pd_addr != AMDGPU_VM_NO_FLUSH || gds_switch_needed || vmid_switch))
+            pd_addr != AMDGPU_VM_NO_FLUSH || gds_switch_needed ||
+                    ring->type == AMDGPU_RING_TYPE_COMPUTE))
 	       amdgpu_ring_emit_pipeline_sync(ring);
 
 	if (ring->funcs->emit_vm_flush &&
-- 
2.7.4


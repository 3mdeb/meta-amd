From ffdbc4188fe1fd726ef1dd868a29b89bda78e606 Mon Sep 17 00:00:00 2001
From: Chunming Zhou <David1.Zhou@amd.com>
Date: Thu, 21 Jul 2016 17:20:52 +0800
Subject: [PATCH 0758/1722] drm/amdgpu: recover vram bo from shadow after gpu
 reset V2
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

V2:
1. don't directly submit to many jobs at the same time.
2. delete unrelated printk.

Signed-off-by: Chunming Zhou <David1.Zhou@amd.com>
Reviewed-by: Christian KÃ¶nig <christian.koenig@amd.com>
Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
Signed-off-by: Kalyan Alle <kalyan.alle@amd.com>
---
 drivers/gpu/drm/amd/amdgpu/amdgpu_device.c | 62 ++++++++++++++++++++++++++++++
 1 file changed, 62 insertions(+)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c
index 913298f..8cd92e9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_device.c
@@ -2123,6 +2123,35 @@ bool amdgpu_need_backup(struct amdgpu_device *adev)
 	return amdgpu_lockup_timeout > 0 ? true : false;
 }
 
+static int amdgpu_recover_vram_from_shadow(struct amdgpu_device *adev,
+					   struct amdgpu_ring *ring,
+					   struct amdgpu_bo *bo,
+					   struct fence **fence)
+{
+	uint32_t domain;
+	int r;
+
+       if (!bo->shadow)
+               return 0;
+
+       r = amdgpu_bo_reserve(bo, false);
+       if (r)
+               return r;
+       domain = amdgpu_mem_type_to_domain(bo->tbo.mem.mem_type);
+       /* if bo has been evicted, then no need to recover */
+       if (domain == AMDGPU_GEM_DOMAIN_VRAM) {
+               r = amdgpu_bo_restore_from_shadow(adev, ring, bo,
+						 NULL, fence, true);
+               if (r) {
+                       DRM_ERROR("recover page table failed!\n");
+                       goto err;
+               }
+       }
+err:
+       amdgpu_bo_unreserve(bo);
+       return r;
+}
+
 /**
  * amdgpu_gpu_reset - reset the asic
  *
@@ -2203,13 +2232,46 @@ retry:
                 if (r) {
                         dev_err(adev->dev, "ib ring test failed (%d).\n", r);
                         r = amdgpu_suspend(adev);
+                        need_full_reset = true;
                         goto retry;
                 }
+                /**
+                 * recovery vm page tables, since we cannot depend on VRAM is
+                 * consistent after gpu full reset.
+                 */
+                if (need_full_reset && amdgpu_need_backup(adev)) {
+                        struct amdgpu_ring *ring = adev->mman.buffer_funcs_ring;
+                        struct amdgpu_bo *bo, *tmp;
+                        struct fence *fence = NULL, *next = NULL;
  
+                        DRM_INFO("recover vram bo from shadow\n");
+                        mutex_lock(&adev->shadow_list_lock);
+                        list_for_each_entry_safe(bo, tmp, &adev->shadow_list, shadow_list) {
+                                amdgpu_recover_vram_from_shadow(adev, ring, bo, &next);
+                                if (fence) {
+                                        r = fence_wait(fence, false);
+                                        if (r) {
+                                                WARN(r, "recovery from shadow isn't comleted\n");
+                                                break;
+                                        }
+                                }
+
+                                fence_put(fence);
+                                fence = next;
+                        }
+                        mutex_unlock(&adev->shadow_list_lock);
+                        if (fence) {
+                                r = fence_wait(fence, false);
+                                if (r)
+                                        WARN(r, "recovery from shadow isn't comleted\n");
+                        }
+                        fence_put(fence);
+                } 
 		for (i = 0; i < AMDGPU_MAX_RINGS; ++i) {
 			struct amdgpu_ring *ring = adev->rings[i];
 			if (!ring)
 				continue;
+
 			amd_sched_job_recovery(&ring->sched);
 			kthread_unpark(ring->sched.thread);
 		}
-- 
2.7.4


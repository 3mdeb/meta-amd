From 6f1dfbde6c1d3e10d8a088f0c95901502089cd0e Mon Sep 17 00:00:00 2001
From: Ken Wang <Qingqing.Wang@amd.com>
Date: Wed, 15 Jul 2015 15:15:21 +0800
Subject: [PATCH 01/16] winsys/amdgpu follow libdrm change to move user fence
 into UMD
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Ken Wang <Qingqing.Wang@amd.com>
Reviewed-by: Marek Olšák <marek.olsak@amd.com>
Signed-off-by: Arindam Nath <arindam.nath@amd.com>
---
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.c | 47 +++++++++++++++++++++++++++----
 src/gallium/winsys/amdgpu/drm/amdgpu_cs.h |  4 +++
 2 files changed, 46 insertions(+), 5 deletions(-)

diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
index 51ec0d9..69698c2 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.c
@@ -55,12 +55,14 @@ amdgpu_fence_create(struct amdgpu_ctx *ctx, unsigned ip_type,
 }
 
 static void amdgpu_fence_submitted(struct pipe_fence_handle *fence,
-                                   uint64_t fence_id)
+				struct amdgpu_cs_request* request,
+				uint64_t *user_fence_cpu_address)
 {
    struct amdgpu_fence *rfence = (struct amdgpu_fence*)fence;
 
-   rfence->fence = fence_id;
+   rfence->fence = request->seq_no;
    rfence->submission_in_progress = false;
+   rfence->user_fence_cpu_address = user_fence_cpu_address;
 }
 
 static void amdgpu_fence_signalled(struct pipe_fence_handle *fence)
@@ -77,6 +79,7 @@ bool amdgpu_fence_wait(struct pipe_fence_handle *fence, uint64_t timeout,
    struct amdgpu_cs_fence query = {0};
    uint32_t expired;
    int64_t abs_timeout;
+   uint64_t *user_fence_cpu;
    int r;
 
    if (rfence->signalled)
@@ -94,6 +97,12 @@ bool amdgpu_fence_wait(struct pipe_fence_handle *fence, uint64_t timeout,
                                        abs_timeout))
       return false;
 
+   user_fence_cpu = rfence->user_fence_cpu_address;
+
+   if (*user_fence_cpu >= rfence->fence) {
+	rfence->signalled = true;
+	return true;
+   }
    /* Now use the libdrm query. */
    query.fence = rfence->fence;
    query.context = rfence->ctx->ctx;
@@ -132,6 +141,8 @@ static struct radeon_winsys_ctx *amdgpu_ctx_create(struct radeon_winsys *ws)
 {
    struct amdgpu_ctx *ctx = CALLOC_STRUCT(amdgpu_ctx);
    int r;
+   struct amdgpu_bo_alloc_request alloc_buffer = {};
+   struct amdgpu_bo_alloc_result info = {};
 
    ctx->ws = amdgpu_winsys(ws);
    ctx->refcount = 1;
@@ -143,6 +154,26 @@ static struct radeon_winsys_ctx *amdgpu_ctx_create(struct radeon_winsys *ws)
       return NULL;
    }
 
+   alloc_buffer.alloc_size = 4 * 1024;
+   alloc_buffer.phys_alignment = 4 *1024;
+   alloc_buffer.preferred_heap = AMDGPU_GEM_DOMAIN_GTT;
+
+   r = amdgpu_bo_alloc(ctx->ws->dev, &alloc_buffer, &info);
+   if (r) {
+      fprintf(stderr, "amdgpu: amdgpu_bo_alloc failed. (%i)\n", r);
+      FREE(ctx);
+      return NULL;
+   }
+
+   r = amdgpu_bo_cpu_map(info.buf_handle, (void**)&ctx->user_fence_cpu_address_base);
+   if (r) {
+      fprintf(stderr, "amdgpu: amdgpu_bo_cpu_map failed. (%i)\n", r);
+      FREE(ctx);
+      return NULL;
+   }
+
+   ctx->user_fence_bo = info.buf_handle;
+
    return (struct radeon_winsys_ctx*)ctx;
 }
 
@@ -501,7 +532,6 @@ void amdgpu_cs_emit_ioctl_oneshot(struct amdgpu_cs *cs, struct amdgpu_cs_context
 {
    struct amdgpu_winsys *ws = cs->ctx->ws;
    int i, j, r;
-   uint64_t fence;
 
    csc->request.number_of_dependencies = 0;
 
@@ -545,7 +575,12 @@ void amdgpu_cs_emit_ioctl_oneshot(struct amdgpu_cs *cs, struct amdgpu_cs_context
    }
    pipe_mutex_unlock(ws->bo_fence_lock);
 
-   r = amdgpu_cs_submit(cs->ctx->ctx, 0, &csc->request, 1, &fence);
+   csc->request.fence_info.handle = NULL;
+   if (csc->request.ip_type != AMDGPU_HW_IP_UVD && csc->request.ip_type != AMDGPU_HW_IP_VCE) {
+	csc->request.fence_info.handle = cs->ctx->user_fence_bo;
+	csc->request.fence_info.offset = cs->base.ring_type;
+   }
+   r = amdgpu_cs_submit(cs->ctx->ctx, 0, &csc->request, 1);
    if (r) {
       fprintf(stderr, "amdgpu: The CS has been rejected, "
               "see dmesg for more information.\n");
@@ -553,7 +588,9 @@ void amdgpu_cs_emit_ioctl_oneshot(struct amdgpu_cs *cs, struct amdgpu_cs_context
       amdgpu_fence_signalled(csc->fence);
    } else {
       /* Success. */
-      amdgpu_fence_submitted(csc->fence, fence);
+      uint64_t *user_fence_cpu_address = cs->ctx->user_fence_cpu_address_base +
+				csc->request.fence_info.offset;
+      amdgpu_fence_submitted(csc->fence, &csc->request, user_fence_cpu_address);
 
       pipe_mutex_lock(ws->bo_fence_lock);
       for (i = 0; i < csc->num_buffers; i++)
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h
index 24a405b..931454a 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_cs.h
@@ -38,6 +38,8 @@
 struct amdgpu_ctx {
    struct amdgpu_winsys *ws;
    amdgpu_context_handle ctx;
+   amdgpu_bo_handle user_fence_bo;
+   uint64_t *user_fence_cpu_address_base;
    int refcount;
 };
 
@@ -104,6 +106,7 @@ struct amdgpu_fence {
 
    struct amdgpu_ctx *ctx;  /* submission context */
    uint64_t fence;          /* fence ID */
+   uint64_t * user_fence_cpu_address;
    unsigned ip_type;        /* which hw ip block the fence belongs to */
    unsigned ip_instance;    /* index of the HW ip block if there are more than 1 */
    unsigned ring;           /* ring index of the hw ip block */
@@ -118,6 +121,7 @@ static INLINE void amdgpu_ctx_unref(struct amdgpu_ctx *ctx)
 {
    if (p_atomic_dec_zero(&ctx->refcount)) {
       amdgpu_cs_ctx_free(ctx->ctx);
+      amdgpu_bo_free(ctx->user_fence_bo);
       FREE(ctx);
    }
 }
-- 
1.9.1


From bcb54aaaf119c7b28463c78318d7eba1da303caf Mon Sep 17 00:00:00 2001
From: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Date: Thu, 8 Sep 2016 15:52:35 -0400
Subject: [PATCH 0968/1722] drm/amd/dal: clean up surface programmming code

Change-Id: I1b97f7766de14d091393d3b9f9a7559a6c61794e
Signed-off-by: Dmytro Laktyushkin <Dmytro.Laktyushkin@amd.com>
Acked-by: Harry Wentland <harry.wentland@amd.com>
Signed-off-by: Kalyan Alle <kalyan.alle@amd.com>
---
 drivers/gpu/drm/amd/dal/dc/core/dc.c | 216 ++++++++++++++++++++---------------
 drivers/gpu/drm/amd/dal/dc/dc.h      |  10 +-
 2 files changed, 129 insertions(+), 97 deletions(-)

diff --git a/drivers/gpu/drm/amd/dal/dc/core/dc.c b/drivers/gpu/drm/amd/dal/dc/core/dc.c
index 30c8490..b9cec57 100644
--- a/drivers/gpu/drm/amd/dal/dc/core/dc.c
+++ b/drivers/gpu/drm/amd/dal/dc/core/dc.c
@@ -1014,7 +1014,7 @@ context_alloc_fail:
 	return (result == DC_OK);
 }
 
-bool dc_pre_commit_surfaces_to_target(
+bool dc_pre_update_surfaces_to_target(
 		struct dc *dc,
 		const struct dc_surface *const *new_surfaces,
 		uint8_t new_surface_count,
@@ -1167,19 +1167,53 @@ val_ctx_fail:
 	return ret;
 }
 
-bool dc_isr_commit_surfaces_to_target(
+bool dc_post_update_surfaces_to_target(struct dc *dc)
+{
+	struct core_dc *core_dc = DC_TO_CORE(dc);
+	int i;
+
+	for (i = 0; i < core_dc->current_context->res_ctx.pool->pipe_count; i++) {
+		if (core_dc->current_context->res_ctx.pipe_ctx[i].stream == NULL) {
+			core_dc->hwss.enable_display_power_gating(
+				core_dc, i, core_dc->ctx->dc_bios,
+				PIPE_GATING_CONTROL_ENABLE);
+			if (core_dc->current_context->res_ctx.pipe_ctx[i].xfm)
+				core_dc->current_context->res_ctx.pipe_ctx[i].xfm->funcs->transform_reset(
+						core_dc->current_context->res_ctx.pipe_ctx[i].xfm);
+			memset(&core_dc->current_context->res_ctx.pipe_ctx[i].scl_data, 0, sizeof(struct scaler_data));
+		}
+	}
+
+	if (core_dc->res_pool->funcs->validate_bandwidth(core_dc, core_dc->current_context)
+			!= DC_OK) {
+		BREAK_TO_DEBUGGER();
+		return false;
+	}
+
+	core_dc->hwss.set_bandwidth(core_dc);
+
+	pplib_apply_display_requirements(
+			core_dc, core_dc->current_context, &core_dc->current_context->pp_display_cfg);
+
+	return true;
+}
+
+bool dc_commit_surfaces_to_target(
 		struct dc *dc,
 		const struct dc_surface **new_surfaces,
-		int new_surface_count,
+		uint8_t new_surface_count,
 		struct dc_target *dc_target)
 {
 	int i, j;
 	struct core_dc *core_dc = DC_TO_CORE(dc);
-	struct validate_context *context = core_dc->temp_flip_context;
+	uint32_t prev_disp_clk = core_dc->current_context->bw_results.dispclk_khz;
 	struct core_target *target = DC_TARGET_TO_CORE(dc_target);
 	struct dc_target_status *target_status = NULL;
-	bool surface_needs_programming = false;
-	struct validate_context *tmp_ctx;
+	struct validate_context *context;
+	struct validate_context *temp_context;
+
+	int current_enabled_surface_count = 0;
+	int new_enabled_surface_count = 0;
 
 	if (core_dc->current_context->target_count == 0)
 		return false;
@@ -1188,86 +1222,111 @@ bool dc_isr_commit_surfaces_to_target(
 	for (i = 0; i < core_dc->current_context->target_count; i++)
 		if (target == core_dc->current_context->targets[i])
 			break;
+
 	if (i == core_dc->current_context->target_count)
 		return false;
 
 	target_status = &core_dc->current_context->target_status[i];
+	context = dm_alloc(sizeof(struct validate_context));
 
-	if (new_surface_count != target_status->surface_count)
-		surface_needs_programming = true;
-	else
-		for (i = 0; i < target_status->surface_count; i++) {
-			struct dc_surface temp_surf = { 0 };
-
-			temp_surf = *target_status->surfaces[i];
-			temp_surf.address = new_surfaces[i]->address;
+	if (!context) {
+		dm_error("%s: failed to create validate ctx\n", __func__);
+		goto val_ctx_fail;
+	}
 
-			if (memcmp(&temp_surf, new_surfaces[i], sizeof(temp_surf)) != 0) {
-				surface_needs_programming = true;
-				break;
-			}
-		}
+	resource_validate_ctx_copy_construct(core_dc->current_context, context);
 
-	*context = *core_dc->current_context;
-	for (i = 0; i < context->res_ctx.pool->pipe_count; i++) {
-		struct pipe_ctx *cur_pipe = &context->res_ctx.pipe_ctx[i];
+	for (i = 0; i < target_status->surface_count; i++)
+		if (target_status->surfaces[i]->visible)
+			current_enabled_surface_count++;
 
-		if (cur_pipe->top_pipe)
-			cur_pipe->top_pipe =
-				&context->res_ctx.pipe_ctx[cur_pipe->top_pipe->pipe_idx];
+	for (i = 0; i < new_surface_count; i++)
+		if (new_surfaces[i]->visible)
+			new_enabled_surface_count++;
 
-		if (cur_pipe->bottom_pipe)
-			cur_pipe->bottom_pipe =
-				&context->res_ctx.pipe_ctx[cur_pipe->bottom_pipe->pipe_idx];
-	}
+	dal_logger_write(core_dc->ctx->logger,
+				LOG_MAJOR_INTERFACE_TRACE,
+				LOG_MINOR_COMPONENT_DC,
+				"%s: commit %d surfaces to target 0x%x\n",
+				__func__,
+				new_surface_count,
+				dc_target);
 
 	if (!resource_attach_surfaces_to_context(
 			new_surfaces, new_surface_count, dc_target, context)) {
 		BREAK_TO_DEBUGGER();
-		return false;
+		goto unexpected_fail;
 	}
 
 	for (i = 0; i < new_surface_count; i++)
 		for (j = 0; j < context->res_ctx.pool->pipe_count; j++) {
-			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[j];
-			struct pipe_ctx *old_pipe_ctx = &core_dc->current_context->res_ctx.pipe_ctx[j];
-
-			if (pipe_ctx->surface !=
+			if (context->res_ctx.pipe_ctx[j].surface !=
 					DC_SURFACE_TO_CORE(new_surfaces[i]))
 				continue;
 
-			resource_build_scaling_params(new_surfaces[i], pipe_ctx);
+			resource_build_scaling_params(
+				new_surfaces[i], &context->res_ctx.pipe_ctx[j]);
 
 			if (dc->debug.surface_visual_confirm) {
-				pipe_ctx->scl_data.recout.height -= 2;
-				pipe_ctx->scl_data.recout.width -= 2;
+				context->res_ctx.pipe_ctx[j].scl_data.recout.height -= 2;
+				context->res_ctx.pipe_ctx[j].scl_data.recout.width -= 2;
 			}
+		}
 
-			if (memcmp(&pipe_ctx->scl_data,
-					&old_pipe_ctx->scl_data,
-					sizeof(pipe_ctx->scl_data)))
-				surface_needs_programming = true;
+	if (core_dc->res_pool->funcs->validate_bandwidth(core_dc, context) != DC_OK) {
+		BREAK_TO_DEBUGGER();
+		goto unexpected_fail;
+	}
+
+	if (core_dc->res_pool->funcs->apply_clk_constraints) {
+		temp_context = core_dc->res_pool->funcs->apply_clk_constraints(
+				core_dc,
+				context);
+		if (!temp_context) {
+			dm_error("%s:failed apply clk constraints\n", __func__);
+			BREAK_TO_DEBUGGER();
+			goto unexpected_fail;
 		}
+		resource_validate_ctx_destruct(context);
+		dm_free(context);
+		context = temp_context;
+	}
+
+	if (prev_disp_clk < context->bw_results.dispclk_khz) {
+		pplib_apply_display_requirements(core_dc, context,
+						&context->pp_display_cfg);
+		core_dc->hwss.set_display_clock(context);
+		core_dc->current_context->bw_results.dispclk_khz =
+				context->bw_results.dispclk_khz;
+	}
 
 	for (i = 0; i < new_surface_count; i++)
 		for (j = 0; j < context->res_ctx.pool->pipe_count; j++) {
-			struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[j];
-			struct pipe_ctx *old_pipe_ctx = &core_dc->current_context->res_ctx.pipe_ctx[j];
+			struct pipe_ctx *pipe_ctx =
+						&context->res_ctx.pipe_ctx[j];
 
-			if (pipe_ctx->surface !=
+			if (context->res_ctx.pipe_ctx[j].surface !=
 					DC_SURFACE_TO_CORE(new_surfaces[i]))
 				continue;
 
+			core_dc->hwss.prepare_pipe_for_context(
+					core_dc,
+					&context->res_ctx.pipe_ctx[j],
+					context);
+
 			core_dc->hwss.pipe_control_lock(
 					core_dc->ctx,
 					pipe_ctx->pipe_idx,
-					PIPE_LOCK_CONTROL_SURFACE,
+					PIPE_LOCK_CONTROL_GRAPHICS |
+					PIPE_LOCK_CONTROL_SCL |
+					PIPE_LOCK_CONTROL_BLENDER |
+					PIPE_LOCK_CONTROL_SURFACE |
+					PIPE_LOCK_CONTROL_MODE,
 					true);
 
 			core_dc->hwss.update_plane_addr(core_dc, pipe_ctx);
 
-			if (surface_needs_programming)
-				core_dc->hwss.apply_ctx_for_surface(
+			core_dc->hwss.apply_ctx_for_surface(
 						core_dc, pipe_ctx->surface, context);
 		}
 
@@ -1289,64 +1348,43 @@ bool dc_isr_commit_surfaces_to_target(
 				false);
 	}
 
-	core_dc->temp_flip_context = core_dc->current_context;
+	resource_validate_ctx_destruct(core_dc->current_context);
+	dm_free(core_dc->current_context);
 	core_dc->current_context = context;
 
-	return true;
-}
+	if (current_enabled_surface_count > 0 && new_enabled_surface_count == 0)
+		target_disable_memory_requests(dc_target,
+				&context->res_ctx);
 
-bool dc_post_commit_surfaces_to_target(struct dc *dc)
-{
-	struct core_dc *core_dc = DC_TO_CORE(dc);
-	int i;
 
-	for (i = 0; i < core_dc->current_context->res_ctx.pool->pipe_count; i++) {
-		if (core_dc->current_context->res_ctx.pipe_ctx[i].stream == NULL) {
+	for (i = 0; i < context->res_ctx.pool->pipe_count; i++) {
+		if (context->res_ctx.pipe_ctx[i].stream == NULL) {
 			core_dc->hwss.enable_display_power_gating(
 				core_dc, i, core_dc->ctx->dc_bios,
 				PIPE_GATING_CONTROL_ENABLE);
-			if (core_dc->current_context->res_ctx.pipe_ctx[i].xfm)
-				core_dc->current_context->res_ctx.pipe_ctx[i].xfm->funcs->transform_reset(
-						core_dc->current_context->res_ctx.pipe_ctx[i].xfm);
-			memset(&core_dc->current_context->res_ctx.pipe_ctx[i].scl_data, 0, sizeof(struct scaler_data));
+			if (context->res_ctx.pipe_ctx[i].xfm)
+				context->res_ctx.pipe_ctx[i].xfm->funcs->transform_reset(
+						context->res_ctx.pipe_ctx[i].xfm);
+			memset(&context->res_ctx.pipe_ctx[i].scl_data,
+					0, sizeof(struct scaler_data));
 		}
 	}
 
-	if (core_dc->res_pool->funcs->validate_bandwidth(core_dc, core_dc->current_context)
-			!= DC_OK) {
-		BREAK_TO_DEBUGGER();
-		return false;
-	}
-
 	core_dc->hwss.set_bandwidth(core_dc);
 
-	pplib_apply_display_requirements(
-			core_dc, core_dc->current_context, &core_dc->current_context->pp_display_cfg);
+	if (prev_disp_clk >= context->bw_results.dispclk_khz)
+		pplib_apply_display_requirements(
+			core_dc, context,
+			&context->pp_display_cfg);
 
 	return true;
-}
-
-bool dc_commit_surfaces_to_target(
-		struct dc *dc,
-		const struct dc_surface **new_surfaces,
-		uint8_t new_surface_count,
-		struct dc_target *dc_target)
-{
-	if (!dc_pre_commit_surfaces_to_target(
-			dc,
-			new_surfaces,
-			new_surface_count,
-			dc_target))
-		return false;
 
-	if (!dc_isr_commit_surfaces_to_target(dc, new_surfaces, new_surface_count, dc_target))
-		return false;
-
-	if (!dc_post_commit_surfaces_to_target(dc))
-		return false;
-
-	return true;
+unexpected_fail:
+	resource_validate_ctx_destruct(context);
+	dm_free(context);
+val_ctx_fail:
 
+	return false;
 }
 
 void dc_update_surfaces_for_target(struct dc *dc, struct dc_surface_update *updates,
diff --git a/drivers/gpu/drm/amd/dal/dc/dc.h b/drivers/gpu/drm/amd/dal/dc/dc.h
index 3fb2150..fba9ac0 100644
--- a/drivers/gpu/drm/amd/dal/dc/dc.h
+++ b/drivers/gpu/drm/amd/dal/dc/dc.h
@@ -268,19 +268,13 @@ bool dc_commit_surfaces_to_target(
 		uint8_t surface_count,
 		struct dc_target *dc_target);
 
-bool dc_pre_commit_surfaces_to_target(
+bool dc_pre_update_surfaces_to_target(
 		struct dc *dc,
 		const struct dc_surface *const *new_surfaces,
 		uint8_t new_surface_count,
 		struct dc_target *dc_target);
 
-bool dc_isr_commit_surfaces_to_target(
-		struct dc *dc,
-		const struct dc_surface **new_surfaces,
-		int new_surface_count,
-		struct dc_target *dc_target);
-
-bool dc_post_commit_surfaces_to_target(
+bool dc_post_update_surfaces_to_target(
 		struct dc *dc);
 
 void dc_update_surfaces_for_target(struct dc *dc, struct dc_surface_update *updates,
-- 
2.7.4


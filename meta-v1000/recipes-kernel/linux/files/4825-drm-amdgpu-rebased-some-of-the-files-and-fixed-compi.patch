From 231d6a19fdcd3c0950210e91d8aa794ce16044bd Mon Sep 17 00:00:00 2001
From: Pavan Kumar Ramayanam <pavan.ramayanam@amd.com>
Date: Tue, 8 May 2018 15:44:04 +0530
Subject: [PATCH 4825/5855] drm/amdgpu: rebased some of the files and fixed
 compilation errors Signed-off-by: Pavan Kumar Ramayanam
 <pavan.ramayanam@amd.com>

---
 Documentation/gpu/drm-uapi.rst                     |   6 +
 drivers/gpu/drm/Makefile                           |   3 +-
 drivers/gpu/drm/amd/amdgpu/Makefile                |  10 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c         |   6 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h         |   3 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gpuvm.c   | 123 +++--
 drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c             |   8 +
 drivers/gpu/drm/amd/amdgpu/amdgpu_debugfs.c        |  28 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c            |   6 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_ids.c            |  82 +--
 drivers/gpu/drm/amd/amdgpu/amdgpu_ids.h            |   7 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_job.c            |   2 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_kms.c            |   4 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_sync.c           |   2 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c            |   7 +-
 drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c             |   8 +-
 drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c              |  25 +-
 drivers/gpu/drm/amd/amdkfd/kfd_chardev.c           |   2 +-
 drivers/gpu/drm/amd/amdkfd/kfd_process.c           |   3 +-
 drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c  | 160 ++++--
 drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.h  |   4 -
 drivers/gpu/drm/amd/display/dc/calcs/bw_fixed.c    |   1 -
 drivers/gpu/drm/amd/display/dc/core/dc.c           |  16 +-
 drivers/gpu/drm/amd/display/dc/dc.h                |   2 +-
 .../gpu/drm/amd/display/dc/dce/dce_clock_source.c  |  84 ----
 drivers/gpu/drm/amd/display/dc/dce/dce_opp.c       | 237 ---------
 drivers/gpu/drm/amd/display/dc/dce/dce_opp.h       | 113 +----
 drivers/gpu/drm/amd/display/dc/dce/dce_transform.c | 202 +++++++-
 drivers/gpu/drm/amd/display/dc/dce/dce_transform.h |  92 +++-
 .../amd/display/dc/dce110/dce110_hw_sequencer.c    |  72 +--
 .../drm/amd/display/dc/dce112/dce112_resource.c    |  10 -
 .../drm/amd/display/dc/dce112/dce112_resource.h    |   5 -
 drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp.h   | 110 ++--
 .../gpu/drm/amd/display/dc/dcn10/dcn10_dpp_cm.c    | 552 +--------------------
 .../drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c  |  54 --
 .../gpu/drm/amd/display/dc/dcn10/dcn10_resource.c  |  30 +-
 drivers/gpu/drm/amd/display/dc/inc/clock_source.h  |   4 -
 drivers/gpu/drm/amd/include/kgd_kfd_interface.h    |   2 +-
 drivers/gpu/drm/amd/powerplay/hwmgr/vega10_hwmgr.c |  13 +-
 drivers/gpu/drm/drm_crtc.c                         |  34 +-
 drivers/gpu/drm/drm_debugfs.c                      |  34 +-
 drivers/gpu/drm/drm_debugfs_crc.c                  | 351 +++++++++++++
 drivers/gpu/drm/drm_internal.h                     |  16 +
 drivers/gpu/drm/radeon/radeon_kfd.c                |   6 +-
 drivers/gpu/drm/ttm/ttm_bo.c                       |  12 +-
 drivers/gpu/drm/ttm/ttm_page_alloc.c               |   2 +-
 drivers/gpu/drm/ttm/ttm_page_alloc_dma.c           |   2 +-
 include/drm/drm_crtc.h                             |  41 ++
 include/drm/drm_debugfs_crc.h                      |  73 +++
 include/drm/ttm/ttm_bo_driver.h                    |   2 +
 include/linux/kref.h                               |   5 +
 include/linux/reservation.h                        |  21 +
 include/uapi/drm/amdgpu_drm.h                      |  89 ++--
 53 files changed, 1324 insertions(+), 1462 deletions(-)
 mode change 100644 => 100755 drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gpuvm.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dce/dce_opp.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dce/dce_opp.h
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dce/dce_transform.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.h
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp.h
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp_cm.c
 mode change 100644 => 100755 drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c
 create mode 100644 drivers/gpu/drm/drm_debugfs_crc.c
 mode change 100644 => 100755 drivers/gpu/drm/ttm/ttm_bo.c
 create mode 100644 include/drm/drm_debugfs_crc.h
 mode change 100644 => 100755 include/linux/reservation.h
 mode change 100644 => 100755 include/uapi/drm/amdgpu_drm.h

diff --git a/Documentation/gpu/drm-uapi.rst b/Documentation/gpu/drm-uapi.rst
index 1ba301c..de3ac9f 100644
--- a/Documentation/gpu/drm-uapi.rst
+++ b/Documentation/gpu/drm-uapi.rst
@@ -216,3 +216,9 @@ interfaces. Especially since all hardware-acceleration interfaces to
 userspace are driver specific for efficiency and other reasons these
 interfaces can be rather substantial. Hence every driver has its own
 chapter.
+
+Testing and validation
+======================
+
+.. kernel-doc:: drivers/gpu/drm/drm_debugfs_crc.c
+   :doc: CRC ABI
diff --git a/drivers/gpu/drm/Makefile b/drivers/gpu/drm/Makefile
index c0b5838..6f74d60 100644
--- a/drivers/gpu/drm/Makefile
+++ b/drivers/gpu/drm/Makefile
@@ -9,7 +9,7 @@ drm-y       :=	drm_auth.o drm_bufs.o drm_cache.o \
 		drm_scatter.o drm_pci.o \
 		drm_platform.o drm_sysfs.o drm_hashtab.o drm_mm.o \
 		drm_crtc.o drm_fourcc.o drm_modes.o drm_edid.o \
-		drm_info.o drm_debugfs.o drm_encoder_slave.o \
+		drm_info.o drm_encoder_slave.o \
 		drm_trace_points.o drm_global.o drm_prime.o \
 		drm_rect.o drm_vma_manager.o drm_flip_work.o \
 		drm_modeset_lock.o drm_atomic.o drm_bridge.o \
@@ -24,6 +24,7 @@ drm-$(CONFIG_PCI) += ati_pcigart.o
 drm-$(CONFIG_DRM_PANEL) += drm_panel.o
 drm-$(CONFIG_OF) += drm_of.o
 drm-$(CONFIG_AGP) += drm_agpsupport.o
+drm-$(CONFIG_DEBUG_FS) += drm_debugfs.o drm_debugfs_crc.o
 
 drm_kms_helper-y := drm_crtc_helper.o drm_dp_helper.o drm_probe_helper.o \
 		drm_plane_helper.o drm_dp_mst_topology.o drm_atomic_helper.o \
diff --git a/drivers/gpu/drm/amd/amdgpu/Makefile b/drivers/gpu/drm/amd/amdgpu/Makefile
index 2fb8a89..f863aef 100644
--- a/drivers/gpu/drm/amd/amdgpu/Makefile
+++ b/drivers/gpu/drm/amd/amdgpu/Makefile
@@ -107,11 +107,11 @@ amdgpu-y += \
 
 # add amdkfd interfaces
 amdgpu-y += \
-	 amdgpu_amdkfd.o \
-	 amdgpu_amdkfd_gfx_v7.o \
-	 amdgpu_amdkfd_gfx_v8.o \
-	 amdgpu_amdkfd_gfx_v9.o \
-	 amdgpu_amdkfd_gpuvm.o 
+	amdgpu_amdkfd.o \
+	amdgpu_amdkfd_gfx_v7.o \
+	amdgpu_amdkfd_gfx_v8.o \
+	amdgpu_amdkfd_gfx_v9.o \
+	amdgpu_amdkfd_gpuvm.o 
 
 # add cgs
 amdgpu-y += amdgpu_cgs.o
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c
old mode 100644
new mode 100755
index 790ed6b..63ac46a
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c
@@ -99,8 +99,8 @@ void amdgpu_amdkfd_device_probe(struct amdgpu_device *adev)
 	case CHIP_VEGA10:
 	case CHIP_RAVEN:
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 16, 0)
-		if (adev->asic_type == CHIP_RAVEN) {
-			dev_dbg(adev->dev, "DKMS installed kfd does not support Raven for kernel < 4.16\n");
+		if (rdev->asic_type == CHIP_RAVEN) {
+			dev_dbg(rdev->dev, "DKMS installed kfd does not support Raven for kernel < 4.16\n");
 			return;
 		}
 #endif
@@ -348,7 +348,7 @@ int alloc_gtt_mem(struct kgd_dev *kgd, size_t size,
 	void *cpu_ptr_tmp = NULL;
 
 	r = amdgpu_bo_create(adev, size, PAGE_SIZE, true, AMDGPU_GEM_DOMAIN_GTT,
-				AMDGPU_GEM_CREATE_CPU_GTT_USWC, NULL, NULL, &bo);
+			AMDGPU_GEM_CREATE_CPU_GTT_USWC, NULL, NULL, &bo);
 	if (r) {
 		dev_err(adev->dev,
 			"failed to allocate BO for amdkfd (%d)\n", r);
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h
index 0650647..2ca271b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h
@@ -199,8 +199,7 @@ int amdgpu_amdkfd_gpuvm_sync_memory(
 int amdgpu_amdkfd_gpuvm_alloc_memory_of_gpu(
 		struct kgd_dev *kgd, uint64_t va, uint64_t size,
 		void *vm, struct kgd_mem **mem,
-		uint64_t *offset, void **kptr,
-		uint32_t flags);
+		uint64_t *offset, uint32_t flags);
 int amdgpu_amdkfd_gpuvm_free_memory_of_gpu(
 		struct kgd_dev *kgd, struct kgd_mem *mem, void *vm);
 int amdgpu_amdkfd_gpuvm_map_memory_to_gpu(
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gpuvm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gpuvm.c
old mode 100644
new mode 100755
index c2b4074..dbec057
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gpuvm.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gpuvm.c
@@ -433,17 +433,25 @@ static int amdgpu_amdkfd_validate(void *param, struct amdgpu_bo *bo)
 	return amdgpu_amdkfd_bo_validate(bo, p->domain, p->wait);
 }
 
-static int vm_validate_pt_pd_bos(struct amdgpu_vm *vm)
+/* vm_validate_pt_pd_bos - Validate page table and directory BOs
+ *
+ * Page directories are not updated here because huge page handling
+ * during page table updates can invalidate page directory entries
+ * again. Page directories are only updated after updating page
+ * tables.
+ */
+static int vm_validate_pt_pd_bos(struct amdkfd_vm *vm)
 {
-	struct amdgpu_bo *pd = vm->root.base.bo;
+	struct amdgpu_bo *pd = vm->base.root.base.bo;
 	struct amdgpu_device *adev = amdgpu_ttm_adev(pd->tbo.bdev);
 	struct amdgpu_vm_parser param;
+	uint64_t addr, flags = AMDGPU_PTE_VALID;
 	int ret;
 
 	param.domain = AMDGPU_GEM_DOMAIN_VRAM;
 	param.wait = false;
 
-	ret = amdgpu_vm_validate_pt_bos(adev, vm, amdgpu_amdkfd_validate,
+	ret = amdgpu_vm_validate_pt_bos(adev, &vm->base, amdgpu_amdkfd_validate,
 					&param);
 	if (ret) {
 		pr_err("amdgpu: failed to validate PT BOs\n");
@@ -558,44 +566,10 @@ static int init_user_pages(struct kgd_mem *mem, struct mm_struct *mm,
 	return ret;
 }
 
-static int __map_bo_to_kernel(struct amdgpu_bo *bo, u32 domain, void **kptr)
-{
-	int ret;
-
-	ret = amdgpu_bo_reserve(bo, true);
-	if (ret) {
-		pr_err("Failed to reserve bo. ret %d\n", ret);
-		return ret;
-	}
-
-	ret = amdgpu_bo_pin(bo, domain, NULL);
-	if (ret) {
-		pr_err("Failed to pin bo. ret %d\n", ret);
-		goto pin_failed;
-	}
-
-	ret = amdgpu_bo_kmap(bo, kptr);
-	if (ret) {
-		pr_err("Failed to map bo to kernel. ret %d\n", ret);
-		goto kmap_failed;
-	}
-
-	amdgpu_bo_unreserve(bo);
-
-	return ret;
-
-kmap_failed:
-	amdgpu_bo_unpin(bo);
-pin_failed:
-	amdgpu_bo_unreserve(bo);
-
-	return ret;
-}
-
 static int __alloc_memory_of_gpu(struct kgd_dev *kgd, uint64_t va,
 		uint64_t size, void *vm, struct kgd_mem **mem,
-		uint64_t *offset, void **kptr,
-		u32 domain, u64 flags, struct sg_table *sg, bool aql_queue,
+		uint64_t *offset, u32 domain, u64 flags,
+		struct sg_table *sg, bool aql_queue,
 		bool readonly, bool execute, bool coherent, bool no_sub,
 		bool userptr)
 {
@@ -676,12 +650,6 @@ static int __alloc_memory_of_gpu(struct kgd_dev *kgd, uint64_t va,
 	if (userptr)
 		bo->flags |= AMDGPU_AMDKFD_USERPTR_BO;
 
-	if (kptr) {
-		ret = __map_bo_to_kernel(bo, domain, kptr);
-		if (ret)
-			goto map_bo_to_kernel_failed;
-	}
-
 	(*mem)->va = va;
 	(*mem)->domain = domain;
 	(*mem)->mapped_to_gpu_memory = 0;
@@ -703,7 +671,6 @@ static int __alloc_memory_of_gpu(struct kgd_dev *kgd, uint64_t va,
 
 	return 0;
 
-map_bo_to_kernel_failed:
 allocate_init_user_pages_failed:
 	amdgpu_bo_unref(&bo);
 err_bo_create:
@@ -943,7 +910,7 @@ static int update_gpuvm_pte(struct amdgpu_device *adev,
 		return ret;
 	}
 
-	amdgpu_sync_fence(adev, sync, vm->last_update);
+	amdgpu_sync_fence(adev, sync, vm->last_update, false);
 
 	/* Update the page tables  */
 	ret = amdgpu_vm_bo_update(adev, bo_va, false);
@@ -1009,7 +976,7 @@ static int map_bo_to_gpuvm(struct amdgpu_device *adev,
 	/* PT BOs may be created during amdgpu_vm_bo_map() call,
 	 * so we have to validate the newly created PT BOs.
 	 */
-	ret = vm_validate_pt_pd_bos(entry->bo_va->base.vm);
+	ret = vm_validate_pt_pd_bos(kvm);
 	if (ret != 0) {
 		pr_err("validate_pt_pd_bos() failed\n");
 		return ret;
@@ -1076,8 +1043,7 @@ int amdgpu_amdkfd_gpuvm_sync_memory(
 int amdgpu_amdkfd_gpuvm_alloc_memory_of_gpu(
 		struct kgd_dev *kgd, uint64_t va, uint64_t size,
 		void *vm, struct kgd_mem **mem,
-		uint64_t *offset, void **kptr,
-		uint32_t flags)
+		uint64_t *offset, uint32_t flags)
 {
 	bool aql_queue, public, readonly, execute, coherent, no_sub, userptr;
 	u64 alloc_flag;
@@ -1100,11 +1066,6 @@ int amdgpu_amdkfd_gpuvm_alloc_memory_of_gpu(
 	no_sub    = (flags & ALLOC_MEM_FLAGS_NO_SUBSTITUTE) ? true : false;
 	userptr   = (flags & ALLOC_MEM_FLAGS_USERPTR) ? true : false;
 
-	if (userptr && kptr) {
-		pr_err("userptr can't be mapped to kernel\n");
-		return -EINVAL;
-	}
-
 	/*
 	 * Check on which domain to allocate BO
 	 */
@@ -1650,17 +1611,53 @@ int amdgpu_amdkfd_gpuvm_map_gtt_bo_to_kernel(struct kgd_dev *kgd,
 		struct kgd_mem *mem, void **kptr)
 {
 	int ret;
-	struct amdgpu_bo *bo;
+	struct amdgpu_bo *bo = mem->bo;
 
-	mutex_lock(&mem->lock);
+	if (amdgpu_ttm_tt_get_usermm(bo->tbo.ttm)) {
+		pr_err("userptr can't be mapped to kernel\n");
+		return -EINVAL;
+	}
 
-	bo = mem->bo;
+	/* delete kgd_mem from kfd_bo_list to avoid re-validating
+	 * this BO in BO's restoring after eviction.
+	 */
+	mutex_lock(&mem->process_info->lock);
 
-	ret = __map_bo_to_kernel(bo, AMDGPU_GEM_DOMAIN_GTT, kptr);
-	if (!ret)
-		mem->kptr = *kptr;
+	ret = amdgpu_bo_reserve(bo, true);
+	if (ret) {
+		pr_err("Failed to reserve bo. ret %d\n", ret);
+		goto bo_reserve_failed;
+	}
 
-	mutex_unlock(&mem->lock);
+	ret = amdgpu_bo_pin(bo, AMDGPU_GEM_DOMAIN_GTT, NULL);
+	if (ret) {
+		pr_err("Failed to pin bo. ret %d\n", ret);
+		goto pin_failed;
+	}
+
+	ret = amdgpu_bo_kmap(bo, kptr);
+	if (ret) {
+		pr_err("Failed to map bo to kernel. ret %d\n", ret);
+		goto kmap_failed;
+	}
+
+	amdgpu_amdkfd_remove_eviction_fence(
+		bo, mem->process_info->eviction_fence, NULL, NULL);
+	list_del_init(&mem->validate_list.head);
+
+	amdgpu_bo_unreserve(bo);
+
+	mem->kptr = *kptr;
+
+	mutex_unlock(&mem->process_info->lock);
+	return 0;
+
+kmap_failed:
+	amdgpu_bo_unpin(bo);
+pin_failed:
+	amdgpu_bo_unreserve(bo);
+bo_reserve_failed:
+	mutex_unlock(&mem->process_info->lock);
 
 	return ret;
 }
@@ -1897,7 +1894,7 @@ static int process_validate_vms(struct amdkfd_process_info *process_info)
 
 	list_for_each_entry(peer_vm, &process_info->vm_list_head,
 			    vm_list_node) {
-		ret = vm_validate_pt_pd_bos(&peer_vm->base);
+		ret = vm_validate_pt_pd_bos(peer_vm);
 		if (ret)
 			return ret;
 	}
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
index 97a3c51..0902729 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_cs.c
@@ -1391,7 +1391,15 @@ int amdgpu_cs_fence_to_handle_ioctl(struct drm_device *dev, void *data,
 		return -EINVAL;
 	}
 }
+#else
+int amdgpu_cs_fence_to_handle_ioctl(struct drm_device *dev, void *data,
+                                    struct drm_file *filp)
+{
+        DRM_ERROR("FENCE_TO_HANDLE ioctl is not supported for kernel < 4.13\n");
+        return -EINVAL;
+}
 #endif
+
 /**
  * amdgpu_cs_wait_all_fence - wait on all fences to signal
  *
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_debugfs.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_debugfs.c
index 07ae10f..a591220 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_debugfs.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_debugfs.c
@@ -88,7 +88,7 @@ void amdgpu_debugfs_cleanup(struct drm_minor *minor)
 static ssize_t amdgpu_debugfs_regs_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;;
 	ssize_t result = 0;
 	int r;
 	bool pm_pg_lock, use_bank;
@@ -164,7 +164,7 @@ static ssize_t amdgpu_debugfs_regs_read(struct file *f, char __user *buf,
 static ssize_t amdgpu_debugfs_regs_write(struct file *f, const char __user *buf,
 					 size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;;
 	ssize_t result = 0;
 	int r;
 	bool pm_pg_lock, use_bank;
@@ -238,7 +238,7 @@ static ssize_t amdgpu_debugfs_regs_write(struct file *f, const char __user *buf,
 static ssize_t amdgpu_debugfs_regs_pcie_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	ssize_t result = 0;
 	int r;
 
@@ -265,7 +265,7 @@ static ssize_t amdgpu_debugfs_regs_pcie_read(struct file *f, char __user *buf,
 static ssize_t amdgpu_debugfs_regs_pcie_write(struct file *f, const char __user *buf,
 					 size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	ssize_t result = 0;
 	int r;
 
@@ -293,7 +293,7 @@ static ssize_t amdgpu_debugfs_regs_pcie_write(struct file *f, const char __user
 static ssize_t amdgpu_debugfs_regs_didt_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	ssize_t result = 0;
 	int r;
 
@@ -320,7 +320,7 @@ static ssize_t amdgpu_debugfs_regs_didt_read(struct file *f, char __user *buf,
 static ssize_t amdgpu_debugfs_regs_didt_write(struct file *f, const char __user *buf,
 					 size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	ssize_t result = 0;
 	int r;
 
@@ -348,7 +348,7 @@ static ssize_t amdgpu_debugfs_regs_didt_write(struct file *f, const char __user
 static ssize_t amdgpu_debugfs_regs_smc_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	ssize_t result = 0;
 	int r;
 
@@ -375,7 +375,7 @@ static ssize_t amdgpu_debugfs_regs_smc_read(struct file *f, char __user *buf,
 static ssize_t amdgpu_debugfs_regs_smc_write(struct file *f, const char __user *buf,
 					 size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	ssize_t result = 0;
 	int r;
 
@@ -403,7 +403,7 @@ static ssize_t amdgpu_debugfs_regs_smc_write(struct file *f, const char __user *
 static ssize_t amdgpu_debugfs_gca_config_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	ssize_t result = 0;
 	int r;
 	uint32_t *config, no_regs = 0;
@@ -479,7 +479,7 @@ static ssize_t amdgpu_debugfs_gca_config_read(struct file *f, char __user *buf,
 static ssize_t amdgpu_debugfs_sensor_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	int idx, x, outsize, r, valuesize;
 	uint32_t values[16];
 
@@ -518,7 +518,7 @@ static ssize_t amdgpu_debugfs_sensor_read(struct file *f, char __user *buf,
 static ssize_t amdgpu_debugfs_wave_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	int r, x;
 	ssize_t result=0;
 	uint32_t offset, se, sh, cu, wave, simd, data[32];
@@ -568,7 +568,7 @@ static ssize_t amdgpu_debugfs_wave_read(struct file *f, char __user *buf,
 static ssize_t amdgpu_debugfs_gpr_read(struct file *f, char __user *buf,
 					size_t size, loff_t *pos)
 {
-	struct amdgpu_device *adev = (struct amdgpu_device *)kcl_file_private(f);
+	struct amdgpu_device *adev = file_inode(f)->i_private;
 	int r;
 	ssize_t result = 0;
 	uint32_t offset, se, sh, cu, wave, simd, thread, bank, *data;
@@ -746,7 +746,7 @@ static int amdgpu_debugfs_test_ib(struct seq_file *m, void *data)
 
 		if (!ring || !ring->sched.thread)
 			continue;
-		kcl_kthread_park(ring->sched.thread);
+		kthread_park(ring->sched.thread);
 	}
 
 	seq_printf(m, "run ib test:\n");
@@ -762,7 +762,7 @@ static int amdgpu_debugfs_test_ib(struct seq_file *m, void *data)
 
 		if (!ring || !ring->sched.thread)
 			continue;
-		kcl_kthread_unpark(ring->sched.thread);
+		kthread_unpark(ring->sched.thread);
 	}
 
 	return 0;
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c
index 17963e8..785e9c8 100755
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c
@@ -841,9 +841,9 @@ static struct drm_driver kms_driver = {
 	.driver_features =
 	    DRIVER_USE_AGP |
 	    DRIVER_HAVE_IRQ | DRIVER_IRQ_SHARED | DRIVER_GEM |
-	    DRIVER_PRIME | DRIVER_RENDER | DRIVER_MODESET | DRIVER_SYNCOBJ,
+	    DRIVER_PRIME | DRIVER_RENDER | DRIVER_MODESET,
 	.load = amdgpu_driver_load_kms,
-    .open = amdgpu_driver_open_kms,
+	.open = amdgpu_driver_open_kms,
 	.postclose = amdgpu_driver_postclose_kms,
 	.lastclose = amdgpu_driver_lastclose_kms,
 	.set_busid = drm_pci_set_busid,
@@ -852,7 +852,7 @@ static struct drm_driver kms_driver = {
 	.enable_vblank = amdgpu_enable_vblank_kms,
 	.disable_vblank = amdgpu_disable_vblank_kms,
 	.get_vblank_timestamp = amdgpu_get_vblank_timestamp_kms,
-	.get_scanout_position = amdgpu_get_crtc_scanoutpos,
+	.get_scanout_position = amdgpu_display_get_crtc_scanoutpos,
 #if defined(CONFIG_DEBUG_FS)
 #endif
 	.irq_handler = amdgpu_irq_handler,
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.c
index 6ecf8ad..4d54187 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.c
@@ -23,7 +23,7 @@
 #include "amdgpu_ids.h"
 
 #include <linux/idr.h>
-#include <linux/dma-fence-array.h>
+#include <linux/fence-array.h>
 #include <drm/drmP.h>
 
 #include "amdgpu.h"
@@ -46,7 +46,7 @@ static DEFINE_IDA2(amdgpu_vm_pasid_ida);
 
 /* Helper to free pasid from a fence callback */
 struct amdgpu_pasid_cb {
-	struct dma_fence_cb cb;
+	struct fence_cb cb;
 	unsigned int pasid;
 };
 
@@ -89,14 +89,14 @@ void amdgpu_pasid_free(unsigned int pasid)
 	ida_simple_remove(&amdgpu_vm_pasid_ida, pasid);
 }
 
-static void amdgpu_pasid_free_cb(struct dma_fence *fence,
-				 struct dma_fence_cb *_cb)
+static void amdgpu_pasid_free_cb(struct fence *fence,
+				 struct fence_cb *_cb)
 {
 	struct amdgpu_pasid_cb *cb =
 		container_of(_cb, struct amdgpu_pasid_cb, cb);
 
 	amdgpu_pasid_free(cb->pasid);
-	dma_fence_put(fence);
+	fence_put(fence);
 	kfree(cb);
 }
 
@@ -111,7 +111,7 @@ static void amdgpu_pasid_free_cb(struct dma_fence *fence,
 void amdgpu_pasid_free_delayed(struct reservation_object *resv,
 			       unsigned int pasid)
 {
-	struct dma_fence *fence, **fences;
+	struct fence *fence, **fences;
 	struct amdgpu_pasid_cb *cb;
 	unsigned count;
 	int r;
@@ -129,10 +129,10 @@ void amdgpu_pasid_free_delayed(struct reservation_object *resv,
 		fence = fences[0];
 		kfree(fences);
 	} else {
-		uint64_t context = dma_fence_context_alloc(1);
-		struct dma_fence_array *array;
+		uint64_t context = fence_context_alloc(1);
+		struct fence_array *array;
 
-		array = dma_fence_array_create(count, fences, context,
+		array = fence_array_create(count, fences, context,
 					       1, false);
 		if (!array) {
 			kfree(fences);
@@ -144,12 +144,12 @@ void amdgpu_pasid_free_delayed(struct reservation_object *resv,
 	cb = kmalloc(sizeof(*cb), GFP_KERNEL);
 	if (!cb) {
 		/* Last resort when we are OOM */
-		dma_fence_wait(fence, false);
-		dma_fence_put(fence);
+		fence_wait(fence, false);
+		fence_put(fence);
 		amdgpu_pasid_free(pasid);
 	} else {
 		cb->pasid = pasid;
-		if (dma_fence_add_callback(fence, &cb->cb,
+		if (fence_add_callback(fence, &cb->cb,
 					   amdgpu_pasid_free_cb))
 			amdgpu_pasid_free_cb(fence, &cb->cb);
 	}
@@ -190,7 +190,7 @@ bool amdgpu_vmid_had_gpu_reset(struct amdgpu_device *adev,
 static int amdgpu_vmid_grab_reserved_locked(struct amdgpu_vm *vm,
 					    struct amdgpu_ring *ring,
 					    struct amdgpu_sync *sync,
-					    struct dma_fence *fence,
+					    struct fence *fence,
 					    struct amdgpu_job *job)
 {
 	struct amdgpu_device *adev = ring->adev;
@@ -198,9 +198,9 @@ static int amdgpu_vmid_grab_reserved_locked(struct amdgpu_vm *vm,
 	uint64_t fence_context = adev->fence_context + ring->idx;
 	struct amdgpu_vmid *id = vm->reserved_vmid[vmhub];
 	struct amdgpu_vmid_mgr *id_mgr = &adev->vm_manager.id_mgr[vmhub];
-	struct dma_fence *updates = sync->last_vm_update;
+	struct fence *updates = sync->last_vm_update;
 	int r = 0;
-	struct dma_fence *flushed, *tmp;
+	struct fence *flushed, *tmp;
 	bool needs_flush = vm->use_cpu_for_update;
 
 	flushed  = id->flushed_updates;
@@ -208,9 +208,9 @@ static int amdgpu_vmid_grab_reserved_locked(struct amdgpu_vm *vm,
 	    (atomic64_read(&id->owner) != vm->entity.fence_context) ||
 	    (job->vm_pd_addr != id->pd_gpu_addr) ||
 	    (updates && (!flushed || updates->context != flushed->context ||
-			dma_fence_is_later(updates, flushed))) ||
+			fence_is_later(updates, flushed))) ||
 	    (!id->last_flush || (id->last_flush->context != fence_context &&
-				 !dma_fence_is_signaled(id->last_flush)))) {
+				 !fence_is_signaled(id->last_flush)))) {
 		needs_flush = true;
 		/* to prevent one context starved by another context */
 		id->pd_gpu_addr = 0;
@@ -229,15 +229,15 @@ static int amdgpu_vmid_grab_reserved_locked(struct amdgpu_vm *vm,
 		goto out;
 
 	if (updates && (!flushed || updates->context != flushed->context ||
-			dma_fence_is_later(updates, flushed))) {
-		dma_fence_put(id->flushed_updates);
-		id->flushed_updates = dma_fence_get(updates);
+			fence_is_later(updates, flushed))) {
+		fence_put(id->flushed_updates);
+		id->flushed_updates = fence_get(updates);
 	}
 	id->pd_gpu_addr = job->vm_pd_addr;
 	atomic64_set(&id->owner, vm->entity.fence_context);
 	job->vm_needs_flush = needs_flush;
 	if (needs_flush) {
-		dma_fence_put(id->last_flush);
+		fence_put(id->last_flush);
 		id->last_flush = NULL;
 	}
 	job->vmid = id - id_mgr->ids;
@@ -258,16 +258,16 @@ static int amdgpu_vmid_grab_reserved_locked(struct amdgpu_vm *vm,
  * Allocate an id for the vm, adding fences to the sync obj as necessary.
  */
 int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
-		     struct amdgpu_sync *sync, struct dma_fence *fence,
+		     struct amdgpu_sync *sync, struct fence *fence,
 		     struct amdgpu_job *job)
 {
 	struct amdgpu_device *adev = ring->adev;
 	unsigned vmhub = ring->funcs->vmhub;
 	struct amdgpu_vmid_mgr *id_mgr = &adev->vm_manager.id_mgr[vmhub];
 	uint64_t fence_context = adev->fence_context + ring->idx;
-	struct dma_fence *updates = sync->last_vm_update;
+	struct fence *updates = sync->last_vm_update;
 	struct amdgpu_vmid *id, *idle;
-	struct dma_fence **fences;
+	struct fence **fences;
 	unsigned i;
 	int r = 0;
 
@@ -295,17 +295,17 @@ int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
 	if (&idle->list == &id_mgr->ids_lru) {
 		u64 fence_context = adev->vm_manager.fence_context + ring->idx;
 		unsigned seqno = ++adev->vm_manager.seqno[ring->idx];
-		struct dma_fence_array *array;
+		struct fence_array *array;
 		unsigned j;
 
 		for (j = 0; j < i; ++j)
-			dma_fence_get(fences[j]);
+			fence_get(fences[j]);
 
-		array = dma_fence_array_create(i, fences, fence_context,
+		array = fence_array_create(i, fences, fence_context,
 					   seqno, true);
 		if (!array) {
 			for (j = 0; j < i; ++j)
-				dma_fence_put(fences[j]);
+				fence_put(fences[j]);
 			kfree(fences);
 			r = -ENOMEM;
 			goto error;
@@ -313,7 +313,7 @@ int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
 
 
 		r = amdgpu_sync_fence(ring->adev, sync, &array->base, false);
-		dma_fence_put(&array->base);
+		fence_put(&array->base);
 		if (r)
 			goto error;
 
@@ -326,7 +326,7 @@ int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
 	job->vm_needs_flush = vm->use_cpu_for_update;
 	/* Check if we can use a VMID already assigned to this VM */
 	list_for_each_entry_reverse(id, &id_mgr->ids_lru, list) {
-		struct dma_fence *flushed;
+		struct fence *flushed;
 		bool needs_flush = vm->use_cpu_for_update;
 
 		/* Check all the prerequisites to using this VMID */
@@ -341,11 +341,11 @@ int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
 
 		if (!id->last_flush ||
 		    (id->last_flush->context != fence_context &&
-		     !dma_fence_is_signaled(id->last_flush)))
+		     !fence_is_signaled(id->last_flush)))
 			needs_flush = true;
 
 		flushed  = id->flushed_updates;
-		if (updates && (!flushed || dma_fence_is_later(updates, flushed)))
+		if (updates && (!flushed || fence_is_later(updates, flushed)))
 			needs_flush = true;
 
 		/* Concurrent flushes are only possible starting with Vega10 */
@@ -359,9 +359,9 @@ int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
 		if (r)
 			goto error;
 
-		if (updates && (!flushed || dma_fence_is_later(updates, flushed))) {
-			dma_fence_put(id->flushed_updates);
-			id->flushed_updates = dma_fence_get(updates);
+		if (updates && (!flushed || fence_is_later(updates, flushed))) {
+			fence_put(id->flushed_updates);
+			id->flushed_updates = fence_get(updates);
 		}
 
 		if (needs_flush)
@@ -380,13 +380,13 @@ int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
 		goto error;
 
 	id->pd_gpu_addr = job->vm_pd_addr;
-	dma_fence_put(id->flushed_updates);
-	id->flushed_updates = dma_fence_get(updates);
+	fence_put(id->flushed_updates);
+	id->flushed_updates = fence_get(updates);
 	atomic64_set(&id->owner, vm->entity.fence_context);
 
 needs_flush:
 	job->vm_needs_flush = true;
-	dma_fence_put(id->last_flush);
+	fence_put(id->last_flush);
 	id->last_flush = NULL;
 
 no_flush_needed:
@@ -519,7 +519,7 @@ void amdgpu_vmid_mgr_init(struct amdgpu_device *adev)
 	}
 
 	adev->vm_manager.fence_context =
-		dma_fence_context_alloc(AMDGPU_MAX_RINGS);
+		fence_context_alloc(AMDGPU_MAX_RINGS);
 	for (i = 0; i < AMDGPU_MAX_RINGS; ++i)
 		adev->vm_manager.seqno[i] = 0;
 }
@@ -544,8 +544,8 @@ void amdgpu_vmid_mgr_fini(struct amdgpu_device *adev)
 			struct amdgpu_vmid *id = &id_mgr->ids[j];
 
 			amdgpu_sync_free(&id->active);
-			dma_fence_put(id->flushed_updates);
-			dma_fence_put(id->last_flush);
+			fence_put(id->flushed_updates);
+			fence_put(id->last_flush);
 		}
 	}
 }
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.h b/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.h
index 38f37c1..abe5dad 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.h
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ids.h
@@ -26,7 +26,6 @@
 #include <linux/types.h>
 #include <linux/mutex.h>
 #include <linux/list.h>
-#include <linux/dma-fence.h>
 
 #include "amdgpu_sync.h"
 
@@ -42,12 +41,12 @@ struct amdgpu_job;
 struct amdgpu_vmid {
 	struct list_head	list;
 	struct amdgpu_sync	active;
-	struct dma_fence	*last_flush;
+	struct fence	        *last_flush;
 	atomic64_t		owner;
 
 	uint64_t		pd_gpu_addr;
 	/* last flushed PD/PT update */
-	struct dma_fence	*flushed_updates;
+	struct fence	        *flushed_updates;
 
 	uint32_t                current_gpu_reset_count;
 
@@ -81,7 +80,7 @@ void amdgpu_vmid_free_reserved(struct amdgpu_device *adev,
 			       struct amdgpu_vm *vm,
 			       unsigned vmhub);
 int amdgpu_vmid_grab(struct amdgpu_vm *vm, struct amdgpu_ring *ring,
-		     struct amdgpu_sync *sync, struct dma_fence *fence,
+		     struct amdgpu_sync *sync, struct fence *fence1,
 		     struct amdgpu_job *job);
 void amdgpu_vmid_reset(struct amdgpu_device *adev, unsigned vmhub,
 		       unsigned vmid);
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c
index d30d848..b64f05b 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_job.c
@@ -150,7 +150,7 @@ static struct fence *amdgpu_job_dependency(struct amd_sched_job *sched_job,
 	bool explicit = false;
 	int r;
 
-	struct dma_fence *fence = amdgpu_sync_get_fence(&job->sync, &explicit);
+	struct fence *fence = amdgpu_sync_get_fence(&job->sync, &explicit);
 
 	if (fence && explicit) {
 		if (amd_sched_dependency_optimized(fence, s_entity)) {
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_kms.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_kms.c
index a32f87b..86cdfa4 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_kms.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_kms.c
@@ -1124,9 +1124,9 @@ int amdgpu_get_vblank_timestamp_kms(struct drm_device *dev, unsigned int pipe,
 	}
 
 	/* Helper routine in DRM core does all the work: */
-	return kcl_drm_calc_vbltimestamp_from_scanoutpos(dev, pipe, max_error,
+	return drm_calc_vbltimestamp_from_scanoutpos(dev, pipe, max_error,
 							 vblank_time, flags,
-							 crtc, &crtc->hwmode);
+							 &crtc->hwmode);
 }
 
 const struct drm_ioctl_desc amdgpu_ioctls_kms[] = {
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_sync.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_sync.c
index e37ac40..e5bf014 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_sync.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_sync.c
@@ -154,7 +154,7 @@ static bool amdgpu_sync_add_later(struct amdgpu_sync *sync, struct fence *f, boo
  *
  */
 int amdgpu_sync_fence(struct amdgpu_device *adev, struct amdgpu_sync *sync,
-		     struct dma_fence *f, bool explicit)
+		     struct fence *f, bool explicit)
 {
 	struct amdgpu_sync_entry *e;
 
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
index 9d7260e..18fd9d9 100755
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
@@ -724,7 +724,8 @@ static unsigned long amdgpu_ttm_io_mem_pfn(struct ttm_buffer_object *bo,
 			(offset >> PAGE_SHIFT);
 	}
 
-	return ttm_bo_default_io_mem_pfn(bo, page_offset);
+	return ((bo->mem.bus.base + bo->mem.bus.offset) >> PAGE_SHIFT)
+		+ page_offset;
 }
 
 /*
@@ -2298,9 +2299,9 @@ static int amdgpu_ttm_debugfs_init(struct amdgpu_device *adev)
                 if (IS_ERR(ent))
                         return PTR_ERR(ent);
                 if (ttm_debugfs_entries[count].domain == TTM_PL_VRAM)
-                        i_size_write(ent->d_inode, adev->mc.mc_vram_size);
+                        i_size_write(ent->d_inode, adev->gmc.mc_vram_size);
                 else if (ttm_debugfs_entries[count].domain == TTM_PL_TT)
-                        i_size_write(ent->d_inode, adev->mc.gart_size);
+                        i_size_write(ent->d_inode, adev->gmc.gart_size);
                 adev->mman.debugfs_entries[count] = ent;
         }
 
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
index ac9f3ad..40c0243 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
@@ -271,7 +271,7 @@ static int amdgpu_vm_clear_bo(struct amdgpu_device *adev,
 			      unsigned level, bool pte_support_ats)
 {
 	struct ttm_operation_ctx ctx = { true, false };
-	struct dma_fence *fence = NULL;
+	struct fence *fence = NULL;
 	unsigned entries, ats_entries;
 	struct amdgpu_ring *ring;
 	struct amdgpu_job *job;
@@ -335,7 +335,7 @@ static int amdgpu_vm_clear_bo(struct amdgpu_device *adev,
 		goto error_free;
 
 	amdgpu_bo_fence(bo, fence, true);
-	dma_fence_put(fence);
+	fence_put(fence);
 	return 0;
 
 error_free:
@@ -947,7 +947,7 @@ int amdgpu_vm_update_directories(struct amdgpu_device *adev,
 	} else {
 		struct amdgpu_bo *root = vm->root.base.bo;
 		struct amdgpu_ring *ring;
-		struct dma_fence *fence;
+		struct fence *fence;
 
 		ring = container_of(vm->entity.sched, struct amdgpu_ring,
 				    sched);
@@ -962,7 +962,7 @@ int amdgpu_vm_update_directories(struct amdgpu_device *adev,
 			goto error;
 
 		amdgpu_bo_fence(root, fence, true);
-		dma_fence_put(vm->last_update);
+		fence_put(vm->last_update);
 		vm->last_update = fence;
 	}
 
diff --git a/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c b/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c
old mode 100644
new mode 100755
index 1bd1c62..2834b40
--- a/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c
+++ b/drivers/gpu/drm/amd/amdgpu/gfx_v9_0.c
@@ -3798,10 +3798,10 @@ static void gfx_v9_0_hqd_set_priority(struct amdgpu_device *adev,
 }
 
 static void gfx_v9_0_ring_set_priority_compute(struct amdgpu_ring *ring,
-					       enum drm_sched_priority priority)
+					      enum amd_sched_priority priority)
 {
 	struct amdgpu_device *adev = ring->adev;
-	bool acquire = priority == DRM_SCHED_PRIORITY_HIGH_HW;
+	bool acquire = priority == AMD_SCHED_PRIORITY_HIGH_HW;
 
 	if (ring->funcs->type != AMDGPU_RING_TYPE_COMPUTE)
 		return;
@@ -3897,6 +3897,12 @@ static void gfx_v9_0_ring_emit_de_meta(struct amdgpu_ring *ring)
 	amdgpu_ring_write_multiple(ring, (void *)&de_payload, sizeof(de_payload) >> 2);
 }
 
+static void gfx_v9_0_ring_emit_tmz(struct amdgpu_ring *ring, bool start)
+{
+	amdgpu_ring_write(ring, PACKET3(PACKET3_FRAME_CONTROL, 0));
+	amdgpu_ring_write(ring, FRAME_CMD(start ? 0 : 1)); /* frame_end */
+}
+
 static void gfx_v9_ring_emit_cntxcntl(struct amdgpu_ring *ring, uint32_t flags)
 {
 	uint32_t dw2 = 0;
@@ -3904,6 +3910,8 @@ static void gfx_v9_ring_emit_cntxcntl(struct amdgpu_ring *ring, uint32_t flags)
 	if (amdgpu_sriov_vf(ring->adev))
 		gfx_v9_0_ring_emit_ce_meta(ring);
 
+	gfx_v9_0_ring_emit_tmz(ring, true);
+
 	dw2 |= 0x80000000; /* set load_enable otherwise this package is just NOPs */
 	if (flags & AMDGPU_HAVE_CTX_SWITCH) {
 		/* set load_global_config & load_global_uconfig */
@@ -3954,12 +3962,6 @@ static void gfx_v9_0_ring_emit_patch_cond_exec(struct amdgpu_ring *ring, unsigne
 		ring->ring[offset] = (ring->ring_size>>2) - offset + cur;
 }
 
-static void gfx_v9_0_ring_emit_tmz(struct amdgpu_ring *ring, bool start)
-{
-	amdgpu_ring_write(ring, PACKET3(PACKET3_FRAME_CONTROL, 0));
-	amdgpu_ring_write(ring, FRAME_CMD(start ? 0 : 1)); /* frame_end */
-}
-
 static void gfx_v9_0_ring_emit_rreg(struct amdgpu_ring *ring, uint32_t reg)
 {
 	struct amdgpu_device *adev = ring->adev;
@@ -4408,8 +4410,8 @@ static void gfx_v9_0_set_ring_funcs(struct amdgpu_device *adev)
 }
 
 static const struct amdgpu_irq_src_funcs gfx_v9_0_kiq_irq_funcs = {
-	.set = gfx_v9_0_kiq_set_interrupt_state,
-	.process = gfx_v9_0_kiq_irq,
+        .set = gfx_v9_0_kiq_set_interrupt_state,
+        .process = gfx_v9_0_kiq_irq,
 };
 
 static const struct amdgpu_irq_src_funcs gfx_v9_0_eop_irq_funcs = {
@@ -4440,9 +4442,6 @@ static void gfx_v9_0_set_irq_funcs(struct amdgpu_device *adev)
 
 	adev->gfx.kiq.irq.num_types = AMDGPU_CP_KIQ_IRQ_LAST;
 	adev->gfx.kiq.irq.funcs = &gfx_v9_0_kiq_irq_funcs;
-
-	adev->gfx.kiq.irq.num_types = AMDGPU_CP_KIQ_IRQ_LAST;
-	adev->gfx.kiq.irq.funcs = &gfx_v9_0_kiq_irq_funcs;
 }
 
 static void gfx_v9_0_set_rlc_funcs(struct amdgpu_device *adev)
diff --git a/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c b/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c
index 3dec240..0a90b16 100644
--- a/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c
+++ b/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c
@@ -1217,7 +1217,7 @@ static int kfd_ioctl_alloc_memory_of_gpu(struct file *filep,
 	err = dev->kfd2kgd->alloc_memory_of_gpu(
 		dev->kgd, args->va_addr, args->size,
 		pdd->vm, (struct kgd_mem **) &mem, &offset,
-		NULL, flags);
+		flags);
 
 	if (err != 0)
 		return err;
diff --git a/drivers/gpu/drm/amd/amdkfd/kfd_process.c b/drivers/gpu/drm/amd/amdkfd/kfd_process.c
index 78a5f7a..21f2428 100644
--- a/drivers/gpu/drm/amd/amdkfd/kfd_process.c
+++ b/drivers/gpu/drm/amd/amdkfd/kfd_process.c
@@ -102,8 +102,7 @@ static int kfd_process_alloc_gpuvm(struct kfd_process *p,
 
 	err = kdev->kfd2kgd->alloc_memory_of_gpu(kdev->kgd, gpu_va, size,
 				pdd->vm,
-				(struct kgd_mem **)&mem, NULL, kptr,
-				flags);
+				(struct kgd_mem **)&mem, NULL, flags);
 	if (err)
 		goto err_alloc_mem;
 
diff --git a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c
old mode 100644
new mode 100755
index 4b274bb..026a0a2
--- a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c
+++ b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c
@@ -116,6 +116,7 @@ static int amdgpu_dm_atomic_check(struct drm_device *dev,
 static void prepare_flip_isr(struct amdgpu_crtc *acrtc);
 
 
+
 static const enum drm_plane_type dm_plane_type_default[AMDGPU_MAX_PLANES] = {
 	DRM_PLANE_TYPE_PRIMARY,
 	DRM_PLANE_TYPE_PRIMARY,
@@ -284,7 +285,6 @@ static void dm_pflip_high_irq(void *interrupt_params)
 		return;
 	}
 
-
 	/* wakeup usersapce */
 	if (amdgpu_crtc->event) {
 		/* Update to correct count/ts if racing with vblank irq */
@@ -646,7 +646,7 @@ amdgpu_dm_find_first_crtc_matching_connector(struct drm_atomic_state *state,
 	struct drm_connector *connector;
 	struct drm_crtc *crtc_from_state;
 
-	for_each_new_connector_in_state(state, connector, new_con_state, i) {
+	for_each_connector_in_state(state, connector, new_con_state, i) {
 		crtc_from_state = from_state_var ? new_con_state->crtc :
 						connector->state->crtc;
 		if (crtc_from_state == crtc)
@@ -747,7 +747,7 @@ int amdgpu_dm_display_resume(struct amdgpu_device *adev )
 
 	ret = drm_atomic_helper_resume(ddev, adev->dm.cached_state);
 
-	drm_atomic_state_free(adev->dm.cached_state);
+
 
 	adev->dm.cached_state = NULL;
 
@@ -837,8 +837,9 @@ static struct drm_mode_config_helper_funcs amdgpu_dm_mode_config_helperfuncs = {
 	.atomic_commit_tail = amdgpu_dm_atomic_commit_tail
 };
 
-static void amdgpu_dm_update_connector_after_detect(
-	struct amdgpu_dm_connector *aconnector)
+
+static void
+amdgpu_dm_update_connector_after_detect(struct amdgpu_dm_connector *aconnector)
 {
 	struct drm_connector *connector = &aconnector->base;
 	struct drm_device *dev = connector->dev;
@@ -2475,6 +2476,81 @@ static void amdgpu_dm_crtc_destroy(struct drm_crtc *crtc)
 	kfree(crtc);
 }
 
+static int amdgpu_atomic_helper_page_flip(struct drm_crtc *crtc,
+				struct drm_framebuffer *fb,
+				struct drm_pending_vblank_event *event,
+				uint32_t flags)
+{
+	struct drm_plane *plane = crtc->primary;
+	struct amdgpu_crtc *acrtc = to_amdgpu_crtc(crtc);
+	struct drm_atomic_state *state;
+	struct drm_plane_state *plane_state;
+	struct drm_crtc_state *crtc_state;
+	int ret = 0;
+
+	state = drm_atomic_state_alloc(plane->dev);
+	if (!state)
+		return -ENOMEM;
+
+	state->acquire_ctx = drm_modeset_legacy_acquire_ctx(crtc);
+retry:
+	crtc_state = drm_atomic_get_crtc_state(state, crtc);
+	if (IS_ERR(crtc_state)) {
+		ret = PTR_ERR(crtc_state);
+		goto fail;
+	}
+	crtc_state->event = event;
+
+	plane_state = drm_atomic_get_plane_state(state, plane);
+	if (IS_ERR(plane_state)) {
+		ret = PTR_ERR(plane_state);
+		goto fail;
+	}
+
+	ret = drm_atomic_set_crtc_for_plane(plane_state, crtc);
+	if (ret != 0)
+		goto fail;
+	drm_atomic_set_fb_for_plane(plane_state, fb);
+
+	/* Make sure we don't accidentally do a full modeset. */
+	state->allow_modeset = false;
+	if (!crtc_state->active) {
+		DRM_DEBUG_ATOMIC("[CRTC:%d] disabled, rejecting legacy flip\n",
+				 crtc->base.id);
+		ret = -EINVAL;
+		goto fail;
+	}
+	acrtc->flip_flags = flags;
+
+
+
+	ret = drm_atomic_nonblocking_commit(state);
+
+	if (ret != 0)
+		goto fail;
+
+	/* Driver takes ownership of state on successful async commit. */
+	return 0;
+fail:
+	if (ret == -EDEADLK)
+		goto backoff;
+
+	drm_atomic_state_free(state);
+
+	return ret;
+backoff:
+	drm_atomic_state_clear(state);
+	drm_atomic_legacy_backoff(state);
+
+	/*
+	 * Someone might have exchanged the framebuffer while we dropped locks
+	 * in the backoff code. We need to fix up the fb refcount tracking the
+	 * core does for us.
+	 */
+	plane->old_fb = plane->fb;
+
+	goto retry;
+}
 static void dm_crtc_destroy_state(struct drm_crtc *crtc,
 					   struct drm_crtc_state *state)
 {
@@ -2518,6 +2594,8 @@ dm_crtc_duplicate_state(struct drm_crtc *crtc)
 		return NULL;
 
 	state = kzalloc(sizeof(*state), GFP_KERNEL);
+	if (!state)
+		return NULL;
 
 	__drm_atomic_helper_crtc_duplicate_state(crtc, &state->base);
 
@@ -2538,10 +2616,11 @@ static const struct drm_crtc_funcs amdgpu_dm_crtc_funcs = {
 	.gamma_set = drm_atomic_helper_legacy_gamma_set,
 	.set_config = drm_atomic_helper_set_config,
 	.set_property = drm_atomic_helper_crtc_set_property,
-	.page_flip = drm_atomic_helper_page_flip,
+	.page_flip = amdgpu_atomic_helper_page_flip,
+
 	.atomic_duplicate_state = dm_crtc_duplicate_state,
 	.atomic_destroy_state = dm_crtc_destroy_state,
-	.set_crc_source = amdgpu_dm_crtc_set_crc_source,
+
 };
 
 static enum drm_connector_status
@@ -2718,8 +2797,6 @@ void amdgpu_dm_connector_funcs_reset(struct drm_connector *connector)
 	kfree(state);
 
 	state = kzalloc(sizeof(*state), GFP_KERNEL);
-	if (!state)
-		return NULL;
 
 	if (state) {
 		state->scaling = RMX_OFF;
@@ -2998,6 +3075,11 @@ dm_drm_plane_duplicate_state(struct drm_plane *plane)
 
 	__drm_atomic_helper_plane_duplicate_state(plane, &dm_plane_state->base);
 
+	if (old_dm_plane_state->dc_state) {
+		dm_plane_state->dc_state = old_dm_plane_state->dc_state;
+		dc_plane_state_retain(dm_plane_state->dc_state);
+	}
+
 	return &dm_plane_state->base;
 }
 
@@ -3005,6 +3087,10 @@ void dm_drm_plane_destroy_state(struct drm_plane *plane,
 					   struct drm_plane_state *state)
 {
 	struct dm_plane_state *dm_plane_state = to_dm_plane_state(state);
+
+	if (dm_plane_state->dc_state)
+		dc_plane_state_release(dm_plane_state->dc_state);
+
 	drm_atomic_helper_plane_destroy_state(plane, state);
 }
 
@@ -4041,7 +4127,7 @@ static void amdgpu_dm_commit_planes(struct drm_atomic_state *state,
 	struct dc_plane_state *plane_states_constructed[MAX_SURFACES];
 	struct amdgpu_crtc *acrtc_attach = to_amdgpu_crtc(pcrtc);
 	struct drm_crtc_state *new_pcrtc_state =
-			drm_atomic_get_new_crtc_state_after_commit(state, pcrtc);
+			state->crtcs[drm_crtc_index(pcrtc)].ptr->state;
 	struct dm_crtc_state *acrtc_state = to_dm_crtc_state(new_pcrtc_state);
 	struct dm_atomic_state *dm_state = to_dm_atomic_state(state);
 	int planes_count = 0;
@@ -4064,7 +4150,7 @@ static void amdgpu_dm_commit_planes(struct drm_atomic_state *state,
 		if (!fb || !crtc || pcrtc != crtc)
 			continue;
 
-		new_crtc_state = drm_atomic_get_new_crtc_state_after_commit(state, crtc);
+		new_crtc_state = state->crtcs[drm_crtc_index(crtc)].ptr->state;
 		if (!new_crtc_state->active)
 			continue;
 
@@ -4138,6 +4224,19 @@ static void amdgpu_dm_commit_planes(struct drm_atomic_state *state,
 	}
 }
 
+/**
+ * amdgpu_dm_crtc_copy_transient_flags - copy mirrored flags from DRM to DC
+ * @crtc_state: the DRM CRTC state
+ * @stream_state: the DC stream state.
+ *
+ * Copy the mirrored transient state flags from DRM, to DC. It is used to bring
+ * a dc_stream_state's flags in sync with a drm_crtc_state's flags.
+ */
+static void amdgpu_dm_crtc_copy_transient_flags(struct drm_crtc_state *crtc_state,
+						struct dc_stream_state *stream_state)
+{
+	stream_state->mode_changed = crtc_state->mode_changed;
+}
 
 static int amdgpu_dm_atomic_commit(
 		struct drm_device *dev,
@@ -4416,24 +4515,6 @@ static void amdgpu_dm_atomic_commit_tail(
 		if (dm_new_crtc_state->stream)
 			amdgpu_dm_commit_planes(state, dev, dm, crtc, &wait_for_vblank);
 	}
-#if defined(OS_NAME_RHEL_6) || defined(OS_NAME_SLE_12_3)
-	else	// Temporary fix for pflip conflict between block and nonblock call
-		return -EBUSY;
-#endif
-
-/**
- * amdgpu_dm_crtc_copy_transient_flags - copy mirrored flags from DRM to DC
- * @crtc_state: the DRM CRTC state
- * @stream_state: the DC stream state.
- *
- * Copy the mirrored transient state flags from DRM, to DC. It is used to bring
- * a dc_stream_state's flags in sync with a drm_crtc_state's flags.
- */
-static void amdgpu_dm_crtc_copy_transient_flags(struct drm_crtc_state *crtc_state,
-						struct dc_stream_state *stream_state)
-{
-	stream_state->mode_changed = crtc_state->mode_changed;
-}
 
 	/*
 	 * send vblank event on all events not handled in flip and
@@ -4742,11 +4823,18 @@ static int dm_update_crtcs_state(
 				*lock_and_validation_needed = true;
 			}
 		}
+
+next_crtc:
 		/* Release extra reference */
 		if (new_stream)
 			dc_stream_release(new_stream);
 	}
 	return ret;
+
+fail:
+        if (new_stream)
+                dc_stream_release(new_stream);
+        return ret;
 }
 
 static int dm_update_planes_state(
@@ -4756,7 +4844,7 @@ static int dm_update_planes_state(
 		bool *lock_and_validation_needed)
 {
 	struct drm_crtc *new_plane_crtc, *old_plane_crtc;
-	struct drm_crtc_state *new_crtc_state, *old_crtc_state;
+	struct drm_crtc_state *old_crtc_state, *new_crtc_state;
 	struct drm_plane *plane;
 	struct drm_plane_state *old_plane_state, *new_plane_state;
 	struct dm_crtc_state *dm_new_crtc_state, *dm_old_crtc_state;
@@ -4787,10 +4875,8 @@ static int dm_update_planes_state(
 			if (!old_plane_crtc)
 				continue;
 
-			old_acrtc_state = to_dm_crtc_state(
-					state->crtcs[drm_crtc_index(old_plane_crtc)].ptr->state);
-
-			dm_old_crtc_state = old_acrtc_state;
+			old_crtc_state = state->crtcs[drm_crtc_index(old_plane_crtc)].ptr->state;
+			dm_old_crtc_state = to_dm_crtc_state(old_crtc_state);
 
 			if (!dm_old_crtc_state->stream)
 				continue;
@@ -4821,9 +4907,9 @@ static int dm_update_planes_state(
 				continue;
 
 			new_crtc_state = state->crtcs[drm_crtc_index(new_plane_crtc)].state;
-			new_acrtc_state = to_dm_crtc_state(new_crtc_state);
 
-			dm_new_crtc_state = new_acrtc_state;
+
+			dm_new_crtc_state = to_dm_crtc_state(new_crtc_state);
 
 			if (!dm_new_crtc_state->stream)
 				continue;
@@ -5116,7 +5202,7 @@ void amdgpu_dm_remove_sink_from_freesync_module(
 {
 	struct amdgpu_dm_connector *amdgpu_dm_connector =
 			to_amdgpu_dm_connector(connector);
-
+	struct dm_connector_state *dm_con_state;
 	struct drm_device *dev = connector->dev;
 	struct amdgpu_device *adev = dev->dev_private;
 
diff --git a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.h b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.h
index 05aaa8d..37e6d7f 100644
--- a/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.h
+++ b/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.h
@@ -72,10 +72,6 @@ struct irq_list_head {
 	struct work_struct work;
 };
 
-	/**
-	 * Caches device atomic state for suspend/resume
-	 */
-	struct drm_atomic_state *cached_state;
 #if defined(CONFIG_DRM_AMD_DC_FBC)
 struct dm_comressor_info {
 	void *cpu_addr;
diff --git a/drivers/gpu/drm/amd/display/dc/calcs/bw_fixed.c b/drivers/gpu/drm/amd/display/dc/calcs/bw_fixed.c
index 5807e7d..b7392e2 100644
--- a/drivers/gpu/drm/amd/display/dc/calcs/bw_fixed.c
+++ b/drivers/gpu/drm/amd/display/dc/calcs/bw_fixed.c
@@ -49,7 +49,6 @@ static uint64_t abs_i64(int64_t arg)
 struct bw_fixed bw_int_to_fixed_nonconst(int64_t value)
 {
 	struct bw_fixed res;
-	BUILD_BUG_ON(value > BW_FIXED_MAX_I32 || value < BW_FIXED_MIN_I32);
 	res.value = value << BW_FIXED_BITS_PER_FRACTIONAL_PART;
 	return res;
 }
diff --git a/drivers/gpu/drm/amd/display/dc/core/dc.c b/drivers/gpu/drm/amd/display/dc/core/dc.c
index 6bbc8092..b57a54d 100755
--- a/drivers/gpu/drm/amd/display/dc/core/dc.c
+++ b/drivers/gpu/drm/amd/display/dc/core/dc.c
@@ -1469,7 +1469,6 @@ void dc_flip_plane_addrs(
 		struct dc_flip_addrs flip_addrs[],
 		uint32_t count)
 {
-	struct dc *core_dc = dc;
 	int i, j;
 
 	for (i = 0; i < count; i++) {
@@ -1478,12 +1477,11 @@ void dc_flip_plane_addrs(
 		plane_state->address = flip_addrs[i].address;
 		plane_state->flip_immediate = flip_addrs[i].flip_immediate;
 
-		for (j = 0; j < core_dc->res_pool->pipe_count; j++) {
-			struct pipe_ctx *pipe_ctx = &core_dc->current_state->res_ctx.pipe_ctx[j];
-
+		for (j = 0; j < dc->res_pool->pipe_count; j++) {
+			struct pipe_ctx *pipe_ctx = &dc->current_state->res_ctx.pipe_ctx[j];
 			if (pipe_ctx->plane_state != plane_state)
 				continue;
-			core_dc->hwss.update_plane_addr(core_dc, pipe_ctx);
+			dc->hwss.update_plane_addr(dc, pipe_ctx);
 		}
 	}
 }		
@@ -1514,7 +1512,6 @@ void dc_set_power_state(
 	struct dc *dc,
 	enum dc_acpi_cm_power_state power_state)
 {
-	struct core_dc *core_dc = DC_TO_CORE(dc);
 	struct kref refcount;
 
 	switch (power_state) {
@@ -1543,13 +1540,6 @@ void dc_set_power_state(
 		break;
 	}
 
-#ifdef CONFIG_DRM_AMD_DC_DCN1_0
-	dm_free(dc->dcn_soc);
-	dc->dcn_soc = NULL;
-
-	dm_free(dc->dcn_ip);
-	dc->dcn_ip = NULL;
-#endif
 }
 
 void dc_resume(struct dc *dc)
diff --git a/drivers/gpu/drm/amd/display/dc/dc.h b/drivers/gpu/drm/amd/display/dc/dc.h
index 44f0f12..55812c9 100644
--- a/drivers/gpu/drm/amd/display/dc/dc.h
+++ b/drivers/gpu/drm/amd/display/dc/dc.h
@@ -464,7 +464,7 @@ struct dc_plane_state {
 
 	/* private to dc_surface.c */
 	enum dc_irq_source irq_source;
-        atomic_t ref_count;
+	struct kref refcount;
 };
 
 struct dc_plane_info {
diff --git a/drivers/gpu/drm/amd/display/dc/dce/dce_clock_source.c b/drivers/gpu/drm/amd/display/dc/dce/dce_clock_source.c
index d7d28b3..5036b67 100644
--- a/drivers/gpu/drm/amd/display/dc/dce/dce_clock_source.c
+++ b/drivers/gpu/drm/amd/display/dc/dce/dce_clock_source.c
@@ -34,7 +34,6 @@
 
 #include "dce_clock_source.h"
 
-#include "core_dc.h"
 #include "reg_helper.h"
 
 #define REG(reg)\
@@ -687,89 +686,6 @@ static uint32_t dce110_get_pix_rate_in_hz(
 	return pix_rate;
 }
 
-static uint32_t dce110_get_pll_pixel_rate_in_hz(
-	struct clock_source *cs,
-	struct pixel_clk_params *pix_clk_params,
-	struct pll_settings *pll_settings)
-{
-	uint32_t inst = pix_clk_params->controller_id - CONTROLLER_ID_D0;
-	struct core_dc *dc_core = DC_TO_CORE(cs->ctx->dc);
-	struct validate_context *context = dc_core->current_context;
-	struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[inst];
-
-	/* This function need separate to different DCE version, before separate, just use pixel clock */
-	return pipe_ctx->stream->phy_pix_clk;
-}
-
-static uint32_t dce110_get_dp_pixel_rate_from_combo_phy_pll(
-	struct clock_source *cs,
-	struct pixel_clk_params *pix_clk_params,
-	struct pll_settings *pll_settings)
-{
-	uint32_t inst = pix_clk_params->controller_id - CONTROLLER_ID_D0;
-	struct core_dc *dc_core = DC_TO_CORE(cs->ctx->dc);
-	struct validate_context *context = dc_core->current_context;
-	struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[inst];
-
-	/* This function need separate to different DCE version, before separate, just use pixel clock */
-	return pipe_ctx->stream->phy_pix_clk;
-}
-
-static uint32_t dce110_get_d_to_pixel_rate_in_hz(
-	struct clock_source *cs,
-	struct pixel_clk_params *pix_clk_params,
-	struct pll_settings *pll_settings)
-{
-	uint32_t inst = pix_clk_params->controller_id - CONTROLLER_ID_D0;
-	struct dce110_clk_src *clk_src = TO_DCE110_CLK_SRC(cs);
-	int dto_enabled = 0;
-	struct fixed31_32 pix_rate;
-
-	REG_GET(PIXEL_RATE_CNTL[inst], DP_DTO0_ENABLE, &dto_enabled);
-
-	if (dto_enabled) {
-		uint32_t phase = 0;
-		uint32_t modulo = 0;
-		REG_GET(PHASE[inst], DP_DTO0_PHASE, &phase);
-		REG_GET(MODULO[inst], DP_DTO0_MODULO, &modulo);
-
-		if (modulo == 0) {
-			return 0;
-		}
-
-		pix_rate = dal_fixed31_32_from_int(clk_src->ref_freq_khz);
-		pix_rate = dal_fixed31_32_mul_int(pix_rate, 1000);
-		pix_rate = dal_fixed31_32_mul_int(pix_rate, phase);
-		pix_rate = dal_fixed31_32_div_int(pix_rate, modulo);
-
-		return dal_fixed31_32_round(pix_rate);
-	} else {
-		return dce110_get_dp_pixel_rate_from_combo_phy_pll(cs, pix_clk_params, pll_settings);
-	}
-}
-
-static uint32_t dce110_get_pix_rate_in_hz(
-	struct clock_source *cs,
-	struct pixel_clk_params *pix_clk_params,
-	struct pll_settings *pll_settings)
-{
-	uint32_t pix_rate = 0;
-	switch (pix_clk_params->signal_type) {
-	case	SIGNAL_TYPE_DISPLAY_PORT:
-	case	SIGNAL_TYPE_DISPLAY_PORT_MST:
-	case	SIGNAL_TYPE_EDP:
-	case	SIGNAL_TYPE_VIRTUAL:
-		pix_rate = dce110_get_d_to_pixel_rate_in_hz(cs, pix_clk_params, pll_settings);
-		break;
-	case	SIGNAL_TYPE_HDMI_TYPE_A:
-	default:
-		pix_rate = dce110_get_pll_pixel_rate_in_hz(cs, pix_clk_params, pll_settings);
-		break;
-	}
-
-	return pix_rate;
-}
-
 static bool disable_spread_spectrum(struct dce110_clk_src *clk_src)
 {
 	enum bp_result result;
diff --git a/drivers/gpu/drm/amd/display/dc/dce/dce_opp.c b/drivers/gpu/drm/amd/display/dc/dce/dce_opp.c
old mode 100644
new mode 100755
index ed27898..3931412
--- a/drivers/gpu/drm/amd/display/dc/dce/dce_opp.c
+++ b/drivers/gpu/drm/amd/display/dc/dce/dce_opp.c
@@ -92,242 +92,8 @@ enum {
  *
  *****************************************************************************
  */
-static void regamma_config_regions_and_segments(
-	struct dce110_opp *opp110,
-	const struct pwl_params *params)
-{
-	const struct gamma_curve *curve;
-
-	{
-		REG_SET_2(REGAMMA_CNTLA_START_CNTL, 0,
-			REGAMMA_CNTLA_EXP_REGION_START, params->arr_points[0].custom_float_x,
-			REGAMMA_CNTLA_EXP_REGION_START_SEGMENT, 0);
-	}
-	{
-		REG_SET(REGAMMA_CNTLA_SLOPE_CNTL, 0,
-			REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE, params->arr_points[0].custom_float_slope);
-
-	}
-	{
-		REG_SET(REGAMMA_CNTLA_END_CNTL1, 0,
-			REGAMMA_CNTLA_EXP_REGION_END, params->arr_points[1].custom_float_x);
-	}
-	{
-		REG_SET_2(REGAMMA_CNTLA_END_CNTL2, 0,
-			REGAMMA_CNTLA_EXP_REGION_END_BASE, params->arr_points[1].custom_float_y,
-			REGAMMA_CNTLA_EXP_REGION_END_SLOPE, params->arr_points[2].custom_float_slope);
-	}
-
-	curve = params->arr_curve_points;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_0_1, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-	}
-
-	curve += 2;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_2_3, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	}
-
-	curve += 2;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_4_5, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	}
-
-	curve += 2;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_6_7, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	}
-
-	curve += 2;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_8_9, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	}
-
-	curve += 2;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_10_11, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	}
-
-	curve += 2;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_12_13, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	}
-
-	curve += 2;
-
-	{
-		REG_SET_4(REGAMMA_CNTLA_REGION_14_15, 0,
-			REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-			REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-			REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-			REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-	}
-}
-
-static void program_pwl(
-	struct dce110_opp *opp110,
-	const struct pwl_params *params)
-{
-	uint32_t value;
-	int retval;
-
-	{
-		uint8_t max_tries = 10;
-		uint8_t counter = 0;
-
-		/* Power on LUT memory */
-		if (REG(DCFE_MEM_PWR_CTRL))
-			REG_UPDATE(DCFE_MEM_PWR_CTRL,
-				DCP_REGAMMA_MEM_PWR_DIS, 1);
-		else
-			REG_UPDATE(DCFE_MEM_LIGHT_SLEEP_CNTL,
-				REGAMMA_LUT_LIGHT_SLEEP_DIS, 1);
-
-		while (counter < max_tries) {
-			if (REG(DCFE_MEM_PWR_STATUS)) {
-				value = REG_READ(DCFE_MEM_PWR_STATUS);
-				REG_GET(DCFE_MEM_PWR_STATUS,
-						DCP_REGAMMA_MEM_PWR_STATE,
-						&retval);
-
-				if (retval == 0)
-						break;
-				++counter;
-			} else {
-				value = REG_READ(DCFE_MEM_LIGHT_SLEEP_CNTL);
-				REG_GET(DCFE_MEM_LIGHT_SLEEP_CNTL,
-						REGAMMA_LUT_MEM_PWR_STATE,
-						&retval);
-
-				if (retval == 0)
-						break;
-				++counter;
-			}
-		}
-
-		if (counter == max_tries) {
-			dm_logger_write(opp110->base.ctx->logger, LOG_WARNING,
-				"%s: regamma lut was not powered on "
-				"in a timely manner,"
-				" programming still proceeds\n",
-				__func__);
-		}
-	}
-
-	REG_UPDATE(REGAMMA_LUT_WRITE_EN_MASK,
-			REGAMMA_LUT_WRITE_EN_MASK, 7);
-
-	REG_WRITE(REGAMMA_LUT_INDEX, 0);
-
-	/* Program REGAMMA_LUT_DATA */
-	{
-		uint32_t i = 0;
-		const struct pwl_result_data *rgb = params->rgb_resulted;
-
-		while (i != params->hw_points_num) {
-
-			REG_WRITE(REGAMMA_LUT_DATA, rgb->red_reg);
-			REG_WRITE(REGAMMA_LUT_DATA, rgb->green_reg);
-			REG_WRITE(REGAMMA_LUT_DATA, rgb->blue_reg);
-			REG_WRITE(REGAMMA_LUT_DATA, rgb->delta_red_reg);
-			REG_WRITE(REGAMMA_LUT_DATA, rgb->delta_green_reg);
-			REG_WRITE(REGAMMA_LUT_DATA, rgb->delta_blue_reg);
-
-			++rgb;
-			++i;
-		}
-	}
-
-	/*  we are done with DCP LUT memory; re-enable low power mode */
-	if (REG(DCFE_MEM_PWR_CTRL))
-		REG_UPDATE(DCFE_MEM_PWR_CTRL,
-			DCP_REGAMMA_MEM_PWR_DIS, 0);
-	else
-		REG_UPDATE(DCFE_MEM_LIGHT_SLEEP_CNTL,
-			REGAMMA_LUT_LIGHT_SLEEP_DIS, 0);
-}
 
-bool dce110_opp_program_regamma_pwl(
-	struct output_pixel_processor *opp,
-	const struct pwl_params *params)
-{
-	struct dce110_opp *opp110 = TO_DCE110_OPP(opp);
-
-	/* Setup regions */
-	regamma_config_regions_and_segments(opp110, params);
-
-	/* Program PWL */
-	program_pwl(opp110, params);
 
-	return true;
-}
-
-void dce110_opp_power_on_regamma_lut(
-	struct output_pixel_processor *opp,
-	bool power_on)
-{
-	struct dce110_opp *opp110 = TO_DCE110_OPP(opp);
-
-	if (REG(DCFE_MEM_PWR_CTRL))
-		REG_UPDATE_2(DCFE_MEM_PWR_CTRL,
-			DCP_REGAMMA_MEM_PWR_DIS, power_on,
-			DCP_LUT_MEM_PWR_DIS, power_on);
-	else
-		REG_UPDATE_2(DCFE_MEM_LIGHT_SLEEP_CNTL,
-			REGAMMA_LUT_LIGHT_SLEEP_DIS, power_on,
-			DCP_LUT_LIGHT_SLEEP_DIS, power_on);
-
-}
-
-void dce110_opp_set_regamma_mode(struct output_pixel_processor *opp,
-		enum opp_regamma mode)
-{
-	struct dce110_opp *opp110 = TO_DCE110_OPP(opp);
-
-	REG_SET(REGAMMA_CONTROL, 0,
-			GRPH_REGAMMA_MODE, mode);
-}
 
 /**
  *	set_truncation
@@ -768,10 +534,7 @@ void dce110_opp_program_fmt(
 /*****************************************/
 
 static const struct opp_funcs funcs = {
-	.opp_power_on_regamma_lut = dce110_opp_power_on_regamma_lut,
 	.opp_set_dyn_expansion = dce110_opp_set_dyn_expansion,
-	.opp_program_regamma_pwl = dce110_opp_program_regamma_pwl,
-	.opp_set_regamma_mode = dce110_opp_set_regamma_mode,
 	.opp_destroy = dce110_opp_destroy,
 	.opp_program_fmt = dce110_opp_program_fmt,
 	.opp_program_bit_depth_reduction = dce110_opp_program_bit_depth_reduction
diff --git a/drivers/gpu/drm/amd/display/dc/dce/dce_opp.h b/drivers/gpu/drm/amd/display/dc/dce/dce_opp.h
old mode 100644
new mode 100755
index 4516574..2ab0147
--- a/drivers/gpu/drm/amd/display/dc/dce/dce_opp.h
+++ b/drivers/gpu/drm/amd/display/dc/dce/dce_opp.h
@@ -41,22 +41,6 @@ enum dce110_opp_reg_type {
 };
 
 #define OPP_COMMON_REG_LIST_BASE(id) \
-	SRI(REGAMMA_CNTLA_START_CNTL, DCP, id), \
-	SRI(REGAMMA_CNTLA_SLOPE_CNTL, DCP, id), \
-	SRI(REGAMMA_CNTLA_END_CNTL1, DCP, id), \
-	SRI(REGAMMA_CNTLA_END_CNTL2, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_0_1, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_2_3, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_4_5, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_6_7, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_8_9, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_10_11, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_12_13, DCP, id), \
-	SRI(REGAMMA_CNTLA_REGION_14_15, DCP, id), \
-	SRI(REGAMMA_LUT_WRITE_EN_MASK, DCP, id), \
-	SRI(REGAMMA_LUT_INDEX, DCP, id), \
-	SRI(REGAMMA_LUT_DATA, DCP, id), \
-	SRI(REGAMMA_CONTROL, DCP, id), \
 	SRI(FMT_DYNAMIC_EXP_CNTL, FMT, id), \
 	SRI(FMT_BIT_DEPTH_CONTROL, FMT, id), \
 	SRI(FMT_CONTROL, FMT, id), \
@@ -70,31 +54,24 @@ enum dce110_opp_reg_type {
 
 #define OPP_DCE_80_REG_LIST(id) \
 	OPP_COMMON_REG_LIST_BASE(id), \
-	SRI(DCFE_MEM_LIGHT_SLEEP_CNTL, CRTC, id), \
 	SRI(FMT_TEMPORAL_DITHER_PATTERN_CONTROL, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_S_MATRIX, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_T_MATRIX, FMT, id)
 
 #define OPP_DCE_100_REG_LIST(id) \
 	OPP_COMMON_REG_LIST_BASE(id), \
-	SRI(DCFE_MEM_PWR_CTRL, CRTC, id), \
-	SRI(DCFE_MEM_PWR_STATUS, CRTC, id), \
 	SRI(FMT_TEMPORAL_DITHER_PATTERN_CONTROL, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_S_MATRIX, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_T_MATRIX, FMT, id)
 
 #define OPP_DCE_110_REG_LIST(id) \
 	OPP_COMMON_REG_LIST_BASE(id), \
-	SRI(DCFE_MEM_PWR_CTRL, DCFE, id), \
-	SRI(DCFE_MEM_PWR_STATUS, DCFE, id), \
 	SRI(FMT_TEMPORAL_DITHER_PATTERN_CONTROL, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_S_MATRIX, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_T_MATRIX, FMT, id)
 
 #define OPP_DCE_112_REG_LIST(id) \
 	OPP_COMMON_REG_LIST_BASE(id), \
-	SRI(DCFE_MEM_PWR_CTRL, DCFE, id), \
-	SRI(DCFE_MEM_PWR_STATUS, DCFE, id), \
 	SRI(FMT_TEMPORAL_DITHER_PATTERN_CONTROL, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_S_MATRIX, FMT, id), \
 	SRI(FMT_TEMPORAL_DITHER_PROGRAMMABLE_PATTERN_T_MATRIX, FMT, id), \
@@ -102,26 +79,12 @@ enum dce110_opp_reg_type {
 
 #define OPP_DCE_120_REG_LIST(id) \
 	OPP_COMMON_REG_LIST_BASE(id), \
-	SRI(DCFE_MEM_PWR_CTRL, DCFE, id), \
-	SRI(DCFE_MEM_PWR_STATUS, DCFE, id), \
 	SRI(CONTROL, FMT_MEMORY, id)
 
 #define OPP_SF(reg_name, field_name, post_fix)\
 	.field_name = reg_name ## __ ## field_name ## post_fix
 
 #define OPP_COMMON_MASK_SH_LIST_DCE_COMMON_BASE(mask_sh)\
-	OPP_SF(REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START_SEGMENT, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_SLOPE_CNTL, REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_END_CNTL1, REGAMMA_CNTLA_EXP_REGION_END, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_BASE, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_SLOPE, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, mask_sh),\
-	OPP_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, mask_sh),\
-	OPP_SF(REGAMMA_LUT_WRITE_EN_MASK, REGAMMA_LUT_WRITE_EN_MASK, mask_sh),\
-	OPP_SF(REGAMMA_CONTROL, GRPH_REGAMMA_MODE, mask_sh),\
 	OPP_SF(FMT_DYNAMIC_EXP_CNTL, FMT_DYNAMIC_EXP_EN, mask_sh),\
 	OPP_SF(FMT_DYNAMIC_EXP_CNTL, FMT_DYNAMIC_EXP_MODE, mask_sh),\
 	OPP_SF(FMT_BIT_DEPTH_CONTROL, FMT_TRUNCATE_EN, mask_sh),\
@@ -160,27 +123,18 @@ enum dce110_opp_reg_type {
 
 #define OPP_COMMON_MASK_SH_LIST_DCE_110(mask_sh)\
 	OPP_COMMON_MASK_SH_LIST_DCE_COMMON_BASE(mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_CTRL, DCP_REGAMMA_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_CTRL, DCP_LUT_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_STATUS, DCP_REGAMMA_MEM_PWR_STATE, mask_sh),\
 	OPP_SF(FMT_CONTROL, FMT_SPATIAL_DITHER_FRAME_COUNTER_MAX, mask_sh),\
 	OPP_SF(FMT_CONTROL, FMT_SPATIAL_DITHER_FRAME_COUNTER_BIT_SWAP, mask_sh),\
 	OPP_SF(FMT_CONTROL, FMT_STEREOSYNC_OVERRIDE, mask_sh)
 
 #define OPP_COMMON_MASK_SH_LIST_DCE_100(mask_sh)\
 	OPP_COMMON_MASK_SH_LIST_DCE_COMMON_BASE(mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_CTRL, DCP_REGAMMA_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_CTRL, DCP_LUT_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_STATUS, DCP_REGAMMA_MEM_PWR_STATE, mask_sh),\
 	OPP_SF(FMT_CONTROL, FMT_SPATIAL_DITHER_FRAME_COUNTER_MAX, mask_sh),\
 	OPP_SF(FMT_CONTROL, FMT_SPATIAL_DITHER_FRAME_COUNTER_BIT_SWAP, mask_sh),\
 	OPP_SF(FMT_CONTROL, FMT_STEREOSYNC_OVERRIDE, mask_sh)
 
 #define OPP_COMMON_MASK_SH_LIST_DCE_112(mask_sh)\
 	OPP_COMMON_MASK_SH_LIST_DCE_COMMON_BASE(mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_CTRL, DCP_REGAMMA_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_CTRL, DCP_LUT_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_PWR_STATUS, DCP_REGAMMA_MEM_PWR_STATE, mask_sh),\
 	OPP_SF(FMT_MEMORY0_CONTROL, FMT420_MEM0_SOURCE_SEL, mask_sh),\
 	OPP_SF(FMT_MEMORY0_CONTROL, FMT420_MEM0_PWR_FORCE, mask_sh),\
 	OPP_SF(FMT_CONTROL, FMT_420_PIXEL_PHASE_LOCKED_CLEAR, mask_sh),\
@@ -191,27 +145,9 @@ enum dce110_opp_reg_type {
 	OPP_SF(FMT_CONTROL, FMT_STEREOSYNC_OVERRIDE, mask_sh)
 
 #define OPP_COMMON_MASK_SH_LIST_DCE_80(mask_sh)\
-	OPP_COMMON_MASK_SH_LIST_DCE_COMMON_BASE(mask_sh),\
-	OPP_SF(DCFE_MEM_LIGHT_SLEEP_CNTL, REGAMMA_LUT_LIGHT_SLEEP_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_LIGHT_SLEEP_CNTL, DCP_LUT_LIGHT_SLEEP_DIS, mask_sh),\
-	OPP_SF(DCFE_MEM_LIGHT_SLEEP_CNTL, REGAMMA_LUT_MEM_PWR_STATE, mask_sh)
+	OPP_COMMON_MASK_SH_LIST_DCE_COMMON_BASE(mask_sh)
 
 #define OPP_COMMON_MASK_SH_LIST_DCE_120(mask_sh)\
-	OPP_SF(DCFE0_DCFE_MEM_PWR_CTRL, DCP_REGAMMA_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCFE0_DCFE_MEM_PWR_CTRL, DCP_LUT_MEM_PWR_DIS, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START_SEGMENT, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_SLOPE_CNTL, REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_END_CNTL1, REGAMMA_CNTLA_EXP_REGION_END, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_BASE, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_SLOPE, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, mask_sh),\
-	OPP_SF(DCFE0_DCFE_MEM_PWR_STATUS, DCP_REGAMMA_MEM_PWR_STATE, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_LUT_WRITE_EN_MASK, REGAMMA_LUT_WRITE_EN_MASK, mask_sh),\
-	OPP_SF(DCP0_REGAMMA_CONTROL, GRPH_REGAMMA_MODE, mask_sh),\
 	OPP_SF(FMT0_FMT_DYNAMIC_EXP_CNTL, FMT_DYNAMIC_EXP_EN, mask_sh),\
 	OPP_SF(FMT0_FMT_DYNAMIC_EXP_CNTL, FMT_DYNAMIC_EXP_MODE, mask_sh),\
 	OPP_SF(FMT0_FMT_BIT_DEPTH_CONTROL, FMT_TRUNCATE_EN, mask_sh),\
@@ -257,24 +193,6 @@ enum dce110_opp_reg_type {
 	OPP_SF(FMT0_FMT_CONTROL, FMT_CBCR_BIT_REDUCTION_BYPASS, mask_sh)
 
 #define OPP_REG_FIELD_LIST(type) \
-	type DCP_REGAMMA_MEM_PWR_DIS; \
-	type DCP_LUT_MEM_PWR_DIS; \
-	type REGAMMA_LUT_LIGHT_SLEEP_DIS; \
-	type DCP_LUT_LIGHT_SLEEP_DIS; \
-	type REGAMMA_CNTLA_EXP_REGION_START; \
-	type REGAMMA_CNTLA_EXP_REGION_START_SEGMENT; \
-	type REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE; \
-	type REGAMMA_CNTLA_EXP_REGION_END; \
-	type REGAMMA_CNTLA_EXP_REGION_END_BASE; \
-	type REGAMMA_CNTLA_EXP_REGION_END_SLOPE; \
-	type REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET; \
-	type REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS; \
-	type REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET; \
-	type REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS; \
-	type DCP_REGAMMA_MEM_PWR_STATE; \
-	type REGAMMA_LUT_MEM_PWR_STATE; \
-	type REGAMMA_LUT_WRITE_EN_MASK; \
-	type GRPH_REGAMMA_MODE; \
 	type FMT_DYNAMIC_EXP_EN; \
 	type FMT_DYNAMIC_EXP_MODE; \
 	type FMT_TRUNCATE_EN; \
@@ -327,25 +245,6 @@ struct dce_opp_mask {
 };
 
 struct dce_opp_registers {
-	uint32_t DCFE_MEM_PWR_CTRL;
-	uint32_t DCFE_MEM_LIGHT_SLEEP_CNTL;
-	uint32_t REGAMMA_CNTLA_START_CNTL;
-	uint32_t REGAMMA_CNTLA_SLOPE_CNTL;
-	uint32_t REGAMMA_CNTLA_END_CNTL1;
-	uint32_t REGAMMA_CNTLA_END_CNTL2;
-	uint32_t REGAMMA_CNTLA_REGION_0_1;
-	uint32_t REGAMMA_CNTLA_REGION_2_3;
-	uint32_t REGAMMA_CNTLA_REGION_4_5;
-	uint32_t REGAMMA_CNTLA_REGION_6_7;
-	uint32_t REGAMMA_CNTLA_REGION_8_9;
-	uint32_t REGAMMA_CNTLA_REGION_10_11;
-	uint32_t REGAMMA_CNTLA_REGION_12_13;
-	uint32_t REGAMMA_CNTLA_REGION_14_15;
-	uint32_t REGAMMA_LUT_WRITE_EN_MASK;
-	uint32_t REGAMMA_LUT_INDEX;
-	uint32_t DCFE_MEM_PWR_STATUS;
-	uint32_t REGAMMA_LUT_DATA;
-	uint32_t REGAMMA_CONTROL;
 	uint32_t FMT_DYNAMIC_EXP_CNTL;
 	uint32_t FMT_BIT_DEPTH_CONTROL;
 	uint32_t FMT_CONTROL;
@@ -382,17 +281,7 @@ void dce110_opp_construct(struct dce110_opp *opp110,
 
 void dce110_opp_destroy(struct output_pixel_processor **opp);
 
-/* REGAMMA RELATED */
-void dce110_opp_power_on_regamma_lut(
-	struct output_pixel_processor *opp,
-	bool power_on);
-
-bool dce110_opp_program_regamma_pwl(
-	struct output_pixel_processor *opp,
-	const struct pwl_params *params);
 
-void dce110_opp_set_regamma_mode(struct output_pixel_processor *opp,
-		enum opp_regamma mode);
 
 /* FORMATTER RELATED */
 void dce110_opp_program_bit_depth_reduction(
diff --git a/drivers/gpu/drm/amd/display/dc/dce/dce_transform.c b/drivers/gpu/drm/amd/display/dc/dce/dce_transform.c
old mode 100644
new mode 100755
index cb133e9..2e5524f
--- a/drivers/gpu/drm/amd/display/dc/dce/dce_transform.c
+++ b/drivers/gpu/drm/amd/display/dc/dce/dce_transform.c
@@ -1166,20 +1166,206 @@ void dce110_opp_set_csc_default(
 		default_adjust->out_color_space);
 }
 
+static void program_pwl(struct dce_transform *xfm_dce,
+			const struct pwl_params *params)
+{
+	int retval;
+	uint8_t max_tries = 10;
+	uint8_t counter = 0;
+	uint32_t i = 0;
+	const struct pwl_result_data *rgb = params->rgb_resulted;
+
+	/* Power on LUT memory */
+	if (REG(DCFE_MEM_PWR_CTRL))
+		REG_UPDATE(DCFE_MEM_PWR_CTRL,
+			   DCP_REGAMMA_MEM_PWR_DIS, 1);
+	else
+		REG_UPDATE(DCFE_MEM_LIGHT_SLEEP_CNTL,
+			   REGAMMA_LUT_LIGHT_SLEEP_DIS, 1);
+
+	while (counter < max_tries) {
+		if (REG(DCFE_MEM_PWR_STATUS)) {
+			REG_GET(DCFE_MEM_PWR_STATUS,
+				DCP_REGAMMA_MEM_PWR_STATE,
+				&retval);
+
+			if (retval == 0)
+				break;
+			++counter;
+		} else {
+			REG_GET(DCFE_MEM_LIGHT_SLEEP_CNTL,
+				REGAMMA_LUT_MEM_PWR_STATE,
+				&retval);
+
+			if (retval == 0)
+				break;
+			++counter;
+		}
+	}
+
+	if (counter == max_tries) {
+		dm_logger_write(xfm_dce->base.ctx->logger, LOG_WARNING,
+				"%s: regamma lut was not powered on "
+				"in a timely manner,"
+				" programming still proceeds\n",
+				__func__);
+	}
+
+	REG_UPDATE(REGAMMA_LUT_WRITE_EN_MASK,
+		   REGAMMA_LUT_WRITE_EN_MASK, 7);
+
+	REG_WRITE(REGAMMA_LUT_INDEX, 0);
+
+	/* Program REGAMMA_LUT_DATA */
+	while (i != params->hw_points_num) {
+
+		REG_WRITE(REGAMMA_LUT_DATA, rgb->red_reg);
+		REG_WRITE(REGAMMA_LUT_DATA, rgb->green_reg);
+		REG_WRITE(REGAMMA_LUT_DATA, rgb->blue_reg);
+		REG_WRITE(REGAMMA_LUT_DATA, rgb->delta_red_reg);
+		REG_WRITE(REGAMMA_LUT_DATA, rgb->delta_green_reg);
+		REG_WRITE(REGAMMA_LUT_DATA, rgb->delta_blue_reg);
+
+		++rgb;
+		++i;
+	}
+
+	/*  we are done with DCP LUT memory; re-enable low power mode */
+	if (REG(DCFE_MEM_PWR_CTRL))
+		REG_UPDATE(DCFE_MEM_PWR_CTRL,
+			   DCP_REGAMMA_MEM_PWR_DIS, 0);
+	else
+		REG_UPDATE(DCFE_MEM_LIGHT_SLEEP_CNTL,
+			   REGAMMA_LUT_LIGHT_SLEEP_DIS, 0);
+}
+
+static void regamma_config_regions_and_segments(struct dce_transform *xfm_dce,
+						const struct pwl_params *params)
+{
+	const struct gamma_curve *curve;
+
+	REG_SET_2(REGAMMA_CNTLA_START_CNTL, 0,
+		  REGAMMA_CNTLA_EXP_REGION_START, params->arr_points[0].custom_float_x,
+		  REGAMMA_CNTLA_EXP_REGION_START_SEGMENT, 0);
+
+	REG_SET(REGAMMA_CNTLA_SLOPE_CNTL, 0,
+		REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE, params->arr_points[0].custom_float_slope);
+
+	REG_SET(REGAMMA_CNTLA_END_CNTL1, 0,
+		REGAMMA_CNTLA_EXP_REGION_END, params->arr_points[1].custom_float_x);
+
+	REG_SET_2(REGAMMA_CNTLA_END_CNTL2, 0,
+		  REGAMMA_CNTLA_EXP_REGION_END_BASE, params->arr_points[1].custom_float_y,
+		  REGAMMA_CNTLA_EXP_REGION_END_SLOPE, params->arr_points[1].custom_float_slope);
+
+	curve = params->arr_curve_points;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_0_1, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+	curve += 2;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_2_3, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+	curve += 2;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_4_5, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+	curve += 2;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_6_7, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+	curve += 2;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_8_9, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+	curve += 2;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_10_11, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+	curve += 2;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_12_13, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+	curve += 2;
+
+	REG_SET_4(REGAMMA_CNTLA_REGION_14_15, 0,
+		  REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
+		  REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
+		  REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
+		  REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
+}
+
+
+
+void dce110_opp_program_regamma_pwl(struct transform *xfm,
+				    const struct pwl_params *params)
+{
+	struct dce_transform *xfm_dce = TO_DCE_TRANSFORM(xfm);
+
+	/* Setup regions */
+	regamma_config_regions_and_segments(xfm_dce, params);
+
+	/* Program PWL */
+	program_pwl(xfm_dce, params);
+}
 
+void dce110_opp_power_on_regamma_lut(struct transform *xfm,
+				     bool power_on)
+{
+	struct dce_transform *xfm_dce = TO_DCE_TRANSFORM(xfm);
+
+	if (REG(DCFE_MEM_PWR_CTRL))
+		REG_UPDATE_2(DCFE_MEM_PWR_CTRL,
+			     DCP_REGAMMA_MEM_PWR_DIS, power_on,
+			     DCP_LUT_MEM_PWR_DIS, power_on);
+	else
+		REG_UPDATE_2(DCFE_MEM_LIGHT_SLEEP_CNTL,
+			    REGAMMA_LUT_LIGHT_SLEEP_DIS, power_on,
+			    DCP_LUT_LIGHT_SLEEP_DIS, power_on);
+
+}
+
+void dce110_opp_set_regamma_mode(struct transform *xfm,
+				 enum opp_regamma mode)
+{
+	struct dce_transform *xfm_dce = TO_DCE_TRANSFORM(xfm);
+
+	REG_SET(REGAMMA_CONTROL, 0,
+		GRPH_REGAMMA_MODE, mode);
+}
 
 static const struct transform_funcs dce_transform_funcs = {
 	.transform_reset = dce_transform_reset,
-	.transform_set_scaler =
-		dce_transform_set_scaler,
-	.transform_set_gamut_remap =
-		dce_transform_set_gamut_remap,
+	.transform_set_scaler = dce_transform_set_scaler,
+	.transform_set_gamut_remap = dce_transform_set_gamut_remap,
 	.opp_set_csc_adjustment = dce110_opp_set_csc_adjustment,
 	.opp_set_csc_default = dce110_opp_set_csc_default,
-	.transform_set_pixel_storage_depth =
-		dce_transform_set_pixel_storage_depth,
-	.transform_get_optimal_number_of_taps =
-		dce_transform_get_optimal_number_of_taps
+	.opp_power_on_regamma_lut = dce110_opp_power_on_regamma_lut,
+	.opp_program_regamma_pwl = dce110_opp_program_regamma_pwl,
+	.opp_set_regamma_mode = dce110_opp_set_regamma_mode,
+	.transform_set_pixel_storage_depth = dce_transform_set_pixel_storage_depth,
+	.transform_get_optimal_number_of_taps = dce_transform_get_optimal_number_of_taps
 };
 
 /*****************************************/
diff --git a/drivers/gpu/drm/amd/display/dc/dce/dce_transform.h b/drivers/gpu/drm/amd/display/dc/dce/dce_transform.h
index 55bb3f6..bfc94b4 100755
--- a/drivers/gpu/drm/amd/display/dc/dce/dce_transform.h
+++ b/drivers/gpu/drm/amd/display/dc/dce/dce_transform.h
@@ -51,6 +51,22 @@
 	SRI(OUTPUT_CSC_C31_C32, DCP, id), \
 	SRI(OUTPUT_CSC_C33_C34, DCP, id), \
 	SRI(OUTPUT_CSC_CONTROL, DCP, id), \
+	SRI(REGAMMA_CNTLA_START_CNTL, DCP, id), \
+	SRI(REGAMMA_CNTLA_SLOPE_CNTL, DCP, id), \
+	SRI(REGAMMA_CNTLA_END_CNTL1, DCP, id), \
+	SRI(REGAMMA_CNTLA_END_CNTL2, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_0_1, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_2_3, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_4_5, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_6_7, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_8_9, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_10_11, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_12_13, DCP, id), \
+	SRI(REGAMMA_CNTLA_REGION_14_15, DCP, id), \
+	SRI(REGAMMA_LUT_WRITE_EN_MASK, DCP, id), \
+	SRI(REGAMMA_LUT_INDEX, DCP, id), \
+	SRI(REGAMMA_LUT_DATA, DCP, id), \
+	SRI(REGAMMA_CONTROL, DCP, id), \
 	SRI(DENORM_CONTROL, DCP, id), \
 	SRI(DCP_SPATIAL_DITHER_CNTL, DCP, id), \
 	SRI(OUT_ROUND_CONTROL, DCP, id), \
@@ -128,6 +144,18 @@
 	XFM_SF(OUTPUT_CSC_C11_C12, OUTPUT_CSC_C11, mask_sh),\
 	XFM_SF(OUTPUT_CSC_C11_C12, OUTPUT_CSC_C12, mask_sh),\
 	XFM_SF(OUTPUT_CSC_CONTROL, OUTPUT_CSC_GRPH_MODE, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START_SEGMENT, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_SLOPE_CNTL, REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_END_CNTL1, REGAMMA_CNTLA_EXP_REGION_END, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_BASE, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_SLOPE, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, mask_sh),\
+	XFM_SF(REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, mask_sh),\
+	XFM_SF(REGAMMA_LUT_WRITE_EN_MASK, REGAMMA_LUT_WRITE_EN_MASK, mask_sh),\
+	XFM_SF(REGAMMA_CONTROL, GRPH_REGAMMA_MODE, mask_sh),\
 	XFM_SF(SCL_MODE, SCL_MODE, mask_sh), \
 	XFM_SF(SCL_TAP_CONTROL, SCL_H_NUM_OF_TAPS, mask_sh), \
 	XFM_SF(SCL_TAP_CONTROL, SCL_V_NUM_OF_TAPS, mask_sh), \
@@ -171,6 +199,9 @@
 	XFM_COMMON_MASK_SH_LIST_DCE_COMMON_BASE(mask_sh), \
 	XFM_SF(DCFE_MEM_PWR_CTRL, SCL_COEFF_MEM_PWR_DIS, mask_sh), \
 	XFM_SF(DCFE_MEM_PWR_STATUS, SCL_COEFF_MEM_PWR_STATE, mask_sh), \
+	XFM_SF(DCFE_MEM_PWR_CTRL, DCP_REGAMMA_MEM_PWR_DIS, mask_sh),\
+	XFM_SF(DCFE_MEM_PWR_CTRL, DCP_LUT_MEM_PWR_DIS, mask_sh),\
+	XFM_SF(DCFE_MEM_PWR_STATUS, DCP_REGAMMA_MEM_PWR_STATE, mask_sh),\
 	XFM_SF(SCL_MODE, SCL_PSCL_EN, mask_sh)
 
 #define XFM_COMMON_MASK_SH_LIST_SOC_BASE(mask_sh) \
@@ -205,8 +236,18 @@
 	XFM_SF(DCP0_GAMUT_REMAP_CONTROL, GRPH_GAMUT_REMAP_MODE, mask_sh), \
 	XFM_SF(DCP0_OUTPUT_CSC_C11_C12, OUTPUT_CSC_C11, mask_sh),\
 	XFM_SF(DCP0_OUTPUT_CSC_C11_C12, OUTPUT_CSC_C12, mask_sh),\
-	XFM_SF(DCP0_REGAMMA_CONTROL, GRPH_REGAMMA_MODE, mask_sh),\
 	XFM_SF(DCP0_OUTPUT_CSC_CONTROL, OUTPUT_CSC_GRPH_MODE, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_START_CNTL, REGAMMA_CNTLA_EXP_REGION_START_SEGMENT, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_SLOPE_CNTL, REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_END_CNTL1, REGAMMA_CNTLA_EXP_REGION_END, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_BASE, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_END_CNTL2, REGAMMA_CNTLA_EXP_REGION_END_SLOPE, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CNTLA_REGION_0_1, REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS, mask_sh),\
+	XFM_SF(DCP0_REGAMMA_CONTROL, GRPH_REGAMMA_MODE, mask_sh),\
 	XFM_SF(SCL0_SCL_MODE, SCL_MODE, mask_sh), \
 	XFM_SF(SCL0_SCL_TAP_CONTROL, SCL_H_NUM_OF_TAPS, mask_sh), \
 	XFM_SF(SCL0_SCL_TAP_CONTROL, SCL_V_NUM_OF_TAPS, mask_sh), \
@@ -240,6 +281,8 @@
 	XFM_SF(SCL0_SCL_UPDATE, SCL_COEF_UPDATE_COMPLETE, mask_sh), \
 	XFM_SF(LB0_LB_DATA_FORMAT, ALPHA_EN, mask_sh), \
 	XFM_SF(DCFE0_DCFE_MEM_PWR_CTRL, SCL_COEFF_MEM_PWR_DIS, mask_sh), \
+	XFM_SF(DCFE0_DCFE_MEM_PWR_CTRL, DCP_REGAMMA_MEM_PWR_DIS, mask_sh),\
+	XFM_SF(DCFE0_DCFE_MEM_PWR_CTRL, DCP_LUT_MEM_PWR_DIS, mask_sh),\
 	XFM_SF(DCFE0_DCFE_MEM_PWR_STATUS, SCL_COEFF_MEM_PWR_STATE, mask_sh), \
 	XFM_SF(SCL0_SCL_MODE, SCL_PSCL_EN, mask_sh)
 
@@ -276,6 +319,24 @@
 	type OUTPUT_CSC_C11; \
 	type OUTPUT_CSC_C12; \
 	type OUTPUT_CSC_GRPH_MODE; \
+	type DCP_REGAMMA_MEM_PWR_DIS; \
+	type DCP_LUT_MEM_PWR_DIS; \
+	type REGAMMA_LUT_LIGHT_SLEEP_DIS; \
+	type DCP_LUT_LIGHT_SLEEP_DIS; \
+	type REGAMMA_CNTLA_EXP_REGION_START; \
+	type REGAMMA_CNTLA_EXP_REGION_START_SEGMENT; \
+	type REGAMMA_CNTLA_EXP_REGION_LINEAR_SLOPE; \
+	type REGAMMA_CNTLA_EXP_REGION_END; \
+	type REGAMMA_CNTLA_EXP_REGION_END_BASE; \
+	type REGAMMA_CNTLA_EXP_REGION_END_SLOPE; \
+	type REGAMMA_CNTLA_EXP_REGION0_LUT_OFFSET; \
+	type REGAMMA_CNTLA_EXP_REGION0_NUM_SEGMENTS; \
+	type REGAMMA_CNTLA_EXP_REGION1_LUT_OFFSET; \
+	type REGAMMA_CNTLA_EXP_REGION1_NUM_SEGMENTS; \
+	type DCP_REGAMMA_MEM_PWR_STATE; \
+	type REGAMMA_LUT_MEM_PWR_STATE; \
+	type REGAMMA_LUT_WRITE_EN_MASK; \
+	type GRPH_REGAMMA_MODE; \
 	type SCL_MODE; \
 	type SCL_BYPASS_MODE; \
 	type SCL_PSCL_EN; \
@@ -336,6 +397,23 @@ struct dce_transform_registers {
 	uint32_t OUTPUT_CSC_C31_C32;
 	uint32_t OUTPUT_CSC_C33_C34;
 	uint32_t OUTPUT_CSC_CONTROL;
+	uint32_t DCFE_MEM_LIGHT_SLEEP_CNTL;
+	uint32_t REGAMMA_CNTLA_START_CNTL;
+	uint32_t REGAMMA_CNTLA_SLOPE_CNTL;
+	uint32_t REGAMMA_CNTLA_END_CNTL1;
+	uint32_t REGAMMA_CNTLA_END_CNTL2;
+	uint32_t REGAMMA_CNTLA_REGION_0_1;
+	uint32_t REGAMMA_CNTLA_REGION_2_3;
+	uint32_t REGAMMA_CNTLA_REGION_4_5;
+	uint32_t REGAMMA_CNTLA_REGION_6_7;
+	uint32_t REGAMMA_CNTLA_REGION_8_9;
+	uint32_t REGAMMA_CNTLA_REGION_10_11;
+	uint32_t REGAMMA_CNTLA_REGION_12_13;
+	uint32_t REGAMMA_CNTLA_REGION_14_15;
+	uint32_t REGAMMA_LUT_WRITE_EN_MASK;
+	uint32_t REGAMMA_LUT_INDEX;
+	uint32_t REGAMMA_LUT_DATA;
+	uint32_t REGAMMA_CONTROL;
 	uint32_t DENORM_CONTROL;
 	uint32_t DCP_SPATIAL_DITHER_CNTL;
 	uint32_t OUT_ROUND_CONTROL;
@@ -423,4 +501,16 @@ void dce110_opp_set_csc_default(
 	struct transform *xfm,
 	const struct default_adjustment *default_adjust);
 
+/* REGAMMA RELATED */
+void dce110_opp_power_on_regamma_lut(
+	struct transform *xfm,
+	bool power_on);
+
+void dce110_opp_program_regamma_pwl(
+	struct transform *xfm,
+	const struct pwl_params *params);
+
+void dce110_opp_set_regamma_mode(struct transform *xfm,
+		enum opp_regamma mode);
+
 #endif /* _DCE_DCE_TRANSFORM_H_ */
diff --git a/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c b/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c
old mode 100644
new mode 100755
index fb78d5a..d293caf
--- a/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c
+++ b/drivers/gpu/drm/amd/display/dc/dce110/dce110_hw_sequencer.c
@@ -592,26 +592,24 @@ static bool
 dce110_set_output_transfer_func(struct pipe_ctx *pipe_ctx,
 				const struct dc_stream_state *stream)
 {
-	struct output_pixel_processor *opp = pipe_ctx->stream_res.opp;
+	struct transform *xfm = pipe_ctx->plane_res.xfm;
 
-	opp->funcs->opp_power_on_regamma_lut(opp, true);
-	opp->regamma_params.hw_points_num = GAMMA_HW_POINTS_NUM;
+	xfm->funcs->opp_power_on_regamma_lut(xfm, true);
+	xfm->regamma_params.hw_points_num = GAMMA_HW_POINTS_NUM;
 
 	if (stream->out_transfer_func &&
-		stream->out_transfer_func->type ==
-			TF_TYPE_PREDEFINED &&
-		stream->out_transfer_func->tf ==
-			TRANSFER_FUNCTION_SRGB) {
-		opp->funcs->opp_set_regamma_mode(opp, OPP_REGAMMA_SRGB);
-	} else if (dce110_translate_regamma_to_hw_format(
-				stream->out_transfer_func, &opp->regamma_params)) {
-			opp->funcs->opp_program_regamma_pwl(opp, &opp->regamma_params);
-			opp->funcs->opp_set_regamma_mode(opp, OPP_REGAMMA_USER);
+	    stream->out_transfer_func->type == TF_TYPE_PREDEFINED &&
+	    stream->out_transfer_func->tf == TRANSFER_FUNCTION_SRGB) {
+		xfm->funcs->opp_set_regamma_mode(xfm, OPP_REGAMMA_SRGB);
+	} else if (dce110_translate_regamma_to_hw_format(stream->out_transfer_func,
+							 &xfm->regamma_params)) {
+		xfm->funcs->opp_program_regamma_pwl(xfm, &xfm->regamma_params);
+		xfm->funcs->opp_set_regamma_mode(xfm, OPP_REGAMMA_USER);
 	} else {
-		opp->funcs->opp_set_regamma_mode(opp, OPP_REGAMMA_BYPASS);
+		xfm->funcs->opp_set_regamma_mode(xfm, OPP_REGAMMA_BYPASS);
 	}
 
-	opp->funcs->opp_power_on_regamma_lut(opp, false);
+	xfm->funcs->opp_power_on_regamma_lut(xfm, false);
 
 	return true;
 }
@@ -1260,15 +1258,15 @@ static enum dc_status apply_single_controller_ctx_to_hw(
 	/*  */
 	dc->hwss.prog_pixclk_crtc_otg(pipe_ctx, context, dc);
 
-	pipe_ctx->stream_res.opp->funcs->opp_set_dyn_expansion(
-			pipe_ctx->stream_res.opp,
-			COLOR_SPACE_YCBCR601,
-			stream->timing.display_color_depth,
-			pipe_ctx->stream->signal);
-
 	/* FPGA does not program backend */
 	if (IS_FPGA_MAXIMUS_DC(dc->ctx->dce_environment)) {
-	pipe_ctx->stream_res.opp->funcs->opp_program_fmt(
+		pipe_ctx->stream_res.opp->funcs->opp_set_dyn_expansion(
+		pipe_ctx->stream_res.opp,
+		COLOR_SPACE_YCBCR601,
+		stream->timing.display_color_depth,
+		pipe_ctx->stream->signal);
+
+		pipe_ctx->stream_res.opp->funcs->opp_program_fmt(
 			pipe_ctx->stream_res.opp,
 			&stream->bit_depth_params,
 			&stream->clamping);
@@ -1280,6 +1278,11 @@ static enum dc_status apply_single_controller_ctx_to_hw(
 			BREAK_TO_DEBUGGER();
 			return DC_ERROR_UNEXPECTED;
 		}
+	pipe_ctx->stream_res.opp->funcs->opp_set_dyn_expansion(
+			pipe_ctx->stream_res.opp,
+			COLOR_SPACE_YCBCR601,
+			stream->timing.display_color_depth,
+			pipe_ctx->stream->signal);
 
 	if (pipe_ctx->stream->signal != SIGNAL_TYPE_VIRTUAL)
 		stream->sink->link->link_enc->funcs->setup(
@@ -1578,16 +1581,6 @@ static void set_safe_displaymarks(
 				MAX_WATERMARK);
 
 	}
-
-	for (i = 0; i < dc->res_pool->pipe_count; i++) {
-		struct pipe_ctx *pipe_ctx = &context->res_ctx.pipe_ctx[i];
-		struct pipe_ctx *old_pipe_ctx = &dc->current_state->res_ctx.pipe_ctx[i];
-
-		if ((stream == pipe_ctx->stream) &&
-			(!pipe_ctx->top_pipe) &&
-			(pipe_ctx->plane_state || old_pipe_ctx->plane_state))
-			dc->hwss.pipe_control_lock(dc, pipe_ctx, false);
-	}
 }
 
 /*******************************************************************************
@@ -1685,13 +1678,11 @@ static uint32_t get_max_pixel_clock_for_all_paths(
 	return max_pix_clk;
 }
 
-/* Find clock state based on clock requested. if clock value is 0, simply
+/*
+ * Find clock state based on clock requested. if clock value is 0, simply
  * set clock state as requested without finding clock state by clock value
- *TODO: when dce120_hw_sequencer.c is created, override apply_min_clock.
- *
- * TODOFPGA  remove TODO after implement dal_display_clock_get_cur_clocks_value
- * etc support for dcn1.0
  */
+
 static void apply_min_clocks(
 	struct dc *dc,
 	struct dc_state *context,
@@ -2843,15 +2834,6 @@ static void dce110_apply_ctx_for_surface(
 			continue;
 
 		/* Need to allocate mem before program front end for Fiji */
-		if (pipe_ctx->plane_res.mi != NULL)
-			pipe_ctx->plane_res.mi->funcs->allocate_mem_input(
-					pipe_ctx->plane_res.mi,
-					pipe_ctx->stream->timing.h_total,
-					pipe_ctx->stream->timing.v_total,
-					pipe_ctx->stream->timing.pix_clk_khz,
-					context->stream_count);
-
-		/* Need to allocate mem before program front end for Fiji */
 		pipe_ctx->plane_res.mi->funcs->allocate_mem_input(
 				pipe_ctx->plane_res.mi,
 				pipe_ctx->stream->timing.h_total,
diff --git a/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c b/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c
old mode 100644
new mode 100755
index 91fc449..c0757dd
--- a/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c
+++ b/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c
@@ -908,16 +908,6 @@ enum dc_status dce112_validate_global(
 	return DC_OK;
 }
 
-enum dc_status dce112_validate_global(
-		struct dc *dc,
-		struct validate_context *context)
-{
-	if (!dce112_validate_surface_sets(context))
-		return DC_FAIL_SURFACE_VALIDATE;
-
-	return DC_OK;
-}
-
 static void dce112_destroy_resource_pool(struct resource_pool **pool)
 {
 	struct dce110_resource_pool *dce110_pool = TO_DCE110_RES_POOL(*pool);
diff --git a/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.h b/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.h
old mode 100644
new mode 100755
index 0073ff6..d5c19d3
--- a/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.h
+++ b/drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.h
@@ -56,11 +56,6 @@ enum dc_status dce112_add_stream_to_ctx(
 		struct dc_state *new_ctx,
 		struct dc_stream_state *dc_stream);
 
-enum dc_status dce112_add_stream_to_ctx(
-		struct dc *dc,
-		struct validate_context *new_ctx,
-		struct dc_stream_state *dc_stream);
-
 
 #endif /* __DC_RESOURCE_DCE112_H__ */
 
diff --git a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp.h b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp.h
old mode 100644
new mode 100755
index 83b6e54..07003d9
--- a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp.h
+++ b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp.h
@@ -90,6 +90,9 @@
 	SRI(CM_DGAM_RAMB_REGION_14_15, CM, id), \
 	SRI(CM_DGAM_RAMA_START_CNTL_B, CM, id), \
 	SRI(CM_DGAM_RAMA_START_CNTL_G, CM, id), \
+	SRI(CM_DGAM_RAMA_START_CNTL_R, CM, id), \
+	SRI(CM_DGAM_RAMA_SLOPE_CNTL_B, CM, id), \
+	SRI(CM_DGAM_RAMA_SLOPE_CNTL_G, CM, id), \
 	SRI(CM_DGAM_RAMA_SLOPE_CNTL_R, CM, id), \
 	SRI(CM_DGAM_RAMA_END_CNTL1_B, CM, id), \
 	SRI(CM_DGAM_RAMA_END_CNTL2_B, CM, id), \
@@ -178,6 +181,9 @@
 	TF_SF(DSCL0_DSCL_EXT_OVERSCAN_TOP_BOTTOM, EXT_OVERSCAN_BOTTOM, mask_sh),\
 	TF_SF(DSCL0_DSCL_EXT_OVERSCAN_TOP_BOTTOM, EXT_OVERSCAN_TOP, mask_sh),\
 	TF_SF(DSCL0_OTG_H_BLANK, OTG_H_BLANK_START, mask_sh),\
+	TF_SF(DSCL0_OTG_H_BLANK, OTG_H_BLANK_END, mask_sh),\
+	TF_SF(DSCL0_OTG_V_BLANK, OTG_V_BLANK_START, mask_sh),\
+	TF_SF(DSCL0_OTG_V_BLANK, OTG_V_BLANK_END, mask_sh),\
 	TF_SF(DSCL0_LB_DATA_FORMAT, INTERLEAVE_EN, mask_sh),\
 	TF2_SF(DSCL0, LB_DATA_FORMAT__ALPHA_EN, mask_sh),\
 	TF_SF(DSCL0_LB_MEMORY_CTRL, MEMORY_CONFIG, mask_sh),\
@@ -236,6 +242,8 @@
 	TF_SF(CM0_CM_ICSC_C33_C34, CM_ICSC_C33, mask_sh), \
 	TF_SF(CM0_CM_ICSC_C33_C34, CM_ICSC_C34, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMB_START_CNTL_B, CM_DGAM_RAMB_EXP_REGION_START_B, mask_sh), \
+	TF_SF(CM0_CM_DGAM_RAMB_START_CNTL_B, CM_DGAM_RAMB_EXP_REGION_START_SEGMENT_B, mask_sh), \
+	TF_SF(CM0_CM_DGAM_RAMB_START_CNTL_G, CM_DGAM_RAMB_EXP_REGION_START_G, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMB_START_CNTL_G, CM_DGAM_RAMB_EXP_REGION_START_SEGMENT_G, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMB_START_CNTL_R, CM_DGAM_RAMB_EXP_REGION_START_R, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMB_START_CNTL_R, CM_DGAM_RAMB_EXP_REGION_START_SEGMENT_R, mask_sh), \
@@ -281,8 +289,6 @@
 	TF_SF(CM0_CM_DGAM_RAMA_REGION_0_1, CM_DGAM_RAMA_EXP_REGION0_NUM_SEGMENTS, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMA_REGION_0_1, CM_DGAM_RAMA_EXP_REGION1_LUT_OFFSET, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMA_REGION_0_1, CM_DGAM_RAMA_EXP_REGION1_NUM_SEGMENTS, mask_sh), \
-	TF_SF(CM0_CM_DGAM_RAMA_REGION_0_1, CM_DGAM_RAMA_EXP_REGION1_LUT_OFFSET, mask_sh), \
-	TF_SF(CM0_CM_DGAM_RAMA_REGION_0_1, CM_DGAM_RAMA_EXP_REGION1_NUM_SEGMENTS, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMA_REGION_14_15, CM_DGAM_RAMA_EXP_REGION14_LUT_OFFSET, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMA_REGION_14_15, CM_DGAM_RAMA_EXP_REGION14_NUM_SEGMENTS, mask_sh), \
 	TF_SF(CM0_CM_DGAM_RAMA_REGION_14_15, CM_DGAM_RAMA_EXP_REGION15_LUT_OFFSET, mask_sh), \
@@ -346,15 +352,6 @@
 	TF_SF(CM0_CM_RGAM_RAMB_SLOPE_CNTL_R, CM_RGAM_RAMB_EXP_REGION_LINEAR_SLOPE_R, mask_sh), \
 	TF_SF(CM0_CM_RGAM_RAMB_END_CNTL1_B, CM_RGAM_RAMB_EXP_REGION_END_B, mask_sh), \
 	TF_SF(CM0_CM_RGAM_RAMB_END_CNTL2_B, CM_RGAM_RAMB_EXP_REGION_END_SLOPE_B, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_START_CNTL_G, CM_RGAM_RAMB_EXP_REGION_START_G, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_START_CNTL_G, CM_RGAM_RAMB_EXP_REGION_START_SEGMENT_G, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_START_CNTL_R, CM_RGAM_RAMB_EXP_REGION_START_R, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_START_CNTL_R, CM_RGAM_RAMB_EXP_REGION_START_SEGMENT_R, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_SLOPE_CNTL_B, CM_RGAM_RAMB_EXP_REGION_LINEAR_SLOPE_B, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_SLOPE_CNTL_G, CM_RGAM_RAMB_EXP_REGION_LINEAR_SLOPE_G, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_SLOPE_CNTL_R, CM_RGAM_RAMB_EXP_REGION_LINEAR_SLOPE_R, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_END_CNTL1_B, CM_RGAM_RAMB_EXP_REGION_END_B, mask_sh), \
-	TF_SF(CM0_CM_RGAM_RAMB_END_CNTL2_B, CM_RGAM_RAMB_EXP_REGION_END_SLOPE_B, mask_sh), \
 	TF_SF(CM0_CM_RGAM_RAMB_END_CNTL2_B, CM_RGAM_RAMB_EXP_REGION_END_BASE_B, mask_sh), \
 	TF_SF(CM0_CM_RGAM_RAMB_END_CNTL1_G, CM_RGAM_RAMB_EXP_REGION_END_G, mask_sh), \
 	TF_SF(CM0_CM_RGAM_RAMB_END_CNTL2_G, CM_RGAM_RAMB_EXP_REGION_END_SLOPE_G, mask_sh), \
@@ -895,6 +892,15 @@
 	type CM_SHAPER_RAMA_EXP_REGION24_NUM_SEGMENTS; \
 	type CM_SHAPER_RAMA_EXP_REGION25_LUT_OFFSET; \
 	type CM_SHAPER_RAMA_EXP_REGION25_NUM_SEGMENTS; \
+	type CM_SHAPER_RAMA_EXP_REGION26_LUT_OFFSET; \
+	type CM_SHAPER_RAMA_EXP_REGION26_NUM_SEGMENTS; \
+	type CM_SHAPER_RAMA_EXP_REGION27_LUT_OFFSET; \
+	type CM_SHAPER_RAMA_EXP_REGION27_NUM_SEGMENTS; \
+	type CM_SHAPER_RAMA_EXP_REGION28_LUT_OFFSET; \
+	type CM_SHAPER_RAMA_EXP_REGION28_NUM_SEGMENTS; \
+	type CM_SHAPER_RAMA_EXP_REGION29_LUT_OFFSET; \
+	type CM_SHAPER_RAMA_EXP_REGION29_NUM_SEGMENTS; \
+	type CM_SHAPER_RAMA_EXP_REGION30_LUT_OFFSET; \
 	type CM_SHAPER_RAMA_EXP_REGION30_NUM_SEGMENTS; \
 	type CM_SHAPER_RAMA_EXP_REGION31_LUT_OFFSET; \
 	type CM_SHAPER_RAMA_EXP_REGION31_NUM_SEGMENTS; \
@@ -917,8 +923,8 @@
 	type CM_BNS_BIAS_G; \
 	type CM_BNS_BIAS_B; \
 	type CM_BNS_SCALE_R; \
-       type CM_BNS_SCALE_G; \
-+       type CM_BNS_SCALE_B; \
+	type CM_BNS_SCALE_G; \
+	type CM_BNS_SCALE_B; \
 	type CM_DGAM_RAMB_EXP_REGION_START_B; \
 	type CM_DGAM_RAMB_EXP_REGION_START_SEGMENT_B; \
 	type CM_DGAM_RAMB_EXP_REGION_START_G; \
@@ -997,21 +1003,6 @@
 	type CURSOR_MODE; \
 	type CURSOR_PITCH; \
 	type CURSOR_LINES_PER_CHUNK; \
-	type CM_DGAM_LUT_WRITE_SEL; \
-	type CM_DGAM_LUT_INDEX; \
-	type CM_DGAM_LUT_DATA; \
-	type CM_DGAM_LUT_MODE; \
-	type CM_IGAM_LUT_MODE; \
-	type CM_IGAM_INPUT_FORMAT; \
-	type CM_IGAM_LUT_RW_INDEX; \
-	type CM_BYPASS_EN; \
-	type FORMAT_EXPANSION_MODE; \
-	type CNVC_BYPASS; \
-	type OUTPUT_FP; \
-	type CNVC_SURFACE_PIXEL_FORMAT; \
-	type CURSOR_MODE; \
-	type CURSOR_PITCH; \
-	type CURSOR_LINES_PER_CHUNK; \
 	type CURSOR_ENABLE; \
 	type CUR0_MODE; \
 	type CUR0_EXPANSION_MODE; \
@@ -1319,30 +1310,30 @@ void dpp1_dscl_calc_lb_num_partitions(
 		int *num_part_y,
 		int *num_part_c);
 
-void ippn10_degamma_ram_select(
-		struct transform *xfm_base,
+void dpp1_degamma_ram_select(
+		struct dpp *dpp_base,
 							bool use_ram_a);
 
-void ippn10_program_degamma_luta_settings(
-		struct transform *xfm_base,
+void dpp1_program_degamma_luta_settings(
+		struct dpp *dpp_base,
 		const struct pwl_params *params);
 
-void ippn10_program_degamma_lutb_settings(
-		struct transform *xfm_base,
+void dpp1_program_degamma_lutb_settings(
+		struct dpp *dpp_base,
 		const struct pwl_params *params);
 
-void ippn10_program_degamma_lut(
-		struct transform *xfm_base,
+void dpp1_program_degamma_lut(
+		struct dpp *dpp_base,
 		const struct pwl_result_data *rgb,
 		uint32_t num,
 		bool is_ram_a);
 
-void ippn10_power_on_degamma_lut(
-		struct transform *xfm_base,
+void dpp1_power_on_degamma_lut(
+		struct dpp *dpp_base,
 	bool power_on);
 
-void ippn10_program_input_csc(
-		struct transform *xfm_base,
+void dpp1_program_input_csc(
+		struct dpp *dpp_base,
 		enum dc_color_space color_space,
 		enum dcn10_input_csc_select select,
 		const struct out_csc_color_matrix *tbl_entry);
@@ -1351,12 +1342,36 @@ void dpp1_program_bias_and_scale(
 		struct dpp *dpp_base,
 		struct dc_bias_and_scale *params);
 
-void ippn10_program_input_lut(
-		struct transform *xfm_base,
+void dpp1_program_input_lut(
+		struct dpp *dpp_base,
 		const struct dc_gamma *gamma);
 
-void ippn10_full_bypass(struct transform *xfm_base);
+void dpp1_full_bypass(struct dpp *dpp_base);
+
+void dpp1_set_degamma(
+		struct dpp *dpp_base,
+		enum ipp_degamma_mode mode);
+
+void dpp1_set_degamma_pwl(struct dpp *dpp_base,
+								 const struct pwl_params *params);
+
+bool dpp_get_optimal_number_of_taps(
+		struct dpp *dpp,
+		struct scaler_data *scl_data,
+		const struct scaling_taps *in_taps);
+
+void dpp_reset(struct dpp *dpp_base);
+
+void dpp1_cm_program_regamma_lut(
+		struct dpp *dpp_base,
+		const struct pwl_result_data *rgb,
+		uint32_t num);
+
+void dpp1_cm_power_on_regamma_lut(
+	struct dpp *dpp_base,
+	bool power_on);
 
+void dpp1_cm_configure_regamma_lut(
 		struct dpp *dpp_base,
 		bool is_ram_a);
 
@@ -1369,7 +1384,6 @@ void dpp1_cm_program_regamma_luta_settings(
 void dpp1_cm_program_regamma_lutb_settings(
 		struct dpp *dpp_base,
 		const struct pwl_params *params);
-
 void dpp1_cm_set_output_csc_adjustment(
 		struct dpp *dpp_base,
 		const uint16_t *regval);
@@ -1379,12 +1393,12 @@ void dpp1_cm_set_output_csc_default(
 		enum dc_color_space colorspace);
 
 void dpp1_cm_set_gamut_remap(
-		struct dpp *dpp,
-		const struct dpp_grph_csc_adjustment *adjust);
+	struct dpp *dpp,
+	const struct dpp_grph_csc_adjustment *adjust);
 
 void dpp1_dscl_set_scaler_manual_scale(
-		struct dpp *dpp_base,
-		const struct scaler_data *scl_data);
+	struct dpp *dpp_base,
+	const struct scaler_data *scl_data);
 
 void dpp1_cnv_setup (
 		struct dpp *dpp_base,
diff --git a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp_cm.c b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp_cm.c
old mode 100644
new mode 100755
index 1433857..2482390
--- a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp_cm.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_dpp_cm.c
@@ -56,11 +56,6 @@ struct dcn10_input_csc_matrix {
 	uint16_t regval[12];
 };
 
-struct dcn10_input_csc_matrix {
-	enum dc_color_space color_space;
-	uint16_t regval[12];
-};
-
 enum dcn10_coef_filter_type_sel {
 	SCL_COEF_LUMA_VERT_FILTER = 0,
 	SCL_COEF_LUMA_HORZ_FILTER = 1,
@@ -124,58 +119,6 @@ static const struct dcn10_input_csc_matrix dcn10_input_csc_matrix[] = {
 						0x2568, 0x43ee, 0xdbb2} }
 };
 
-static void dpp_cm_program_color_registers(
-		struct dcn10_dpp *xfm,
-		const uint16_t *regval,
-		uint32_t cm_reg_start,
-		uint32_t cm_reg_end)
-{
-	uint32_t reg_region_cur;
-	unsigned int i = 0;
-
-#undef REG
-#define REG(reg) reg
-
-	for (reg_region_cur = cm_reg_start;
-			reg_region_cur <= cm_reg_end;
-			reg_region_cur++) {
-
-		const uint16_t *regval0 = &(regval[2 * i]);
-		const uint16_t *regval1 = &(regval[(2 * i) + 1]);
-
-		REG_SET_2(reg_region_cur, 0,
-				CM_GAMUT_REMAP_C11, *regval0,
-				CM_GAMUT_REMAP_C12, *regval1);
-
-		i++;
-	}
-
-#undef REG
-#define REG(reg)\
-	xfm->tf_regs->reg
-
-}
-
-static const struct dcn10_input_csc_matrix dcn10_input_csc_matrix[] = {
-	{COLOR_SPACE_SRGB,
-		{0x2000, 0, 0, 0, 0, 0x2000, 0, 0, 0, 0, 0x2000, 0} },
-	{COLOR_SPACE_SRGB_LIMITED,
-		{0x2000, 0, 0, 0, 0, 0x2000, 0, 0, 0, 0, 0x2000, 0} },
-	{COLOR_SPACE_YCBCR601,
-		{0x2cdd, 0x2000, 0, 0xe991, 0xe926, 0x2000, 0xf4fd, 0x10ef,
-						0, 0x2000, 0x38b4, 0xe3a6} },
-	{COLOR_SPACE_YCBCR601_LIMITED,
-		{0x3353, 0x2568, 0, 0xe400, 0xe5dc, 0x2568, 0xf367, 0x1108,
-						0, 0x2568, 0x40de, 0xdd3a} },
-	{COLOR_SPACE_YCBCR709,
-		{0x3265, 0x2000, 0, 0xe6ce, 0xf105, 0x2000, 0xfa01, 0xa7d, 0,
-						0x2000, 0x3b61, 0xe24f} },
-
-	{COLOR_SPACE_YCBCR709_LIMITED,
-		{0x39a6, 0x2568, 0, 0xe0d6, 0xeedd, 0x2568, 0xf925, 0x9a8, 0,
-						0x2568, 0x43ee, 0xdbb2} }
-};
-
 static void program_gamut_remap(
 		struct dcn10_dpp *dpp,
 		const uint16_t *regval,
@@ -493,9 +436,9 @@ void dpp1_program_input_csc(
 		if (regval == NULL) {
 			BREAK_TO_DEBUGGER();
 			return;
-	        } else {
-			regval = tbl_entry->regval;
 		}
+	} else {
+		regval = tbl_entry->regval;
 	}
 
 	if (select == INPUT_CSC_SELECT_COMA)
@@ -551,7 +494,6 @@ void dpp1_program_bias_and_scale(
 
 }
 
-
 /*program de gamma RAM B*/
 void dpp1_program_degamma_lutb_settings(
 		struct dpp *dpp_base,
@@ -836,493 +778,3 @@ void dpp1_program_input_lut(
 	REG_UPDATE(CM_IGAM_CONTROL, CM_IGAM_LUT_MODE, rama_occupied ? 3 : 2);
 	REG_GET(CM_IGAM_CONTROL, CM_IGAM_LUT_MODE, &ram_num);
 }
-
-void ippn10_program_input_csc(
-		struct transform *xfm_base,
-		enum dc_color_space color_space,
-		enum dcn10_input_csc_select select)
-{
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-	int i;
-	int arr_size = sizeof(dcn10_input_csc_matrix)/sizeof(struct dcn10_input_csc_matrix);
-	const uint16_t *regval = NULL;
-	uint32_t selection = 1;
-
-	if (select == INPUT_CSC_SELECT_BYPASS) {
-		REG_SET(CM_ICSC_CONTROL, 0, CM_ICSC_MODE, 0);
-		return;
-	}
-
-	for (i = 0; i < arr_size; i++)
-		if (dcn10_input_csc_matrix[i].color_space == color_space) {
-			regval = dcn10_input_csc_matrix[i].regval;
-			break;
-		}
-
-	if (regval == NULL) {
-		BREAK_TO_DEBUGGER();
-		return;
-	}
-
-	if (select == INPUT_CSC_SELECT_COMA)
-		selection = 2;
-	REG_SET(CM_ICSC_CONTROL, 0,
-			CM_ICSC_MODE, selection);
-
-	if (select == INPUT_CSC_SELECT_ICSC) {
-
-		dpp_cm_program_color_registers(
-				xfm,
-				regval,
-				REG(CM_ICSC_C11_C12),
-				REG(CM_ICSC_C33_C34));
-	} else {
-
-		dpp_cm_program_color_registers(
-				xfm,
-				regval,
-				REG(CM_COMA_C11_C12),
-				REG(CM_COMA_C33_C34));
-	}
-}
-
-/*program de gamma RAM B*/
-void ippn10_program_degamma_lutb_settings(
-		struct transform *xfm_base,
-		const struct pwl_params *params)
-{
-	const struct gamma_curve *curve;
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	REG_SET_2(CM_DGAM_RAMB_START_CNTL_B, 0,
-		CM_DGAM_RAMB_EXP_REGION_START_B, params->arr_points[0].custom_float_x,
-		CM_DGAM_RAMB_EXP_REGION_START_SEGMENT_B, 0);
-
-	REG_SET_2(CM_DGAM_RAMB_START_CNTL_G, 0,
-		CM_DGAM_RAMB_EXP_REGION_START_G, params->arr_points[0].custom_float_x,
-		CM_DGAM_RAMB_EXP_REGION_START_SEGMENT_G, 0);
-
-	REG_SET_2(CM_DGAM_RAMB_START_CNTL_R, 0,
-		CM_DGAM_RAMB_EXP_REGION_START_R, params->arr_points[0].custom_float_x,
-		CM_DGAM_RAMB_EXP_REGION_START_SEGMENT_R, 0);
-
-	REG_SET(CM_DGAM_RAMB_SLOPE_CNTL_B, 0,
-		CM_DGAM_RAMB_EXP_REGION_LINEAR_SLOPE_B, params->arr_points[0].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMB_SLOPE_CNTL_G, 0,
-		CM_DGAM_RAMB_EXP_REGION_LINEAR_SLOPE_G, params->arr_points[0].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMB_SLOPE_CNTL_R, 0,
-		CM_DGAM_RAMB_EXP_REGION_LINEAR_SLOPE_R, params->arr_points[0].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMB_END_CNTL1_B, 0,
-		CM_DGAM_RAMB_EXP_REGION_END_B, params->arr_points[1].custom_float_x);
-
-	REG_SET_2(CM_DGAM_RAMB_END_CNTL2_B, 0,
-		CM_DGAM_RAMB_EXP_REGION_END_SLOPE_B, params->arr_points[1].custom_float_y,
-		CM_DGAM_RAMB_EXP_REGION_END_BASE_B, params->arr_points[2].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMB_END_CNTL1_G, 0,
-		CM_DGAM_RAMB_EXP_REGION_END_G, params->arr_points[1].custom_float_x);
-
-	REG_SET_2(CM_DGAM_RAMB_END_CNTL2_G, 0,
-		CM_DGAM_RAMB_EXP_REGION_END_SLOPE_G, params->arr_points[1].custom_float_y,
-		CM_DGAM_RAMB_EXP_REGION_END_BASE_G, params->arr_points[2].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMB_END_CNTL1_R, 0,
-		CM_DGAM_RAMB_EXP_REGION_END_R, params->arr_points[1].custom_float_x);
-
-	REG_SET_2(CM_DGAM_RAMB_END_CNTL2_R, 0,
-		CM_DGAM_RAMB_EXP_REGION_END_SLOPE_R, params->arr_points[1].custom_float_y,
-		CM_DGAM_RAMB_EXP_REGION_END_BASE_R, params->arr_points[2].custom_float_slope);
-
-	curve = params->arr_curve_points;
-	REG_SET_4(CM_DGAM_RAMB_REGION_0_1, 0,
-		CM_DGAM_RAMB_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION1_LUT_OFFSET, 	curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMB_REGION_2_3, 0,
-		CM_DGAM_RAMB_EXP_REGION2_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION2_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION3_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION3_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMB_REGION_4_5, 0,
-		CM_DGAM_RAMB_EXP_REGION4_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION4_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION5_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION5_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMB_REGION_6_7, 0,
-		CM_DGAM_RAMB_EXP_REGION6_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION6_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION7_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION7_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMB_REGION_8_9, 0,
-		CM_DGAM_RAMB_EXP_REGION8_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION8_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION9_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION9_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMB_REGION_10_11, 0,
-		CM_DGAM_RAMB_EXP_REGION10_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION10_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION11_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION11_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMB_REGION_12_13, 0,
-		CM_DGAM_RAMB_EXP_REGION12_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION12_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION13_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION13_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMB_REGION_14_15, 0,
-		CM_DGAM_RAMB_EXP_REGION14_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMB_EXP_REGION14_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMB_EXP_REGION15_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMB_EXP_REGION15_NUM_SEGMENTS, curve[1].segments_num);
-}
-
-/*program de gamma RAM A*/
-void ippn10_program_degamma_luta_settings(
-		struct transform *xfm_base,
-		const struct pwl_params *params)
-{
-	const struct gamma_curve *curve;
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	REG_SET_2(CM_DGAM_RAMA_START_CNTL_B, 0,
-		CM_DGAM_RAMA_EXP_REGION_START_B, params->arr_points[0].custom_float_x,
-		CM_DGAM_RAMA_EXP_REGION_START_SEGMENT_B, 0);
-
-	REG_SET_2(CM_DGAM_RAMA_START_CNTL_G, 0,
-		CM_DGAM_RAMA_EXP_REGION_START_G, params->arr_points[0].custom_float_x,
-		CM_DGAM_RAMA_EXP_REGION_START_SEGMENT_G, 0);
-
-	REG_SET_2(CM_DGAM_RAMA_START_CNTL_R, 0,
-		CM_DGAM_RAMA_EXP_REGION_START_R, params->arr_points[0].custom_float_x,
-		CM_DGAM_RAMA_EXP_REGION_START_SEGMENT_R, 0);
-
-	REG_SET(CM_DGAM_RAMA_SLOPE_CNTL_B, 0,
-		CM_DGAM_RAMA_EXP_REGION_LINEAR_SLOPE_B, params->arr_points[0].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMA_SLOPE_CNTL_G, 0,
-		CM_DGAM_RAMA_EXP_REGION_LINEAR_SLOPE_G, params->arr_points[0].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMA_SLOPE_CNTL_R, 0,
-		CM_DGAM_RAMA_EXP_REGION_LINEAR_SLOPE_R, params->arr_points[0].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMA_END_CNTL1_B, 0,
-		CM_DGAM_RAMA_EXP_REGION_END_B, params->arr_points[1].custom_float_x);
-
-	REG_SET_2(CM_DGAM_RAMA_END_CNTL2_B, 0,
-		CM_DGAM_RAMA_EXP_REGION_END_SLOPE_B, params->arr_points[1].custom_float_y,
-		CM_DGAM_RAMA_EXP_REGION_END_BASE_B, params->arr_points[2].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMA_END_CNTL1_G, 0,
-		CM_DGAM_RAMA_EXP_REGION_END_G, params->arr_points[1].custom_float_x);
-
-	REG_SET_2(CM_DGAM_RAMA_END_CNTL2_G, 0,
-		CM_DGAM_RAMA_EXP_REGION_END_SLOPE_G, params->arr_points[1].custom_float_y,
-		CM_DGAM_RAMA_EXP_REGION_END_BASE_G, params->arr_points[2].custom_float_slope);
-
-	REG_SET(CM_DGAM_RAMA_END_CNTL1_R, 0,
-		CM_DGAM_RAMA_EXP_REGION_END_R, params->arr_points[1].custom_float_x);
-
-	REG_SET_2(CM_DGAM_RAMA_END_CNTL2_R, 0,
-		CM_DGAM_RAMA_EXP_REGION_END_SLOPE_R, params->arr_points[1].custom_float_y,
-		CM_DGAM_RAMA_EXP_REGION_END_BASE_R, params->arr_points[2].custom_float_slope);
-
-	curve = params->arr_curve_points;
-	REG_SET_4(CM_DGAM_RAMA_REGION_0_1, 0,
-		CM_DGAM_RAMA_EXP_REGION0_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION0_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION1_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION1_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMA_REGION_2_3, 0,
-		CM_DGAM_RAMA_EXP_REGION2_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION2_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION3_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION3_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMA_REGION_4_5, 0,
-		CM_DGAM_RAMA_EXP_REGION4_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION4_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION5_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION5_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMA_REGION_6_7, 0,
-		CM_DGAM_RAMA_EXP_REGION6_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION6_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION7_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION7_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMA_REGION_8_9, 0,
-		CM_DGAM_RAMA_EXP_REGION8_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION8_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION9_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION9_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMA_REGION_10_11, 0,
-		CM_DGAM_RAMA_EXP_REGION10_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION10_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION11_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION11_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMA_REGION_12_13, 0,
-		CM_DGAM_RAMA_EXP_REGION12_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION12_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION13_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION13_NUM_SEGMENTS, curve[1].segments_num);
-
-	curve += 2;
-	REG_SET_4(CM_DGAM_RAMA_REGION_14_15, 0,
-		CM_DGAM_RAMA_EXP_REGION14_LUT_OFFSET, curve[0].offset,
-		CM_DGAM_RAMA_EXP_REGION14_NUM_SEGMENTS, curve[0].segments_num,
-		CM_DGAM_RAMA_EXP_REGION15_LUT_OFFSET, curve[1].offset,
-		CM_DGAM_RAMA_EXP_REGION15_NUM_SEGMENTS, curve[1].segments_num);
-}
-
-void ippn10_power_on_degamma_lut(
-		struct transform *xfm_base,
-	bool power_on)
-{
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	REG_SET(CM_MEM_PWR_CTRL, 0,
-			SHARED_MEM_PWR_DIS, power_on == true ? 0:1);
-
-}
-
-static void ippn10_enable_cm_block(
-		struct transform *xfm_base)
-{
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	REG_UPDATE(CM_CONTROL, CM_BYPASS_EN, 0);
-}
-
-void ippn10_set_degamma(
-		struct transform *xfm_base,
-		enum ipp_degamma_mode mode)
-{
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-	ippn10_enable_cm_block(xfm_base);
-
-	switch (mode) {
-	case IPP_DEGAMMA_MODE_BYPASS:
-		/* Setting de gamma bypass for now */
-		REG_UPDATE(CM_DGAM_CONTROL, CM_DGAM_LUT_MODE, 0);
-		break;
-	case IPP_DEGAMMA_MODE_HW_sRGB:
-		REG_UPDATE(CM_DGAM_CONTROL, CM_DGAM_LUT_MODE, 1);
-		break;
-	case IPP_DEGAMMA_MODE_HW_xvYCC:
-		REG_UPDATE(CM_DGAM_CONTROL, CM_DGAM_LUT_MODE, 2);
-			break;
-	default:
-		BREAK_TO_DEBUGGER();
-		break;
-	}
-}
-
-void ippn10_degamma_ram_select(
-		struct transform *xfm_base,
-							bool use_ram_a)
-{
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	if (use_ram_a)
-		REG_UPDATE(CM_DGAM_CONTROL, CM_DGAM_LUT_MODE, 3);
-	else
-		REG_UPDATE(CM_DGAM_CONTROL, CM_DGAM_LUT_MODE, 4);
-
-}
-
-static bool ippn10_degamma_ram_inuse(
-		struct transform *xfm_base,
-							bool *ram_a_inuse)
-{
-	bool ret = false;
-	uint32_t status_reg = 0;
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	REG_GET(CM_IGAM_LUT_RW_CONTROL, CM_IGAM_DGAM_CONFIG_STATUS,
-			&status_reg);
-
-	if (status_reg == 9) {
-		*ram_a_inuse = true;
-		ret = true;
-	} else if (status_reg == 10) {
-		*ram_a_inuse = false;
-		ret = true;
-	}
-	return ret;
-}
-
-void ippn10_program_degamma_lut(
-		struct transform *xfm_base,
-		const struct pwl_result_data *rgb,
-		uint32_t num,
-		bool is_ram_a)
-{
-	uint32_t i;
-
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-	REG_UPDATE(CM_IGAM_LUT_RW_CONTROL, CM_IGAM_LUT_HOST_EN, 0);
-	REG_UPDATE(CM_DGAM_LUT_WRITE_EN_MASK,
-				   CM_DGAM_LUT_WRITE_EN_MASK, 7);
-	REG_UPDATE(CM_DGAM_LUT_WRITE_EN_MASK, CM_DGAM_LUT_WRITE_SEL,
-					is_ram_a == true ? 0:1);
-
-	REG_SET(CM_DGAM_LUT_INDEX, 0, CM_DGAM_LUT_INDEX, 0);
-	for (i = 0 ; i < num; i++) {
-		REG_SET(CM_DGAM_LUT_DATA, 0, CM_DGAM_LUT_DATA, rgb[i].red_reg);
-		REG_SET(CM_DGAM_LUT_DATA, 0, CM_DGAM_LUT_DATA, rgb[i].green_reg);
-		REG_SET(CM_DGAM_LUT_DATA, 0, CM_DGAM_LUT_DATA, rgb[i].blue_reg);
-
-		REG_SET(CM_DGAM_LUT_DATA, 0,
-				CM_DGAM_LUT_DATA, rgb[i].delta_red_reg);
-		REG_SET(CM_DGAM_LUT_DATA, 0,
-				CM_DGAM_LUT_DATA, rgb[i].delta_green_reg);
-		REG_SET(CM_DGAM_LUT_DATA, 0,
-				CM_DGAM_LUT_DATA, rgb[i].delta_blue_reg);
-	}
-}
-
-void ippn10_set_degamma_pwl(struct transform *xfm_base,
-								 const struct pwl_params *params)
-{
-	bool is_ram_a = true;
-
-	ippn10_power_on_degamma_lut(xfm_base, true);
-	ippn10_enable_cm_block(xfm_base);
-	ippn10_degamma_ram_inuse(xfm_base, &is_ram_a);
-	if (is_ram_a == true)
-		ippn10_program_degamma_lutb_settings(xfm_base, params);
-	else
-		ippn10_program_degamma_luta_settings(xfm_base, params);
-
-	ippn10_program_degamma_lut(xfm_base, params->rgb_resulted,
-							params->hw_points_num, !is_ram_a);
-	ippn10_degamma_ram_select(xfm_base, !is_ram_a);
-}
-
-void ippn10_full_bypass(struct transform *xfm_base)
-{
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	/* Input pixel format: ARGB8888 */
-	REG_SET(CNVC_SURFACE_PIXEL_FORMAT, 0,
-			CNVC_SURFACE_PIXEL_FORMAT, 0x8);
-
-	/* Zero expansion */
-	REG_SET_3(FORMAT_CONTROL, 0,
-			CNVC_BYPASS, 0,
-			FORMAT_CONTROL__ALPHA_EN, 0,
-			FORMAT_EXPANSION_MODE, 0);
-
-	/* COLOR_KEYER_CONTROL.COLOR_KEYER_EN = 0 this should be default */
-	REG_SET(CM_CONTROL, 0, CM_BYPASS_EN, 1);
-
-	/* Setting degamma bypass for now */
-	REG_SET(CM_DGAM_CONTROL, 0, CM_DGAM_LUT_MODE, 0);
-	REG_SET(CM_IGAM_CONTROL, 0, CM_IGAM_LUT_MODE, 0);
-}
-
-static bool ippn10_ingamma_ram_inuse(struct transform *xfm_base,
-							bool *ram_a_inuse)
-{
-	bool in_use = false;
-	uint32_t status_reg = 0;
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-
-	REG_GET(CM_IGAM_LUT_RW_CONTROL, CM_IGAM_DGAM_CONFIG_STATUS,
-				&status_reg);
-
-	// 1 => IGAM_RAMA, 3 => IGAM_RAMA & DGAM_ROMA, 4 => IGAM_RAMA & DGAM_ROMB
-	if (status_reg == 1 || status_reg == 3 || status_reg == 4) {
-		*ram_a_inuse = true;
-		in_use = true;
-	// 2 => IGAM_RAMB, 5 => IGAM_RAMB & DGAM_ROMA, 6 => IGAM_RAMB & DGAM_ROMB
-	} else if (status_reg == 2 || status_reg == 5 || status_reg == 6) {
-		*ram_a_inuse = false;
-		in_use = true;
-	}
-	return in_use;
-}
-
-/*
- * Input gamma LUT currently supports 256 values only. This means input color
- * can have a maximum of 8 bits per channel (= 256 possible values) in order to
- * have a one-to-one mapping with the LUT. Truncation will occur with color
- * values greater than 8 bits.
- *
- * In the future, this function should support additional input gamma methods,
- * such as piecewise linear mapping, and input gamma bypass.
- */
-void ippn10_program_input_lut(
-		struct transform *xfm_base,
-		const struct dc_gamma *gamma)
-{
-	int i;
-	struct dcn10_dpp *xfm = TO_DCN10_DPP(xfm_base);
-	bool rama_occupied = false;
-	uint32_t ram_num;
-	// Power on LUT memory.
-	REG_SET(CM_MEM_PWR_CTRL, 0, SHARED_MEM_PWR_DIS, 1);
-	ippn10_enable_cm_block(xfm_base);
-	// Determine whether to use RAM A or RAM B
-	ippn10_ingamma_ram_inuse(xfm_base, &rama_occupied);
-	if (!rama_occupied)
-		REG_UPDATE(CM_IGAM_LUT_RW_CONTROL, CM_IGAM_LUT_SEL, 0);
-	else
-		REG_UPDATE(CM_IGAM_LUT_RW_CONTROL, CM_IGAM_LUT_SEL, 1);
-	// RW mode is 256-entry LUT
-	REG_UPDATE(CM_IGAM_LUT_RW_CONTROL, CM_IGAM_LUT_RW_MODE, 0);
-	// IGAM Input format should be 8 bits per channel.
-	REG_UPDATE(CM_IGAM_CONTROL, CM_IGAM_INPUT_FORMAT, 0);
-	// Do not mask any R,G,B values
-	REG_UPDATE(CM_IGAM_LUT_RW_CONTROL, CM_IGAM_LUT_WRITE_EN_MASK, 7);
-	// LUT-256, unsigned, integer, new u0.12 format
-	REG_UPDATE_3(
-		CM_IGAM_CONTROL,
-		CM_IGAM_LUT_FORMAT_R, 3,
-		CM_IGAM_LUT_FORMAT_G, 3,
-		CM_IGAM_LUT_FORMAT_B, 3);
-	// Start at index 0 of IGAM LUT
-	REG_UPDATE(CM_IGAM_LUT_RW_INDEX, CM_IGAM_LUT_RW_INDEX, 0);
-	for (i = 0; i < gamma->num_entries; i++) {
-		REG_SET(CM_IGAM_LUT_SEQ_COLOR, 0, CM_IGAM_LUT_SEQ_COLOR,
-				dal_fixed31_32_round(
-					gamma->entries.red[i]));
-		REG_SET(CM_IGAM_LUT_SEQ_COLOR, 0, CM_IGAM_LUT_SEQ_COLOR,
-				dal_fixed31_32_round(
-					gamma->entries.green[i]));
-		REG_SET(CM_IGAM_LUT_SEQ_COLOR, 0, CM_IGAM_LUT_SEQ_COLOR,
-				dal_fixed31_32_round(
-					gamma->entries.blue[i]));
-	}
-	// Power off LUT memory
-	REG_SET(CM_MEM_PWR_CTRL, 0, SHARED_MEM_PWR_DIS, 0);
-	// Enable IGAM LUT on ram we just wrote to. 2 => RAMA, 3 => RAMB
-	REG_UPDATE(CM_IGAM_CONTROL, CM_IGAM_LUT_MODE, rama_occupied ? 3 : 2);
-	REG_GET(CM_IGAM_CONTROL, CM_IGAM_LUT_MODE, &ram_num);
-}
diff --git a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
index b025ecb..2c3dcae 100755
--- a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_hw_sequencer.c
@@ -44,9 +44,6 @@
 #include "dcn10_hubp.h"
 #include "dcn10_hubbub.h"
 #include "dcn10_cm_common.h"
-#include "dcn/dcn_1_0_offset.h"
-#include "dcn/dcn_1_0_sh_mask.h"
-#include "soc15ip.h"
 
 #define CTX \
 	hws->ctx
@@ -389,56 +386,6 @@ static void apply_DEGVIDCN10_253_wa(struct dc *dc)
 	REG_SET(DC_IP_REQUEST_CNTL, 0,
 			IP_REQUEST_EN, 0);
 
-	mi->funcs->set_hubp_blank_en(mi, false);
-}
-
-static void optimize_shared_resources(struct dc *dc)
-{
-	if (dc->current_state->stream_count == 0 &&
-			!dc->debug.disable_stutter)
-		apply_DEGVIDCN10_253_wa(dc);
-}
-
-static void undo_DEGVIDCN10_253_wa(struct dc *dc)
-{
-	struct dce_hwseq *hws = dc->hwseq;
-	struct mem_input *mi = dc->res_pool->mis[0];
-	int pwr_status = 0;
-
-	REG_GET(DOMAIN0_PG_STATUS, DOMAIN0_PGFSM_PWR_STATUS, &pwr_status);
-	/* Don't need to blank if hubp is power gated*/
-	if (pwr_status == 2)
-		return;
-
-	mi->funcs->set_blank(mi, true);
-
-	REG_SET(DC_IP_REQUEST_CNTL, 0,
-			IP_REQUEST_EN, 1);
-
-	hubp_pg_control(hws, 0, false);
-	REG_SET(DC_IP_REQUEST_CNTL, 0,
-			IP_REQUEST_EN, 0);
-}
-
-static void ready_shared_resources(struct dc *dc)
-{
-	if (dc->current_state->stream_count == 0 &&
-			!dc->debug.disable_stutter)
-		undo_DEGVIDCN10_253_wa(dc);
-}
-
-static void apply_DEGVIDCN10_253_wa(struct dc *dc)
-{
-	struct dce_hwseq *hws = dc->hwseq;
-	struct mem_input *mi = dc->res_pool->mis[0];
-
-	REG_SET(DC_IP_REQUEST_CNTL, 0,
-			IP_REQUEST_EN, 1);
-
-	hubp_pg_control(hws, 0, true);
-	REG_SET(DC_IP_REQUEST_CNTL, 0,
-			IP_REQUEST_EN, 0);
-
 	hubp->funcs->set_hubp_blank_en(hubp, false);
 	hws->wa_state.DEGVIDCN10_253_applied = true;
 }
@@ -918,7 +865,6 @@ static bool patch_address_for_sbs_tb_stereo(struct pipe_ctx *pipe_ctx,
 			plane_state->address.grph_stereo.left_addr;
 		}
 	}
-
 	return false;
 }
 
diff --git a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c
old mode 100644
new mode 100755
index 183f278..17dd222
--- a/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c
+++ b/drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c
@@ -464,13 +464,13 @@ static const struct dc_debug debug_defaults_diags = {
 		.disable_pplib_wm_range = true
 };
 
-static void dcn10_dpp_destroy(struct transform **xfm)
+static void dcn10_dpp_destroy(struct dpp **dpp)
 {
-	kfree(TO_DCN10_DPP(*xfm));
-	*xfm = NULL;
+	kfree(TO_DCN10_DPP(*dpp));
+	*dpp = NULL;
 }
 
-static struct transform *dcn10_dpp_create(
+static struct dpp *dcn10_dpp_create(
 	struct dc_context *ctx,
 	uint32_t inst)
 {
@@ -480,8 +480,8 @@ static struct transform *dcn10_dpp_create(
 	if (!dpp)
 		return NULL;
 
-	dcn10_dpp_construct(dpp, ctx, inst,
-			    &tf_regs[inst], &tf_shift, &tf_mask);
+	dpp1_construct(dpp, ctx, inst,
+		       &tf_regs[inst], &tf_shift, &tf_mask);
 	return &dpp->base;
 }
 
@@ -751,7 +751,7 @@ static void destruct(struct dcn10_resource_pool *pool)
 			pool->base.ipps[i]->funcs->ipp_destroy(&pool->base.ipps[i]);
 
 		if (pool->base.hubps[i] != NULL) {
-			dm_free(TO_DCN10_MEM_INPUT(pool->base.hubps[i]));
+			kfree(TO_DCN10_HUBP(pool->base.hubps[i]));
 			pool->base.hubps[i] = NULL;
 		}
 
@@ -765,10 +765,8 @@ static void destruct(struct dcn10_resource_pool *pool)
 		}
 	}
 
-	for (i = 0; i < pool->base.stream_enc_count; i++) {
-		if (pool->base.stream_enc[i] != NULL)
-		kfree(DCE110STRENC_FROM_STRENC(pool->base.stream_enc[i]));
-	}
+	for (i = 0; i < pool->base.stream_enc_count; i++)
+		kfree(pool->base.stream_enc[i]);
 
 	for (i = 0; i < pool->base.audio_count; i++) {
 		if (pool->base.audios[i])
@@ -804,16 +802,14 @@ static struct hubp *dcn10_hubp_create(
 	uint32_t inst)
 {
 	struct dcn10_hubp *hubp1 =
-               dm_alloc(sizeof(struct dcn10_hubp));
+		kzalloc(sizeof(struct dcn10_hubp), GFP_KERNEL);
 
 	if (!hubp1)
 		return NULL;
 
-	if(dcn10_hubp_construct(hubp1, ctx, inst,
-				&hubp_regs[inst], &hubp_shift, &hubp_mask))
-		return &hubp1->base;
-	dm_free(hubp1);
-        return NULL;
+	dcn10_hubp_construct(hubp1, ctx, inst,
+			     &hubp_regs[inst], &hubp_shift, &hubp_mask);
+	return &hubp1->base;
 }
 
 static void get_pixel_clock_parameters(
diff --git a/drivers/gpu/drm/amd/display/dc/inc/clock_source.h b/drivers/gpu/drm/amd/display/dc/inc/clock_source.h
index cfe009a..ebcf67b 100644
--- a/drivers/gpu/drm/amd/display/dc/inc/clock_source.h
+++ b/drivers/gpu/drm/amd/display/dc/inc/clock_source.h
@@ -170,10 +170,6 @@ struct clock_source_funcs {
 			struct clock_source *,
 			struct pixel_clk_params *,
 			struct pll_settings *);
-	uint32_t (*get_pix_rate_in_hz)(
-			struct clock_source *,
-			struct pixel_clk_params *,
-			struct pll_settings *);
 };
 
 struct clock_source {
diff --git a/drivers/gpu/drm/amd/include/kgd_kfd_interface.h b/drivers/gpu/drm/amd/include/kgd_kfd_interface.h
index c2eb37b..cf921ab 100644
--- a/drivers/gpu/drm/amd/include/kgd_kfd_interface.h
+++ b/drivers/gpu/drm/amd/include/kgd_kfd_interface.h
@@ -361,7 +361,7 @@ struct kfd2kgd_calls {
 	int (*alloc_memory_of_gpu)(struct kgd_dev *kgd, uint64_t va,
 			uint64_t size, void *vm,
 			struct kgd_mem **mem, uint64_t *offset,
-			void **kptr, uint32_t flags);
+			uint32_t flags);
 	int (*free_memory_of_gpu)(struct kgd_dev *kgd, struct kgd_mem *mem,
 			void *vm);
 	int (*map_memory_to_gpu)(struct kgd_dev *kgd, struct kgd_mem *mem,
diff --git a/drivers/gpu/drm/amd/powerplay/hwmgr/vega10_hwmgr.c b/drivers/gpu/drm/amd/powerplay/hwmgr/vega10_hwmgr.c
index 37356d2..43f8b8f 100644
--- a/drivers/gpu/drm/amd/powerplay/hwmgr/vega10_hwmgr.c
+++ b/drivers/gpu/drm/amd/powerplay/hwmgr/vega10_hwmgr.c
@@ -2881,8 +2881,8 @@ static int vega10_enable_dpm_tasks(struct pp_hwmgr *hwmgr)
 			"DPM is already running right , skipping re-enablement!",
 			return 0);
 
-	if ((data->smu_version == 0x001c2c00) ||
-			(data->smu_version == 0x001c2d00)) {
+	if ((hwmgr->smu_version == 0x001c2c00) ||
+			(hwmgr->smu_version == 0x001c2d00)) {
 		tmp_result = smum_send_msg_to_smc_with_parameter(hwmgr,
 				PPSMC_MSG_UpdatePkgPwrPidAlpha, 1);
 		PP_ASSERT_WITH_CODE(!tmp_result,
@@ -2890,15 +2890,6 @@ static int vega10_enable_dpm_tasks(struct pp_hwmgr *hwmgr)
 				return tmp_result);
 	}
 
-        if ((hwmgr->smu_version == 0x001c2c00) ||
-                        (hwmgr->smu_version == 0x001c2d00)) {
-                tmp_result = smum_send_msg_to_smc_with_parameter(hwmgr,
-                                PPSMC_MSG_UpdatePkgPwrPidAlpha, 1);
-                PP_ASSERT_WITH_CODE(!tmp_result,
-                                "Failed to set package power PID!",
-                                return tmp_result);
-        }
-
 	tmp_result = vega10_construct_voltage_tables(hwmgr);
 	PP_ASSERT_WITH_CODE(!tmp_result,
 			"Failed to contruct voltage tables!",
diff --git a/drivers/gpu/drm/drm_crtc.c b/drivers/gpu/drm/drm_crtc.c
index 2d7bedf..60403bf 100644
--- a/drivers/gpu/drm/drm_crtc.c
+++ b/drivers/gpu/drm/drm_crtc.c
@@ -40,7 +40,7 @@
 #include <drm/drm_modeset_lock.h>
 #include <drm/drm_atomic.h>
 #include <drm/drm_auth.h>
-#include <drm/drm_framebuffer.h>
+#include <drm/drm_debugfs_crc.h>
 
 #include "drm_crtc_internal.h"
 #include "drm_internal.h"
@@ -122,6 +122,10 @@ static int drm_crtc_register_all(struct drm_device *dev)
 	int ret = 0;
 
 	drm_for_each_crtc(crtc, dev) {
+		if (drm_debugfs_crtc_add(crtc))
+			DRM_ERROR("Failed to initialize debugfs entry for CRTC '%s'.\n",
+				  crtc->name);
+
 		if (crtc->funcs->late_register)
 			ret = crtc->funcs->late_register(crtc);
 		if (ret)
@@ -138,9 +142,29 @@ static void drm_crtc_unregister_all(struct drm_device *dev)
 	drm_for_each_crtc(crtc, dev) {
 		if (crtc->funcs->early_unregister)
 			crtc->funcs->early_unregister(crtc);
+		drm_debugfs_crtc_remove(crtc);
 	}
 }
 
+static int drm_crtc_crc_init(struct drm_crtc *crtc)
+{
+#ifdef CONFIG_DEBUG_FS
+	spin_lock_init(&crtc->crc.lock);
+	init_waitqueue_head(&crtc->crc.wq);
+	crtc->crc.source = kstrdup("auto", GFP_KERNEL);
+	if (!crtc->crc.source)
+		return -ENOMEM;
+#endif
+	return 0;
+}
+
+static void drm_crtc_crc_fini(struct drm_crtc *crtc)
+{
+#ifdef CONFIG_DEBUG_FS
+	kfree(crtc->crc.source);
+#endif
+}
+
 /**
  * drm_crtc_init_with_planes - Initialise a new CRTC object with
  *    specified primary and cursor planes.
@@ -210,6 +234,12 @@ int drm_crtc_init_with_planes(struct drm_device *dev, struct drm_crtc *crtc,
 	if (cursor)
 		cursor->possible_crtcs = 1 << drm_crtc_index(crtc);
 
+	ret = drm_crtc_crc_init(crtc);
+	if (ret) {
+		drm_mode_object_unregister(dev, &crtc->base);
+		return ret;
+	}
+
 	if (drm_core_check_feature(dev, DRIVER_ATOMIC)) {
 		drm_object_attach_property(&crtc->base, config->prop_active, 0);
 		drm_object_attach_property(&crtc->base, config->prop_mode_id, 0);
@@ -236,6 +266,8 @@ void drm_crtc_cleanup(struct drm_crtc *crtc)
 	 * the indices on the drm_crtc after us in the crtc_list.
 	 */
 
+	drm_crtc_crc_fini(crtc);
+
 	kfree(crtc->gamma_store);
 	crtc->gamma_store = NULL;
 
diff --git a/drivers/gpu/drm/drm_debugfs.c b/drivers/gpu/drm/drm_debugfs.c
index 1205790..800055c 100644
--- a/drivers/gpu/drm/drm_debugfs.c
+++ b/drivers/gpu/drm/drm_debugfs.c
@@ -415,5 +415,37 @@ void drm_debugfs_connector_remove(struct drm_connector *connector)
 	connector->debugfs_entry = NULL;
 }
 
-#endif /* CONFIG_DEBUG_FS */
+int drm_debugfs_crtc_add(struct drm_crtc *crtc)
+{
+	struct drm_minor *minor = crtc->dev->primary;
+	struct dentry *root;
+	char *name;
+
+	name = kasprintf(GFP_KERNEL, "crtc-%d", crtc->index);
+	if (!name)
+		return -ENOMEM;
+
+	root = debugfs_create_dir(name, minor->debugfs_root);
+	kfree(name);
+	if (!root)
+		return -ENOMEM;
+
+	crtc->debugfs_entry = root;
+
+	if (drm_debugfs_crtc_crc_add(crtc))
+		goto error;
 
+	return 0;
+
+error:
+	drm_debugfs_crtc_remove(crtc);
+	return -ENOMEM;
+}
+
+void drm_debugfs_crtc_remove(struct drm_crtc *crtc)
+{
+	debugfs_remove_recursive(crtc->debugfs_entry);
+	crtc->debugfs_entry = NULL;
+}
+
+#endif /* CONFIG_DEBUG_FS */
diff --git a/drivers/gpu/drm/drm_debugfs_crc.c b/drivers/gpu/drm/drm_debugfs_crc.c
new file mode 100644
index 0000000..4129405
--- /dev/null
+++ b/drivers/gpu/drm/drm_debugfs_crc.c
@@ -0,0 +1,351 @@
+/*
+ * Copyright © 2008 Intel Corporation
+ * Copyright © 2016 Collabora Ltd
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ *
+ * Based on code from the i915 driver.
+ * Original author: Damien Lespiau <damien.lespiau@intel.com>
+ *
+ */
+
+#include <linux/circ_buf.h>
+#include <linux/ctype.h>
+#include <linux/debugfs.h>
+#include <drm/drmP.h>
+
+/**
+ * DOC: CRC ABI
+ *
+ * DRM device drivers can provide to userspace CRC information of each frame as
+ * it reached a given hardware component (a "source").
+ *
+ * Userspace can control generation of CRCs in a given CRTC by writing to the
+ * file dri/0/crtc-N/crc/control in debugfs, with N being the index of the CRTC.
+ * Accepted values are source names (which are driver-specific) and the "auto"
+ * keyword, which will let the driver select a default source of frame CRCs
+ * for this CRTC.
+ *
+ * Once frame CRC generation is enabled, userspace can capture them by reading
+ * the dri/0/crtc-N/crc/data file. Each line in that file contains the frame
+ * number in the first field and then a number of unsigned integer fields
+ * containing the CRC data. Fields are separated by a single space and the number
+ * of CRC fields is source-specific.
+ *
+ * Note that though in some cases the CRC is computed in a specified way and on
+ * the frame contents as supplied by userspace (eDP 1.3), in general the CRC
+ * computation is performed in an unspecified way and on frame contents that have
+ * been already processed in also an unspecified way and thus userspace cannot
+ * rely on being able to generate matching CRC values for the frame contents that
+ * it submits. In this general case, the maximum userspace can do is to compare
+ * the reported CRCs of frames that should have the same contents.
+ */
+
+static int crc_control_show(struct seq_file *m, void *data)
+{
+	struct drm_crtc *crtc = m->private;
+
+	seq_printf(m, "%s\n", crtc->crc.source);
+
+	return 0;
+}
+
+static int crc_control_open(struct inode *inode, struct file *file)
+{
+	struct drm_crtc *crtc = inode->i_private;
+
+	return single_open(file, crc_control_show, crtc);
+}
+
+static ssize_t crc_control_write(struct file *file, const char __user *ubuf,
+				 size_t len, loff_t *offp)
+{
+	struct seq_file *m = file->private_data;
+	struct drm_crtc *crtc = m->private;
+	struct drm_crtc_crc *crc = &crtc->crc;
+	char *source;
+
+	if (len == 0)
+		return 0;
+
+	if (len > PAGE_SIZE - 1) {
+		DRM_DEBUG_KMS("Expected < %lu bytes into crtc crc control\n",
+			      PAGE_SIZE);
+		return -E2BIG;
+	}
+
+	source = memdup_user_nul(ubuf, len);
+	if (IS_ERR(source))
+		return PTR_ERR(source);
+
+	if (source[len] == '\n')
+		source[len] = '\0';
+
+	spin_lock_irq(&crc->lock);
+
+	if (crc->opened) {
+		spin_unlock_irq(&crc->lock);
+		kfree(source);
+		return -EBUSY;
+	}
+
+	kfree(crc->source);
+	crc->source = source;
+
+	spin_unlock_irq(&crc->lock);
+
+	*offp += len;
+	return len;
+}
+
+const struct file_operations drm_crtc_crc_control_fops = {
+	.owner = THIS_MODULE,
+	.open = crc_control_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+	.write = crc_control_write
+};
+
+static int crtc_crc_open(struct inode *inode, struct file *filep)
+{
+	struct drm_crtc *crtc = inode->i_private;
+	struct drm_crtc_crc *crc = &crtc->crc;
+	struct drm_crtc_crc_entry *entries = NULL;
+	size_t values_cnt;
+	int ret;
+
+	if (crc->opened)
+		return -EBUSY;
+
+	ret = crtc->funcs->set_crc_source(crtc, crc->source, &values_cnt);
+	if (ret)
+		return ret;
+
+	if (WARN_ON(values_cnt > DRM_MAX_CRC_NR)) {
+		ret = -EINVAL;
+		goto err_disable;
+	}
+
+	if (WARN_ON(values_cnt == 0)) {
+		ret = -EINVAL;
+		goto err_disable;
+	}
+
+	entries = kcalloc(DRM_CRC_ENTRIES_NR, sizeof(*entries), GFP_KERNEL);
+	if (!entries) {
+		ret = -ENOMEM;
+		goto err_disable;
+	}
+
+	spin_lock_irq(&crc->lock);
+	crc->entries = entries;
+	crc->values_cnt = values_cnt;
+	crc->opened = true;
+	spin_unlock_irq(&crc->lock);
+
+	return 0;
+
+err_disable:
+	crtc->funcs->set_crc_source(crtc, NULL, &values_cnt);
+	return ret;
+}
+
+static int crtc_crc_release(struct inode *inode, struct file *filep)
+{
+	struct drm_crtc *crtc = filep->f_inode->i_private;
+	struct drm_crtc_crc *crc = &crtc->crc;
+	size_t values_cnt;
+
+	spin_lock_irq(&crc->lock);
+	kfree(crc->entries);
+	crc->entries = NULL;
+	crc->head = 0;
+	crc->tail = 0;
+	crc->values_cnt = 0;
+	crc->opened = false;
+	spin_unlock_irq(&crc->lock);
+
+	crtc->funcs->set_crc_source(crtc, NULL, &values_cnt);
+
+	return 0;
+}
+
+static int crtc_crc_data_count(struct drm_crtc_crc *crc)
+{
+	assert_spin_locked(&crc->lock);
+	return CIRC_CNT(crc->head, crc->tail, DRM_CRC_ENTRIES_NR);
+}
+
+/*
+ * 1 frame field of 10 chars plus a number of CRC fields of 10 chars each, space
+ * separated, with a newline at the end and null-terminated.
+ */
+#define LINE_LEN(values_cnt)	(10 + 11 * values_cnt + 1 + 1)
+#define MAX_LINE_LEN		(LINE_LEN(DRM_MAX_CRC_NR))
+
+static ssize_t crtc_crc_read(struct file *filep, char __user *user_buf,
+			     size_t count, loff_t *pos)
+{
+	struct drm_crtc *crtc = filep->f_inode->i_private;
+	struct drm_crtc_crc *crc = &crtc->crc;
+	struct drm_crtc_crc_entry *entry;
+	char buf[MAX_LINE_LEN];
+	int ret, i;
+
+	spin_lock_irq(&crc->lock);
+
+	if (!crc->source) {
+		spin_unlock_irq(&crc->lock);
+		return 0;
+	}
+
+	/* Nothing to read? */
+	while (crtc_crc_data_count(crc) == 0) {
+		if (filep->f_flags & O_NONBLOCK) {
+			spin_unlock_irq(&crc->lock);
+			return -EAGAIN;
+		}
+
+		ret = wait_event_interruptible_lock_irq(crc->wq,
+							crtc_crc_data_count(crc),
+							crc->lock);
+		if (ret) {
+			spin_unlock_irq(&crc->lock);
+			return ret;
+		}
+	}
+
+	/* We know we have an entry to be read */
+	entry = &crc->entries[crc->tail];
+
+	if (count < LINE_LEN(crc->values_cnt)) {
+		spin_unlock_irq(&crc->lock);
+		return -EINVAL;
+	}
+
+	BUILD_BUG_ON_NOT_POWER_OF_2(DRM_CRC_ENTRIES_NR);
+	crc->tail = (crc->tail + 1) & (DRM_CRC_ENTRIES_NR - 1);
+
+	spin_unlock_irq(&crc->lock);
+
+	if (entry->has_frame_counter)
+		sprintf(buf, "0x%08x", entry->frame);
+	else
+		sprintf(buf, "XXXXXXXXXX");
+
+	for (i = 0; i < crc->values_cnt; i++)
+		sprintf(buf + 10 + i * 11, " 0x%08x", entry->crcs[i]);
+	sprintf(buf + 10 + crc->values_cnt * 11, "\n");
+
+	if (copy_to_user(user_buf, buf, LINE_LEN(crc->values_cnt)))
+		return -EFAULT;
+
+	return LINE_LEN(crc->values_cnt);
+}
+
+const struct file_operations drm_crtc_crc_data_fops = {
+	.owner = THIS_MODULE,
+	.open = crtc_crc_open,
+	.read = crtc_crc_read,
+	.release = crtc_crc_release,
+};
+
+/**
+ * drm_debugfs_crtc_crc_add - Add files to debugfs for capture of frame CRCs
+ * @crtc: CRTC to whom the frames will belong
+ *
+ * Adds files to debugfs directory that allows userspace to control the
+ * generation of frame CRCs and to read them.
+ *
+ * Returns:
+ * Zero on success, error code on failure.
+ */
+int drm_debugfs_crtc_crc_add(struct drm_crtc *crtc)
+{
+	struct dentry *crc_ent, *ent;
+
+	if (!crtc->funcs->set_crc_source)
+		return 0;
+
+	crc_ent = debugfs_create_dir("crc", crtc->debugfs_entry);
+	if (!crc_ent)
+		return -ENOMEM;
+
+	ent = debugfs_create_file("control", S_IRUGO, crc_ent, crtc,
+				  &drm_crtc_crc_control_fops);
+	if (!ent)
+		goto error;
+
+	ent = debugfs_create_file("data", S_IRUGO, crc_ent, crtc,
+				  &drm_crtc_crc_data_fops);
+	if (!ent)
+		goto error;
+
+	return 0;
+
+error:
+	debugfs_remove_recursive(crc_ent);
+
+	return -ENOMEM;
+}
+
+/**
+ * drm_crtc_add_crc_entry - Add entry with CRC information for a frame
+ * @crtc: CRTC to which the frame belongs
+ * @has_frame: whether this entry has a frame number to go with
+ * @frame: number of the frame these CRCs are about
+ * @crcs: array of CRC values, with length matching #drm_crtc_crc.values_cnt
+ *
+ * For each frame, the driver polls the source of CRCs for new data and calls
+ * this function to add them to the buffer from where userspace reads.
+ */
+int drm_crtc_add_crc_entry(struct drm_crtc *crtc, bool has_frame,
+			   uint32_t frame, uint32_t *crcs)
+{
+	struct drm_crtc_crc *crc = &crtc->crc;
+	struct drm_crtc_crc_entry *entry;
+	int head, tail;
+
+	assert_spin_locked(&crc->lock);
+
+	/* Caller may not have noticed yet that userspace has stopped reading */
+	if (!crc->opened)
+		return -EINVAL;
+
+	head = crc->head;
+	tail = crc->tail;
+
+	if (CIRC_SPACE(head, tail, DRM_CRC_ENTRIES_NR) < 1) {
+		DRM_ERROR("Overflow of CRC buffer, userspace reads too slow.\n");
+		return -ENOBUFS;
+	}
+
+	entry = &crc->entries[head];
+	entry->frame = frame;
+	entry->has_frame_counter = has_frame;
+	memcpy(&entry->crcs, crcs, sizeof(*crcs) * crc->values_cnt);
+
+	head = (head + 1) & (DRM_CRC_ENTRIES_NR - 1);
+	crc->head = head;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(drm_crtc_add_crc_entry);
diff --git a/drivers/gpu/drm/drm_internal.h b/drivers/gpu/drm/drm_internal.h
index 0473e4f..fe98d85 100644
--- a/drivers/gpu/drm/drm_internal.h
+++ b/drivers/gpu/drm/drm_internal.h
@@ -100,6 +100,9 @@ int drm_debugfs_init(struct drm_minor *minor, int minor_id,
 int drm_debugfs_cleanup(struct drm_minor *minor);
 int drm_debugfs_connector_add(struct drm_connector *connector);
 void drm_debugfs_connector_remove(struct drm_connector *connector);
+int drm_debugfs_crtc_add(struct drm_crtc *crtc);
+void drm_debugfs_crtc_remove(struct drm_crtc *crtc);
+int drm_debugfs_crtc_crc_add(struct drm_crtc *crtc);
 #else
 static inline int drm_debugfs_init(struct drm_minor *minor, int minor_id,
 				   struct dentry *root)
@@ -119,6 +122,19 @@ static inline int drm_debugfs_connector_add(struct drm_connector *connector)
 static inline void drm_debugfs_connector_remove(struct drm_connector *connector)
 {
 }
+
+static inline int drm_debugfs_crtc_add(struct drm_crtc *crtc)
+{
+	return 0;
+}
+static inline void drm_debugfs_crtc_remove(struct drm_crtc *crtc)
+{
+}
+
+static inline int drm_debugfs_crtc_crc_add(struct drm_crtc *crtc)
+{
+	return 0;
+}
 #endif
 
 /* drm_syncobj.c */
diff --git a/drivers/gpu/drm/radeon/radeon_kfd.c b/drivers/gpu/drm/radeon/radeon_kfd.c
index 9480b04..cf38599 100644
--- a/drivers/gpu/drm/radeon/radeon_kfd.c
+++ b/drivers/gpu/drm/radeon/radeon_kfd.c
@@ -91,8 +91,7 @@ static int unmap_memory_from_gpu(struct kgd_dev *kgd, struct kgd_mem *mem,
 		void *vm);
 static int alloc_memory_of_gpu(struct kgd_dev *kgd, uint64_t va, uint64_t size,
 		void *vm, struct kgd_mem **mem,
-		uint64_t *offset, void **kptr,
-		uint32_t flags);
+		uint64_t *offset, uint32_t flags);
 static int free_memory_of_gpu(struct kgd_dev *kgd, struct kgd_mem *mem,
 			      void *vm);
 
@@ -1384,8 +1383,7 @@ static int alloc_memory_of_scratch(struct kgd_dev *kgd,
 
 static int alloc_memory_of_gpu(struct kgd_dev *kgd, uint64_t va, uint64_t size,
 		void *vm, struct kgd_mem **mem,
-		uint64_t *offset, void **kptr,
-		uint32_t flags)
+		uint64_t *offset, uint32_t flags)
 {
 	struct radeon_device *rdev = (struct radeon_device *) kgd;
 	int ret;
diff --git a/drivers/gpu/drm/ttm/ttm_bo.c b/drivers/gpu/drm/ttm/ttm_bo.c
old mode 100644
new mode 100755
index a080f92..a3505a6
--- a/drivers/gpu/drm/ttm/ttm_bo.c
+++ b/drivers/gpu/drm/ttm/ttm_bo.c
@@ -54,6 +54,12 @@ static struct attribute ttm_bo_count = {
 	.mode = S_IRUGO
 };
 
+/* default destructor */
+static void ttm_bo_default_destroy(struct ttm_buffer_object *bo)
+{
+	kfree(bo);
+}
+
 static inline int ttm_mem_type_from_place(const struct ttm_place *place,
 					  uint32_t *mem_type)
 {
@@ -108,8 +114,8 @@ static ssize_t ttm_bo_global_show(struct kobject *kobj,
 	struct ttm_bo_global *glob =
 		container_of(kobj, struct ttm_bo_global, kobj);
 
-	return snprintf(buffer, PAGE_SIZE, "%lu\n",
-			(unsigned long) atomic_read(&glob->bo_count));
+	return snprintf(buffer, PAGE_SIZE, "%d\n",
+				atomic_read(&glob->bo_count));
 }
 
 static struct attribute *ttm_bo_global_attrs[] = {
@@ -1163,7 +1169,7 @@ int ttm_bo_init_reserved(struct ttm_bo_device *bdev,
 	struct ttm_mem_global *mem_glob = bdev->glob->mem_glob;
 	bool locked;
 
-	ret = ttm_mem_global_alloc(mem_glob, acc_size, false, false);
+	ret = ttm_mem_global_alloc(mem_glob, acc_size, ctx->no_wait_gpu, ctx->interruptible);
 	if (ret) {
 		pr_err("Out of kernel memory\n");
 		if (destroy)
diff --git a/drivers/gpu/drm/ttm/ttm_page_alloc.c b/drivers/gpu/drm/ttm/ttm_page_alloc.c
index 2e9d0b3d..a0ba7d9 100644
--- a/drivers/gpu/drm/ttm/ttm_page_alloc.c
+++ b/drivers/gpu/drm/ttm/ttm_page_alloc.c
@@ -880,7 +880,7 @@ int ttm_pool_populate(struct ttm_tt *ttm, struct ttm_operation_ctx *ctx)
 		}
 
 		ret = ttm_mem_global_alloc_page(mem_glob, ttm->pages[i],
-						PAGE_SIZE, ctx);
+						ctx->no_wait_gpu, ctx->interruptible);
 		if (unlikely(ret != 0)) {
 			ttm_pool_unpopulate(ttm);
 			return -ENOMEM;
diff --git a/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c b/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
index ce699de..732d662 100644
--- a/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
+++ b/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
@@ -911,7 +911,7 @@ int ttm_dma_populate(struct ttm_dma_tt *ttm_dma, struct device *dev,
 		}
 
 		ret = ttm_mem_global_alloc_page(mem_glob, ttm->pages[i],
-						pool->size, ctx);
+						ctx->no_wait_gpu, ctx->interruptible);
 		if (unlikely(ret != 0)) {
 			ttm_dma_unpopulate(ttm_dma, dev);
 			return -ENOMEM;
diff --git a/include/drm/drm_crtc.h b/include/drm/drm_crtc.h
index 5c28e88..f03a919 100755
--- a/include/drm/drm_crtc.h
+++ b/include/drm/drm_crtc.h
@@ -47,6 +47,7 @@
 #include <drm/drm_plane.h>
 #include <drm/drm_blend.h>
 #include <drm/drm_color_mgmt.h>
+#include <drm/drm_debugfs_crc.h>
 
 struct drm_device;
 struct drm_mode_set;
@@ -616,6 +617,30 @@ struct drm_crtc_funcs {
 	 * before data structures are torndown.
 	 */
 	void (*early_unregister)(struct drm_crtc *crtc);
+
+	/**
+	 * @set_crc_source:
+	 *
+	 * Changes the source of CRC checksums of frames at the request of
+	 * userspace, typically for testing purposes. The sources available are
+	 * specific of each driver and a %NULL value indicates that CRC
+	 * generation is to be switched off.
+	 *
+	 * When CRC generation is enabled, the driver should call
+	 * drm_crtc_add_crc_entry() at each frame, providing any information
+	 * that characterizes the frame contents in the crcN arguments, as
+	 * provided from the configured source. Drivers must accept a "auto"
+	 * source name that will select a default source for this CRTC.
+	 *
+	 * This callback is optional if the driver does not support any CRC
+	 * generation functionality.
+	 *
+	 * RETURNS:
+	 *
+	 * 0 on success or a negative error code on failure.
+	 */
+	int (*set_crc_source)(struct drm_crtc *crtc, const char *source,
+			      size_t *values_cnt);
 };
 
 /**
@@ -732,6 +757,22 @@ struct drm_crtc {
 	 * context.
 	 */
 	struct drm_modeset_acquire_ctx *acquire_ctx;
+
+#ifdef CONFIG_DEBUG_FS
+	/**
+	 * @debugfs_entry:
+	 *
+	 * Debugfs directory for this CRTC.
+	 */
+	struct dentry *debugfs_entry;
+
+	/**
+	 * @crc:
+	 *
+	 * Configuration settings of CRC capture.
+	 */
+	struct drm_crtc_crc crc;
+#endif
 };
 
 /**
diff --git a/include/drm/drm_debugfs_crc.h b/include/drm/drm_debugfs_crc.h
new file mode 100644
index 0000000..7d63b1d
--- /dev/null
+++ b/include/drm/drm_debugfs_crc.h
@@ -0,0 +1,73 @@
+/*
+ * Copyright © 2016 Collabora Ltd.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+#ifndef __DRM_DEBUGFS_CRC_H__
+#define __DRM_DEBUGFS_CRC_H__
+
+#define DRM_MAX_CRC_NR		10
+
+/**
+ * struct drm_crtc_crc_entry - entry describing a frame's content
+ * @has_frame_counter: whether the source was able to provide a frame number
+ * @frame: number of the frame this CRC is about, if @has_frame_counter is true
+ * @crc: array of values that characterize the frame
+ */
+struct drm_crtc_crc_entry {
+	bool has_frame_counter;
+	uint32_t frame;
+	uint32_t crcs[DRM_MAX_CRC_NR];
+};
+
+#define DRM_CRC_ENTRIES_NR	128
+
+/**
+ * struct drm_crtc_crc - data supporting CRC capture on a given CRTC
+ * @lock: protects the fields in this struct
+ * @source: name of the currently configured source of CRCs
+ * @opened: whether userspace has opened the data file for reading
+ * @entries: array of entries, with size of %DRM_CRC_ENTRIES_NR
+ * @head: head of circular queue
+ * @tail: tail of circular queue
+ * @values_cnt: number of CRC values per entry, up to %DRM_MAX_CRC_NR
+ * @wq: workqueue used to synchronize reading and writing
+ */
+struct drm_crtc_crc {
+	spinlock_t lock;
+	const char *source;
+	bool opened;
+	struct drm_crtc_crc_entry *entries;
+	int head, tail;
+	size_t values_cnt;
+	wait_queue_head_t wq;
+};
+
+#if defined(CONFIG_DEBUG_FS)
+int drm_crtc_add_crc_entry(struct drm_crtc *crtc, bool has_frame,
+			   uint32_t frame, uint32_t *crcs);
+#else
+static inline int drm_crtc_add_crc_entry(struct drm_crtc *crtc, bool has_frame,
+					 uint32_t frame, uint32_t *crcs)
+{
+	return -EINVAL;
+}
+#endif /* defined(CONFIG_DEBUG_FS) */
+
+#endif /* __DRM_DEBUGFS_CRC_H__ */
diff --git a/include/drm/ttm/ttm_bo_driver.h b/include/drm/ttm/ttm_bo_driver.h
index 915a851..aa2903d 100644
--- a/include/drm/ttm/ttm_bo_driver.h
+++ b/include/drm/ttm/ttm_bo_driver.h
@@ -592,6 +592,8 @@ struct ttm_bo_device {
 	struct delayed_work wq;
 
 	bool need_dma32;
+
+	bool no_retry;
 };
 
 /**
diff --git a/include/linux/kref.h b/include/linux/kref.h
index e15828f..f72fd76 100644
--- a/include/linux/kref.h
+++ b/include/linux/kref.h
@@ -46,6 +46,11 @@ static inline void kref_get(struct kref *kref)
 	WARN_ON_ONCE(atomic_inc_return(&kref->refcount) < 2);
 }
 
+static inline unsigned int kref_read(const struct kref *kref)
+{
+        return atomic_read(&kref->refcount);
+}
+
 /**
  * kref_sub - subtract a number of refcounts for object.
  * @kref: object.
diff --git a/include/linux/reservation.h b/include/linux/reservation.h
old mode 100644
new mode 100755
index 30d8a94..d470f9a
--- a/include/linux/reservation.h
+++ b/include/linux/reservation.h
@@ -167,6 +167,27 @@ reservation_object_lock(struct reservation_object *obj,
 }
 
 /**
+/**
+ * reservation_object_trylock - trylock the reservation object
+ * @obj: the reservation object
+ *
+ * Tries to lock the reservation object for exclusive access and modification.
+ * Note, that the lock is only against other writers, readers will run
+ * concurrently with a writer under RCU. The seqlock is used to notify readers
+ * if they overlap with a writer.
+ *
+ * Also note that since no context is provided, no deadlock protection is
+ * possible.
+ *
+ * Returns true if the lock was acquired, false otherwise.
+ */
+static inline bool __must_check
+reservation_object_trylock(struct reservation_object *obj)
+{
+	return ww_mutex_trylock(&obj->lock);
+}
+
+/**
  * reservation_object_unlock - unlock the reservation object
  * @obj: the reservation object
  *
diff --git a/include/uapi/drm/amdgpu_drm.h b/include/uapi/drm/amdgpu_drm.h
old mode 100644
new mode 100755
index dc1bb05..71ab384
--- a/include/uapi/drm/amdgpu_drm.h
+++ b/include/uapi/drm/amdgpu_drm.h
@@ -239,42 +239,6 @@ union drm_amdgpu_ctx {
 	union drm_amdgpu_ctx_out out;
 };
 
-/* vm ioctl */
-#define AMDGPU_VM_OP_RESERVE_VMID	1
-#define AMDGPU_VM_OP_UNRESERVE_VMID	2
-
-struct drm_amdgpu_vm_in {
-	/** AMDGPU_VM_OP_* */
-	__u32	op;
-	__u32	flags;
-};
-
-struct drm_amdgpu_vm_out {
-	/** For future use, no flags defined so far */
-	__u64	flags;
-};
-
-union drm_amdgpu_vm {
-	struct drm_amdgpu_vm_in in;
-	struct drm_amdgpu_vm_out out;
-};
-
-/* sched ioctl */
-#define AMDGPU_SCHED_OP_PROCESS_PRIORITY_OVERRIDE      1
-
-struct drm_amdgpu_sched_in {
-        /* AMDGPU_SCHED_OP_* */
-        __u32   op;
-        __u32   fd;
-        __s32   priority;
-        __u32   flags;
-};
-
-union drm_amdgpu_sched {
-        struct drm_amdgpu_sched_in in;
-};
-
-
 /* sem related */
 #define AMDGPU_SEM_OP_CREATE_SEM        1
 #define AMDGPU_SEM_OP_WAIT_SEM	        2
@@ -304,6 +268,41 @@ union drm_amdgpu_sem {
 	union drm_amdgpu_sem_out out;
 };
 
+/* vm ioctl */
+#define AMDGPU_VM_OP_RESERVE_VMID      1
+#define AMDGPU_VM_OP_UNRESERVE_VMID    2
+
+struct drm_amdgpu_vm_in {
+	/** AMDGPU_VM_OP_* */
+	__u32   op;
+	__u32   flags;
+};
+
+struct drm_amdgpu_vm_out {
+	/** For future use, no flags defined so far */
+	__u64   flags;
+};
+
+union drm_amdgpu_vm {
+	struct drm_amdgpu_vm_in in;
+	struct drm_amdgpu_vm_out out;
+};
+
+/* sched ioctl */
+#define AMDGPU_SCHED_OP_PROCESS_PRIORITY_OVERRIDE       1
+
+struct drm_amdgpu_sched_in {
+        /* AMDGPU_SCHED_OP_* */
+        __u32   op;
+        __u32   fd;
+        __s32   priority;
+        __u32   flags;
+};
+
+union drm_amdgpu_sched {
+        struct drm_amdgpu_sched_in in;
+};
+
 /*
  * This is not a reliable API and you should expect it to fail for any
  * number of reasons and have fallback path that do not use userptr to
@@ -323,6 +322,14 @@ struct drm_amdgpu_gem_userptr {
 	__u32		handle;
 };
 
+#define AMDGPU_GEM_DGMA_IMPORT			0
+#define AMDGPU_GEM_DGMA_QUERY_PHYS_ADDR		1
+struct drm_amdgpu_gem_dgma {
+	__u64		addr;
+	__u64		size;
+	__u32		op;
+	__u32		handle;
+};
 struct drm_amdgpu_gem_find_bo {
 	uint64_t		addr;
 	uint64_t		size;
@@ -333,15 +340,6 @@ struct drm_amdgpu_gem_find_bo {
 	uint64_t		offset;
 };
 
-#define AMDGPU_GEM_DGMA_IMPORT			0
-#define AMDGPU_GEM_DGMA_QUERY_PHYS_ADDR			1
-struct drm_amdgpu_gem_dgma {
-	__u64           addr;
-	__u64           size;
-	__u32           op;
-	__u32           handle;
-};
-
 /* SI-CI-VI: */
 /* same meaning as the GB_TILE_MODE and GL_MACRO_TILE_MODE fields */
 #define AMDGPU_TILING_ARRAY_MODE_SHIFT			0
@@ -632,6 +630,7 @@ union drm_amdgpu_fence_to_handle {
 	struct {
 		struct drm_amdgpu_fence fence;
 		__u32 what;
+		__u32 pad;
 	} in;
 	struct {
 		__u32 handle;
-- 
2.7.4


From 1eb0d8b2eedbd3da3fd627010743cab953537ef1 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Christian=20K=C3=B6nig?= <christian.koenig@amd.com>
Date: Mon, 1 Feb 2016 12:20:25 +0100
Subject: [PATCH 0279/1110] drm/amdgpu: cleanup in kernel job submission
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Add a job_alloc_with_ib helper and proper job submission.

Signed-off-by: Christian KÃ¶nig <christian.koenig@amd.com>
Reviewed-by: Alex Deucher <alexander.deucer@amd.com>
Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
Signed-off-by: Kalyan Alle <kalyan.alle@amd.com>
---
 drivers/gpu/drm/amd/amdgpu/amdgpu.h    | 16 ++----
 drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c | 90 ++++++++++------------------------
 2 files changed, 30 insertions(+), 76 deletions(-)

diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu.h b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
index ea4e3aa..0e63bd3 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu.h
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu.h
@@ -754,16 +754,12 @@ enum amdgpu_ring_type {
 };
 
 extern struct amd_sched_backend_ops amdgpu_sched_ops;
-int amdgpu_job_alloc(struct amdgpu_device *adev, unsigned num_ibs,
-                    struct amdgpu_job **job);
+int amdgpu_job_alloc_with_ib(struct amdgpu_device *adev, unsigned size,
+                             struct amdgpu_job **job);
+
 void amdgpu_job_free(struct amdgpu_job *job);
-int amdgpu_sched_ib_submit_kernel_helper(struct amdgpu_device *adev,
-					 struct amdgpu_ring *ring,
-					 struct amdgpu_ib *ibs,
-					 unsigned num_ibs,
-					 int (*free_job)(struct amdgpu_job *),
-					 void *owner,
-					 struct fence **fence);
+int amdgpu_job_submit(struct amdgpu_job *job, struct amdgpu_ring *ring,
+                      void *owner, struct fence **f);
 
 struct amdgpu_ring {
 	struct amdgpu_device		*adev;
@@ -954,7 +950,6 @@ int amdgpu_vm_bo_unmap(struct amdgpu_device *adev,
 		       uint64_t addr);
 void amdgpu_vm_bo_rmv(struct amdgpu_device *adev,
 		      struct amdgpu_bo_va *bo_va);
-int amdgpu_vm_free_job(struct amdgpu_job *job);
 
 /*
  * context related structures
@@ -1208,7 +1203,6 @@ struct amdgpu_job {
 	uint32_t		num_ibs;
 	void			*owner;
 	struct amdgpu_user_fence uf;
-	int (*free_job)(struct amdgpu_job *job);
 };
 #define to_amdgpu_job(sched_job)		\
 		container_of((sched_job), struct amdgpu_job, base)
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
index ec9c967..e65f4a9 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c
@@ -320,15 +320,6 @@ static void amdgpu_vm_update_pages(struct amdgpu_device *adev,
 	}
 }
 
-int amdgpu_vm_free_job(struct amdgpu_job *job)
-{
-	int i;
-	for (i = 0; i < job->num_ibs; i++)
-		amdgpu_ib_free(job->adev, &job->ibs[i]);
-	kfree(job->ibs);
-	return 0;
-}
-
 /**
  * amdgpu_vm_clear_bo - initially clear the page dir/table
  *
@@ -342,7 +333,7 @@ static int amdgpu_vm_clear_bo(struct amdgpu_device *adev,
 {
 	struct amdgpu_ring *ring = adev->vm_manager.vm_pte_funcs_ring;
 	struct fence *fence = NULL;
-	struct amdgpu_ib *ib;
+        struct amdgpu_job *job;
 	unsigned entries;
 	uint64_t addr;
 	int r;
@@ -358,33 +349,24 @@ static int amdgpu_vm_clear_bo(struct amdgpu_device *adev,
 	addr = amdgpu_bo_gpu_offset(bo);
 	entries = amdgpu_bo_size(bo) / 8;
 
-	ib = kzalloc(sizeof(struct amdgpu_ib), GFP_KERNEL);
-	if (!ib)
+        r = amdgpu_job_alloc_with_ib(adev, 64, &job);
+        if (r)
 		goto error;
+        amdgpu_vm_update_pages(adev, NULL, 0, &job->ibs[0], addr, 0, entries,
+                                0, 0);
+        amdgpu_ring_pad_ib(ring, &job->ibs[0]);
 
-        r = amdgpu_ib_get(adev, NULL, 64, ib);
+        WARN_ON(job->ibs[0].length_dw > 64);
+        r = amdgpu_job_submit(job, ring, AMDGPU_FENCE_OWNER_VM, &fence);
 	if (r)
 		goto error_free;
 
-	ib->length_dw = 0;
-
-	amdgpu_vm_update_pages(adev, NULL, 0, ib, addr, 0, entries, 0, 0);
-        amdgpu_ring_pad_ib(ring, ib);
-
-	WARN_ON(ib->length_dw > 64);
-	r = amdgpu_sched_ib_submit_kernel_helper(adev, ring, ib, 1,
-						 &amdgpu_vm_free_job,
-						 AMDGPU_FENCE_OWNER_VM,
-						 &fence);
-	if (!r)
-		amdgpu_bo_fence(bo, fence, true);
+        amdgpu_bo_fence(bo, fence, true)
 	fence_put(fence);
 	return 0;
 
 error_free:
-	amdgpu_ib_free(adev, ib);
-	kfree(ib);
-
+        amdgpu_job_free(job);
 error:
 	return r;
 }
@@ -440,6 +422,7 @@ int amdgpu_vm_update_page_directory(struct amdgpu_device *adev,
 	uint32_t incr = AMDGPU_VM_PTE_COUNT * 8;
 	uint64_t last_pde = ~0, last_pt = ~0;
 	unsigned count = 0, pt_idx, ndw;
+        struct amdgpu_job *job;
 	struct amdgpu_ib *ib;
 	struct fence *fence = NULL;
 
@@ -450,18 +433,11 @@ int amdgpu_vm_update_page_directory(struct amdgpu_device *adev,
 
 	/* assume the worst case */
 	ndw += vm->max_pde_used * 6;
-
-	ib = kzalloc(sizeof(struct amdgpu_ib), GFP_KERNEL);
-	if (!ib)
-		return -ENOMEM;
-
-        r = amdgpu_ib_get(adev, NULL, ndw * 4, ib);
-	if (r) {
-		kfree(ib);
+        r = amdgpu_job_alloc_with_ib(adev, ndw * 4, &job);
+        if (r)
 		return r;
-	}
-	ib->length_dw = 0;
 
+        ib = &job->ibs[0];
 	/* walk over the address space and update the page directory */
 	for (pt_idx = 0; pt_idx <= vm->max_pde_used; ++pt_idx) {
                 struct amdgpu_bo *bo = vm->page_tables[pt_idx].entry.robj;
@@ -502,10 +478,7 @@ int amdgpu_vm_update_page_directory(struct amdgpu_device *adev,
                 amdgpu_ring_pad_ib(ring, ib);
 		amdgpu_sync_resv(adev, &ib->sync, pd->tbo.resv, AMDGPU_FENCE_OWNER_VM);
 		WARN_ON(ib->length_dw > ndw);
-		r = amdgpu_sched_ib_submit_kernel_helper(adev, ring, ib, 1,
-							 &amdgpu_vm_free_job,
-							 AMDGPU_FENCE_OWNER_VM,
-							 &fence);
+                r = amdgpu_job_submit(job, ring, AMDGPU_FENCE_OWNER_VM, &fence);
 		if (r)
 			goto error_free;
 
@@ -513,18 +486,13 @@ int amdgpu_vm_update_page_directory(struct amdgpu_device *adev,
 		fence_put(vm->page_directory_fence);
 		vm->page_directory_fence = fence_get(fence);
 		fence_put(fence);
-	}
-
-	if (ib->length_dw == 0) {
-		amdgpu_ib_free(adev, ib);
-		kfree(ib);
-	}
+        } else {
+                amdgpu_job_free(job);
 
 	return 0;
 
 error_free:
-	amdgpu_ib_free(adev, ib);
-	kfree(ib);
+        amdgpu_job_free(job);
 	return r;
 }
 
@@ -707,6 +675,7 @@ static int amdgpu_vm_bo_update_mapping(struct amdgpu_device *adev,
 	struct amdgpu_ring *ring = adev->vm_manager.vm_pte_funcs_ring;
         void *owner = AMDGPU_FENCE_OWNER_VM;
 	unsigned nptes, ncmds, ndw;
+        struct amdgpu_job *job;
 	struct amdgpu_ib *ib;
 	struct fence *f = NULL;
 	int r;
@@ -744,18 +713,13 @@ static int amdgpu_vm_bo_update_mapping(struct amdgpu_device *adev,
 		/* two extra commands for begin/end of fragment */
 		ndw += 2 * 10;
 	}
+        r = amdgpu_job_alloc_with_ib(adev, ndw * 4, &job);
+        if (r)
 
-	ib = kzalloc(sizeof(struct amdgpu_ib), GFP_KERNEL);
-	if (!ib)
-		return -ENOMEM;
-
-        r = amdgpu_ib_get(adev, NULL, ndw * 4, ib);
-	if (r) {
-		kfree(ib);
 		return r;
-	}
 
-	ib->length_dw = 0;
+        ib = &job->ibs[0];
+
         r = amdgpu_sync_resv(adev, &ib->sync, vm->page_directory->tbo.resv,
                              owner);
         if (r)
@@ -770,10 +734,7 @@ static int amdgpu_vm_bo_update_mapping(struct amdgpu_device *adev,
 
         amdgpu_ring_pad_ib(ring, ib);
 	WARN_ON(ib->length_dw > ndw);
-	r = amdgpu_sched_ib_submit_kernel_helper(adev, ring, ib, 1,
-						 &amdgpu_vm_free_job,
-						 AMDGPU_FENCE_OWNER_VM,
-						 &f);
+        r = amdgpu_job_submit(job, ring, AMDGPU_FENCE_OWNER_VM, &f);
 	if (r)
 		goto error_free;
 
@@ -786,8 +747,7 @@ static int amdgpu_vm_bo_update_mapping(struct amdgpu_device *adev,
 	return 0;
 
 error_free:
-	amdgpu_ib_free(adev, ib);
-	kfree(ib);
+        amdgpu_job_free(job);
 	return r;
 }
 
-- 
2.7.4

